[
  {
    "objectID": "17.sf.html",
    "href": "17.sf.html",
    "title": "17. Spatial Features",
    "section": "",
    "text": "The Spatial features package allows us to read in spatial data into R and transform it. Let’s get a spatial dataset on affordable housing from the NYC open data portal.\n\naff_hsg &lt;- read_csv(\"https://data.cityofnewyork.us/resource/hg8x-zxpr.csv?$limit=10000\")\n\nRows: 6996 Columns: 41\n\n\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr  (10): project_name, house_number, street_name, borough, community_board...\ndbl  (28): project_id, building_id, postcode, bbl, bin, council_district, la...\ndttm  (3): project_start_date, project_completion_date, building_completion_...\n\n\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWith SF, I can take tabular data and make it into a spatial dataset. In this case I have coordinates that I turn into points us st_as_sf\n\nlibrary(sf)\n\nWarning: package 'sf' was built under R version 4.0.5\n\n\nLinking to GEOS 3.9.1, GDAL 3.2.1, PROJ 7.2.1; sf_use_s2() is TRUE\n\naff_hsg_sf &lt;- aff_hsg %&gt;% \n  clean_names() %&gt;% \n  filter(!is.na(longitude)) %&gt;%  #remove properties with missing coordinates\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 2263) #be careful! x = longitude, y = latitude\n\nNow that this is spatial, I can map it! geom_sf is the ggplot function that maps spatial objects. It works much like any other ggplot.\n\nggplot()+\n  geom_sf(aff_hsg_sf, mapping = aes())\n\n\n\n\nI can use programming for styling, too.\n\nggplot()+\n  geom_sf(aff_hsg_sf,\n          mapping = aes(size = all_counted_units,\n                        color = all_counted_units),\n          alpha = 0.25)\n\n\n\n\nBut that doesn’t look very good, let’s add some other layers. I can read in CDs directly as a shapefile using the geojson version from the Open data portal. This map is a long way from done, but now it has a semblance of a basemap.\n\ncd_sf &lt;- read_sf(\"https://data.cityofnewyork.us/resource/jp9i-3b7y.geojson\") %&gt;% \n  st_set_crs(st_crs(aff_hsg_sf)) # here I am setting the crs of the new data to the crs of the point data I already have\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\nggplot()+\n  geom_sf(cd_sf,\n          mapping = aes())+ #this layer will be on bottom!\n  geom_sf(aff_hsg_sf,\n          mapping = aes(size = all_counted_units,\n                        color = all_counted_units),\n          alpha = 0.25) #this layer will be on top!\n\n\n\n          #alpha changes the opacity of the dots\n\nI can also summarize data like I would in a tabular dataset\n\naff_hsg_sum &lt;- aff_hsg %&gt;% \n  group_by(community_board) %&gt;% \n  summarize(total_affordable_units = sum(all_counted_units, na.rm = T))\n\nAnd then I could create a choropleth with the summarized data, now that I have the nta shapes (just a simple join!)\n\ncd_aff_sum &lt;- cd_sf %&gt;% \n  mutate(community_board = case_when(\n    str_sub(boro_cd, 1, 1) == \"1\" ~ paste0(\"MN-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"2\" ~ paste0(\"BX-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"3\" ~ paste0(\"BK-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"4\" ~ paste0(\"QN-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"5\" ~ paste0(\"SI-\",str_sub(boro_cd, 2,3)),\n  )) %&gt;%  #take the first character of boro_cd, replace it with the boro abbreviation, add the community board number\n  left_join(aff_hsg_sum, by = \"community_board\")\n\nI can map that, now as a choropleth\n\nggplot()+\n  geom_sf(cd_aff_sum,\n          mapping = aes(fill = total_affordable_units))\n\n\n\n\nI could also match it to other data, and write it out to a shapefile to use in GIS\n\nlibrary(tidycensus)\n\nWarning: package 'tidycensus' was built under R version 4.0.5\n\ncensus_stats &lt;- get_acs(\n  geography = \"tract\",\n  variables = c(population = \"B01003_001\",\n                med_income = \"B07011_001\"),\n  year = 2021,\n  state = \"NY\",\n  county = c(\"Bronx\", \"New York\", \"Kings\", \"Queens\", \"Richmond\"),\n  output = \"wide\"\n) %&gt;% \n  clean_names()\n\nGetting data from the 2017-2021 5-year ACS\n\n\nI need a crosswalk to go from census tracts to community districts. Open data has one!\n\ncdtas_tracts &lt;- read_csv(\"https://data.cityofnewyork.us/resource/hm78-6dwm.csv?$limit=10000\",\n                         col_types = cols(geoid = col_character()))\n\ncdta_stats &lt;- census_stats %&gt;%\n  left_join(cdtas_tracts, by = \"geoid\") %&gt;% \n  group_by(cdtacode, cdtaname) %&gt;% \n  summarize(total_pop = sum(population_e, na.rm = T),\n            avg_med_inc = mean(med_income_e, na.rm = T)) %&gt;% \n  mutate()\n\n`summarise()` has grouped output by 'cdtacode'. You can override using the `.groups` argument.\n\n\nNow I can join! With everything in the same data frame I can write it out to read into spatial software, or I can visualize it\n\ncd_aff_stats &lt;- cd_aff_sum %&gt;% \n  mutate(cdtacode = str_replace(community_board, \"-\", \"\")) %&gt;% \n  left_join(cdta_stats) %&gt;% \n  mutate(aff_units_person = total_affordable_units/total_pop)\n\nJoining, by = \"cdtacode\"\n\n\n\nst_write(cd_aff_stats,\n         \"output/cd_aff_hsg.shp\",\n         append = F)\n\nWarning in abbreviate_shapefile_names(obj): Field names abbreviated for ESRI\nShapefile driver\n\n\nDeleting layer `cd_aff_hsg' using driver `ESRI Shapefile'\nWriting layer `cd_aff_hsg' to data source \n  `output/cd_aff_hsg.shp' using driver `ESRI Shapefile'\nWriting 71 features with 10 fields and geometry type Multi Polygon.\n\n\nI can map affordable units per person (normalized!)\n\nggplot()+\n  geom_sf(cd_aff_stats,\n          mapping = aes(fill = aff_units_person))\n\n\n\n\nWhat if I wanted to map both both the # of units per cd and the median income?\nI can use one of sf’s spatial operators and to take a centroid and map points\n\npoints_aff_cd &lt;- cd_aff_stats %&gt;% \n  select(total_affordable_units, cdtacode) %&gt;% \n  st_centroid()\n\nWarning in st_centroid.sf(.): st_centroid assumes attributes are constant over\ngeometries of x\n\n\nAnd overlay on a choropleth. You notice that a lot of the buildings are built in low income areas!\n\nggplot()+\n  geom_sf(cd_aff_stats,\n          mapping = aes(fill = avg_med_inc))+\n  geom_sf(points_aff_cd,\n          mapping = aes(size = total_affordable_units),\n          color = \"pink\",\n          alpha = 0.5)\n\nWarning: Removed 12 rows containing missing values (geom_sf).\n\n\n\n\n\nI could write out this ggplot to edit in vector graphics\n\nggsave(\"output/aff_hsg_inc_nyc.svg\")\n\nSaving 7 x 5 in image\n\n\nWarning: Removed 12 rows containing missing values (geom_sf).\n\n\nWhat if I didn’t have a crosswalk and needed to match points to the community district? I can do a spatial join to find what cd all the points fall into.\n\npoints_polygons_join &lt;- st_intersection(aff_hsg_sf, cd_sf)\n\nWarning: attribute variables are assumed to be spatially constant throughout all\ngeometries\n\n\nI can then use summarize() to count points in polygons - or do more advanced summaries\n\npoints_polygons_join %&gt;% \n  as.data.frame() %&gt;% #summarize works faster without the spatial features attached\n  group_by(boro_cd) %&gt;% \n  summarize(points_in_polygon = n(),\n            units_per_cd = sum(all_counted_units, na.rm = T))\n\n# A tibble: 59 x 3\n   boro_cd points_in_polygon units_per_cd\n   &lt;chr&gt;               &lt;int&gt;        &lt;dbl&gt;\n 1 101                     5          300\n 2 102                     7          451\n 3 103                   140         8380\n 4 104                    66         6312\n 5 105                    19         1588\n 6 106                    75         6479\n 7 107                    74         3314\n 8 108                    18         1581\n 9 109                   103         3095\n10 110                   321         9218\n# ... with 49 more rows\n\n\nWhat if I wanted to find the proportion of affordable housing in the flood zone? I can do this with an intersects and mutate - I don’t even need to join the two datasets!\n\n# floodplain_2020s_100y &lt;- read_sf(\"https://data.cityofnewyork.us/resource/inra-wqx3.geojson?$limit=10000\") %&gt;% \n#   st_make_valid() %&gt;%  #this magic function repairs any invalid geometries\n#   st_union() %&gt;% #here I make the entire floodplain into one big shape\n#   st_set_crs(st_crs(points_polygons_join)) #and set it to the same crs as my points\n# \n# points_polygons_join %&gt;% \n#   mutate(fplain_2020s_100y = lengths(st_intersects(.,floodplain_2020s_100y))) %&gt;%  #st_intersects returns a list of the shapes it intersects with - if its 0 it didn't intersect, if its 1 it did!\n#   as.data.frame() %&gt;% \n#   group_by(fplain_2020s_100y) %&gt;% \n#   summarize(count = n(),\n#             units = sum(all_counted_units, na.rm = T))\n\nMany more spatial operations available on the cheat sheets"
  },
  {
    "objectID": "17.sf.html#video-tutorial",
    "href": "17.sf.html#video-tutorial",
    "title": "17. Spatial Features",
    "section": "",
    "text": "The Spatial features package allows us to read in spatial data into R and transform it. Let’s get a spatial dataset on affordable housing from the NYC open data portal.\n\naff_hsg &lt;- read_csv(\"https://data.cityofnewyork.us/resource/hg8x-zxpr.csv?$limit=10000\")\n\nRows: 6996 Columns: 41\n\n\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr  (10): project_name, house_number, street_name, borough, community_board...\ndbl  (28): project_id, building_id, postcode, bbl, bin, council_district, la...\ndttm  (3): project_start_date, project_completion_date, building_completion_...\n\n\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWith SF, I can take tabular data and make it into a spatial dataset. In this case I have coordinates that I turn into points us st_as_sf\n\nlibrary(sf)\n\nWarning: package 'sf' was built under R version 4.0.5\n\n\nLinking to GEOS 3.9.1, GDAL 3.2.1, PROJ 7.2.1; sf_use_s2() is TRUE\n\naff_hsg_sf &lt;- aff_hsg %&gt;% \n  clean_names() %&gt;% \n  filter(!is.na(longitude)) %&gt;%  #remove properties with missing coordinates\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 2263) #be careful! x = longitude, y = latitude\n\nNow that this is spatial, I can map it! geom_sf is the ggplot function that maps spatial objects. It works much like any other ggplot.\n\nggplot()+\n  geom_sf(aff_hsg_sf, mapping = aes())\n\n\n\n\nI can use programming for styling, too.\n\nggplot()+\n  geom_sf(aff_hsg_sf,\n          mapping = aes(size = all_counted_units,\n                        color = all_counted_units),\n          alpha = 0.25)\n\n\n\n\nBut that doesn’t look very good, let’s add some other layers. I can read in CDs directly as a shapefile using the geojson version from the Open data portal. This map is a long way from done, but now it has a semblance of a basemap.\n\ncd_sf &lt;- read_sf(\"https://data.cityofnewyork.us/resource/jp9i-3b7y.geojson\") %&gt;% \n  st_set_crs(st_crs(aff_hsg_sf)) # here I am setting the crs of the new data to the crs of the point data I already have\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\nggplot()+\n  geom_sf(cd_sf,\n          mapping = aes())+ #this layer will be on bottom!\n  geom_sf(aff_hsg_sf,\n          mapping = aes(size = all_counted_units,\n                        color = all_counted_units),\n          alpha = 0.25) #this layer will be on top!\n\n\n\n          #alpha changes the opacity of the dots\n\nI can also summarize data like I would in a tabular dataset\n\naff_hsg_sum &lt;- aff_hsg %&gt;% \n  group_by(community_board) %&gt;% \n  summarize(total_affordable_units = sum(all_counted_units, na.rm = T))\n\nAnd then I could create a choropleth with the summarized data, now that I have the nta shapes (just a simple join!)\n\ncd_aff_sum &lt;- cd_sf %&gt;% \n  mutate(community_board = case_when(\n    str_sub(boro_cd, 1, 1) == \"1\" ~ paste0(\"MN-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"2\" ~ paste0(\"BX-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"3\" ~ paste0(\"BK-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"4\" ~ paste0(\"QN-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"5\" ~ paste0(\"SI-\",str_sub(boro_cd, 2,3)),\n  )) %&gt;%  #take the first character of boro_cd, replace it with the boro abbreviation, add the community board number\n  left_join(aff_hsg_sum, by = \"community_board\")\n\nI can map that, now as a choropleth\n\nggplot()+\n  geom_sf(cd_aff_sum,\n          mapping = aes(fill = total_affordable_units))\n\n\n\n\nI could also match it to other data, and write it out to a shapefile to use in GIS\n\nlibrary(tidycensus)\n\nWarning: package 'tidycensus' was built under R version 4.0.5\n\ncensus_stats &lt;- get_acs(\n  geography = \"tract\",\n  variables = c(population = \"B01003_001\",\n                med_income = \"B07011_001\"),\n  year = 2021,\n  state = \"NY\",\n  county = c(\"Bronx\", \"New York\", \"Kings\", \"Queens\", \"Richmond\"),\n  output = \"wide\"\n) %&gt;% \n  clean_names()\n\nGetting data from the 2017-2021 5-year ACS\n\n\nI need a crosswalk to go from census tracts to community districts. Open data has one!\n\ncdtas_tracts &lt;- read_csv(\"https://data.cityofnewyork.us/resource/hm78-6dwm.csv?$limit=10000\",\n                         col_types = cols(geoid = col_character()))\n\ncdta_stats &lt;- census_stats %&gt;%\n  left_join(cdtas_tracts, by = \"geoid\") %&gt;% \n  group_by(cdtacode, cdtaname) %&gt;% \n  summarize(total_pop = sum(population_e, na.rm = T),\n            avg_med_inc = mean(med_income_e, na.rm = T)) %&gt;% \n  mutate()\n\n`summarise()` has grouped output by 'cdtacode'. You can override using the `.groups` argument.\n\n\nNow I can join! With everything in the same data frame I can write it out to read into spatial software, or I can visualize it\n\ncd_aff_stats &lt;- cd_aff_sum %&gt;% \n  mutate(cdtacode = str_replace(community_board, \"-\", \"\")) %&gt;% \n  left_join(cdta_stats) %&gt;% \n  mutate(aff_units_person = total_affordable_units/total_pop)\n\nJoining, by = \"cdtacode\"\n\n\n\nst_write(cd_aff_stats,\n         \"output/cd_aff_hsg.shp\",\n         append = F)\n\nWarning in abbreviate_shapefile_names(obj): Field names abbreviated for ESRI\nShapefile driver\n\n\nDeleting layer `cd_aff_hsg' using driver `ESRI Shapefile'\nWriting layer `cd_aff_hsg' to data source \n  `output/cd_aff_hsg.shp' using driver `ESRI Shapefile'\nWriting 71 features with 10 fields and geometry type Multi Polygon.\n\n\nI can map affordable units per person (normalized!)\n\nggplot()+\n  geom_sf(cd_aff_stats,\n          mapping = aes(fill = aff_units_person))\n\n\n\n\nWhat if I wanted to map both both the # of units per cd and the median income?\nI can use one of sf’s spatial operators and to take a centroid and map points\n\npoints_aff_cd &lt;- cd_aff_stats %&gt;% \n  select(total_affordable_units, cdtacode) %&gt;% \n  st_centroid()\n\nWarning in st_centroid.sf(.): st_centroid assumes attributes are constant over\ngeometries of x\n\n\nAnd overlay on a choropleth. You notice that a lot of the buildings are built in low income areas!\n\nggplot()+\n  geom_sf(cd_aff_stats,\n          mapping = aes(fill = avg_med_inc))+\n  geom_sf(points_aff_cd,\n          mapping = aes(size = total_affordable_units),\n          color = \"pink\",\n          alpha = 0.5)\n\nWarning: Removed 12 rows containing missing values (geom_sf).\n\n\n\n\n\nI could write out this ggplot to edit in vector graphics\n\nggsave(\"output/aff_hsg_inc_nyc.svg\")\n\nSaving 7 x 5 in image\n\n\nWarning: Removed 12 rows containing missing values (geom_sf).\n\n\nWhat if I didn’t have a crosswalk and needed to match points to the community district? I can do a spatial join to find what cd all the points fall into.\n\npoints_polygons_join &lt;- st_intersection(aff_hsg_sf, cd_sf)\n\nWarning: attribute variables are assumed to be spatially constant throughout all\ngeometries\n\n\nI can then use summarize() to count points in polygons - or do more advanced summaries\n\npoints_polygons_join %&gt;% \n  as.data.frame() %&gt;% #summarize works faster without the spatial features attached\n  group_by(boro_cd) %&gt;% \n  summarize(points_in_polygon = n(),\n            units_per_cd = sum(all_counted_units, na.rm = T))\n\n# A tibble: 59 x 3\n   boro_cd points_in_polygon units_per_cd\n   &lt;chr&gt;               &lt;int&gt;        &lt;dbl&gt;\n 1 101                     5          300\n 2 102                     7          451\n 3 103                   140         8380\n 4 104                    66         6312\n 5 105                    19         1588\n 6 106                    75         6479\n 7 107                    74         3314\n 8 108                    18         1581\n 9 109                   103         3095\n10 110                   321         9218\n# ... with 49 more rows\n\n\nWhat if I wanted to find the proportion of affordable housing in the flood zone? I can do this with an intersects and mutate - I don’t even need to join the two datasets!\n\n# floodplain_2020s_100y &lt;- read_sf(\"https://data.cityofnewyork.us/resource/inra-wqx3.geojson?$limit=10000\") %&gt;% \n#   st_make_valid() %&gt;%  #this magic function repairs any invalid geometries\n#   st_union() %&gt;% #here I make the entire floodplain into one big shape\n#   st_set_crs(st_crs(points_polygons_join)) #and set it to the same crs as my points\n# \n# points_polygons_join %&gt;% \n#   mutate(fplain_2020s_100y = lengths(st_intersects(.,floodplain_2020s_100y))) %&gt;%  #st_intersects returns a list of the shapes it intersects with - if its 0 it didn't intersect, if its 1 it did!\n#   as.data.frame() %&gt;% \n#   group_by(fplain_2020s_100y) %&gt;% \n#   summarize(count = n(),\n#             units = sum(all_counted_units, na.rm = T))\n\nMany more spatial operations available on the cheat sheets"
  },
  {
    "objectID": "2.r_projects.html#opening-r-studio",
    "href": "2.r_projects.html#opening-r-studio",
    "title": "2. Creating R Projects",
    "section": "Opening R Studio",
    "text": "Opening R Studio\nWhen you load RStudio, the screen will be split in three. This is some important vocabulary to direct yourself around RStudio and get help when you need it.\n\nThe CONSOLE is where all your code is run. Here you will see the output from the code you run. The COMMAND LINE is where you can type in code and execute it to the console. Code you run in the console is not saved. Try typing 1+1 into the console, and you’ll see that R spits back 2.\nThe ENVIRONMENT is where all your data will be stored. R is an object oriented programming language. Think of it like having a bunch of spreadsheets open at once. The environment shows you all the data you have loaded, and what each dataset, list, or other object is called.\nThe DIRECTORY is in the bottom right. This links to all the files in your current folder, called your working directory. If you are ever in the wrong working directory, you can set it by running the setwd() function or going to “Session” -\\&gt; “Set Working Directory.” We will keep files organized by using an R Project."
  },
  {
    "objectID": "2.r_projects.html#creating-a-project",
    "href": "2.r_projects.html#creating-a-project",
    "title": "2. Creating R Projects",
    "section": "Creating a Project",
    "text": "Creating a Project\nAn R Project is basically a folder that will hold all your files together in one place - including your code, raw data, and any output you may produce.\nCreate your first R Project by clicking on the projects icon in the top right. You can create a project from a new or existing directory.\nWhen you return to RStudio to work on a saved project, open the project again by using the Project menu in RStudio, or double clicking the .Rproj file in the project directory."
  },
  {
    "objectID": "2.r_projects.html#creating-your-first-script",
    "href": "2.r_projects.html#creating-your-first-script",
    "title": "2. Creating R Projects",
    "section": "Creating Your First Script",
    "text": "Creating Your First Script\nGo to File -&gt; New Script and save it to your project folder\nUse the assignment operator &lt;- to save values, dataframes, and other objects to the environment for future use.\nUse command+enter (Mac) or ctrl + enter (Windows) to run your code. Or select all and then run the shortcut to run the whole script at once."
  },
  {
    "objectID": "3.packages_functions.html#packages",
    "href": "3.packages_functions.html#packages",
    "title": "3. Packages and Functions",
    "section": "Packages",
    "text": "Packages\nR is a base programming language. We access R through a library of different packages. Packages are downloadable content that we use in R to modify data. Packages are made up of functions, which we use to modify and analyze data.\nBase R has a number of functions, packages, and data already installed, which we can preview by putting code in our console.\nTake the iris dataset for example, which we can access by simply typing iris\n\nhead(iris) #head just limits the output to the first few rows of a dataset. put \"iris\" into your console to see the whole dataset\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\nTo get started with R, we need to install packages beyond the preinstalled.\nWe install packages with a console command, using a function called install.packages(). We can get our first, and most crucial package, the tidyverse, using this function. Copy this into your console. Make sure to put the package name in quotes.\n\n#install.packages(\"tidyverse\") #remove the # at the front to actually get this to run\n\nWe can install multiple packages at once by putting them into a list (also called a vector), like so. More on lists later.\n\nFinally we need to load packages at the beginning of our .R script in order to use them. The library() function loads functions that we have installed. Note that we only need to install packages once, so we use the command line. But we need to load packages with library each time we use them, so we put that in our .R script.\n\nlibrary(tidyverse)\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.2 --\n\n\nv ggplot2 3.3.5     v purrr   0.3.4\nv tibble  3.1.6     v dplyr   1.0.7\nv tidyr   1.1.4     v stringr 1.4.0\nv readr   2.1.1     v forcats 0.5.1\n\n\nWarning: package 'ggplot2' was built under R version 4.0.5\n\n\nWarning: package 'tibble' was built under R version 4.0.5\n\n\nWarning: package 'tidyr' was built under R version 4.0.5\n\n\nWarning: package 'readr' was built under R version 4.0.5\n\n\nWarning: package 'dplyr' was built under R version 4.0.5\n\n\nWarning: package 'forcats' was built under R version 4.0.5\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "3.packages_functions.html#functions",
    "href": "3.packages_functions.html#functions",
    "title": "3. Packages and Functions",
    "section": "Functions",
    "text": "Functions\nSo how do these functions we’ve been using work?\nEach function has a name and arguments. The name of a function tells R the operation we want to do. The arguments are the inputs for the function, or what we want to transform, separated by commas.\nYou can look up any R function by typing the function name into the console, preceded by a ?.\n\n?install.packages()\n\nWhen we look at the first function we used, install.packages() the help menu pops up in the bottom right, describing the function, the arguments, and giving us examples. The first argument is called pkgs and it’s defined as “character vector of the names of the packages whose current versions should be downloaded from the repositories.” That first argument is required. Without it install.packages() won’t know which package to install.\nNote that the argument here, the name of the package, is in quotes. In programming, quotes define character objects. In this case the function requires a character input, so we use quotes. More on this later when we talk about data types.\nArguments in R can be named or ordered. Naming an argument means adding the name of the argument, followed by = and then the value of the argument. Unnamed arguments rely on the programmer to put each argument in the proper order, separated by commas. In this case, pkgs is the first argument. So install.packages(pkgs = \"tidyverse\") and install.packages(\"tidyverse\") do the same thing. When you are getting started programming, it’s good practice to name your arguments."
  },
  {
    "objectID": "3.packages_functions.html#tidy-data",
    "href": "3.packages_functions.html#tidy-data",
    "title": "3. Packages and Functions",
    "section": "Tidy Data",
    "text": "Tidy Data\nOur first package, the tidyverse features a number of functions that help keep our data organized in a way that a computer can read, understand, and transform it. The tidyverse uses a principle of tidy data, a standard way of mapping the meaning of a dataset to its structure. In tidy data…\n\nEvery column is a variable.\nEvery row is an observation.\nEvery cell is a single value.\n\nNext time we’ll learn how to read in data, keep it tidy, and get our observations in the right data types.\nTake a second look at iris to see an example of a tidy dataset. There’s one row (observation) for each flower in the sample, a column for each variable (measurements and species) and one value in each cell, the value of that variable for that observation."
  },
  {
    "objectID": "4.readingdata_datatypes.html#reading-data",
    "href": "4.readingdata_datatypes.html#reading-data",
    "title": "4. Reading Data and Data Types",
    "section": "Reading Data",
    "text": "Reading Data\nWe can use R to read in a number of different types of data, manipulate it, and output it in different ways.\nThe core type of data we will be using in this class is the .csv or a comma separated values file. A .csv is a text file where each observation is in its own row and each variable or value is, you guessed it, separated by a comma. R can read these types of files in super easily. Let’s download our first comma separated file from the NYC Open Data Portal.\n\nLet’s download the data on for hire vehicles in NYC and read it into R.\n\nIf we open a csv in a text editor it looks like this, but R will read it into something called a dataframe which is the tidy format for tabular data (data that has rows and columns).\nTo read data into R, we are going to need the function read_csv() and need to learn about file paths.\nIn order for R to read in the file, we need to tell R where the file is. We can do that with an absolute or a local path. An absolute path is the exact location of the file on your computer. For me, when I downloaded this file it went to my downloads folder - a path that looks something like this: /Users/patrickspauster/Downloads/For_Hire_Vehicles__FHV__-_Active.csv. You can look up the path to a file by navigating to the file in finder or windows explorer and right clicking to “Get Info”. I could read it in by using read_csv(\"/Users/patrickspauster/Downloads/For_Hire_Vehicles__FHV__-_Active.csv\").\nBut, not everyone who views my work or wants to run my code will have the same file structure on their computer. If i sent this code to someone and they tried to run it, they would get an error. That’s where the R project and a local path comes in handy.\nNow, save a copy of For_Hire_Vehicles__FHV__-_Active.csv to your project folder. When you do, you should see it appear in the file explorer in the bottom right of your R Studio window. Now we can access the .csv using a local path. Because we have the R project open, R will start looking in the project folder. Now we can run read_csv on our file without having to look up the path.\n(remember to load the tidyverse first! If you get an error like “the function function_name can’t be found”, you probably forgot to load the proper package with library()!)\n\nlibrary(tidyverse)\n\n\nread_csv(\"For_Hire_Vehicles__FHV__-_Active.csv\")\n\nRows: 98318 Columns: 23\n\n\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr  (20): Active, Vehicle License Number, Name, License Type, Expiration Da...\ndbl   (1): Vehicle Year\nlgl   (1): Order Date\ntime  (1): Last Time Updated\n\n\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 98,318 x 23\n   Active `Vehicle License Number` Name          `License Type` `Expiration Dat~\n   &lt;chr&gt;  &lt;chr&gt;                    &lt;chr&gt;         &lt;chr&gt;          &lt;chr&gt;           \n 1 YES    5608977                  AMERICAN,UNI~ FOR HIRE VEHI~ 04/30/2025      \n 2 YES    5645622                  RAMA,ILIR     FOR HIRE VEHI~ 09/11/2023      \n 3 YES    5192507                  ORDONEZ,ELIAS FOR HIRE VEHI~ 03/08/2025      \n 4 YES    5378856                  RIVERA,ENMA   FOR HIRE VEHI~ 11/12/2024      \n 5 YES    5852121                  A/VA,SERVICE~ FOR HIRE VEHI~ 04/11/2024      \n 6 YES    5415237                  REYES,JUAN,E  FOR HIRE VEHI~ 10/31/2023      \n 7 YES    5643301                  BEGUM,TAZMIN~ FOR HIRE VEHI~ 09/30/2025      \n 8 YES    5701439                  GONZALEZALVA~ FOR HIRE VEHI~ 06/13/2024      \n 9 YES    5790931                  GOMEZ,JOSE,A  FOR HIRE VEHI~ 05/23/2025      \n10 YES    5743759                  HOSSAIN,SM,K~ FOR HIRE VEHI~ 12/08/2024      \n# ... with 98,308 more rows, and 18 more variables:\n#   Permit License Number &lt;chr&gt;, DMV License Plate Number &lt;chr&gt;,\n#   Vehicle VIN Number &lt;chr&gt;, Wheelchair Accessible &lt;chr&gt;,\n#   Certification Date &lt;chr&gt;, Hack Up Date &lt;chr&gt;, Vehicle Year &lt;dbl&gt;,\n#   Base Number &lt;chr&gt;, Base Name &lt;chr&gt;, Base Type &lt;chr&gt;, VEH &lt;chr&gt;,\n#   Base Telephone Number &lt;chr&gt;, Website &lt;chr&gt;, Base Address &lt;chr&gt;,\n#   Reason &lt;chr&gt;, Order Date &lt;lgl&gt;, Last Date Updated &lt;chr&gt;, ...\n\n\nLet’s take a closer look at what read_csv() is doing.\n\n?read_csv()\n\nThe function has one required argument, “file” and several optional arguments that we can change. The “file” argument asks for a path to a file as a “string” - remember if you see the words “character” or “string” think quotes. So let’s feed read_csv() the name of the file we want to read in in quotes, and assign it to something using our assignment operator &lt;- so we can further modify it.\n\nfhv &lt;- read_csv(file = \"For_Hire_Vehicles__FHV__-_Active.csv\")\n\n(Aside - naming things is hard, and you will have to name a lot of different objects. Some general rules - don’t use spaces, and try to keep the names simple but informative, and be careful about overwriting the same name)\nNow, fhv is an object in our environment. R gives us some helpful details about the object in the environment menu and the dropdown arrow on the object itself.\n\nR tells us how many observations (rows) and variables (columns) this object has - note how this is a “tidy” dataset. If you hover over the object itself, it will tell you the type of object and its size. In this case we have a dataframe, the tidy format for data in R, often abbreviated df. You can confirm this by running the function is.data.frame() which identifies if an object is of a certain type.\n\nis.data.frame(fhv)\n\n[1] TRUE"
  },
  {
    "objectID": "4.readingdata_datatypes.html#reading-different-types-of-data",
    "href": "4.readingdata_datatypes.html#reading-different-types-of-data",
    "title": "4. Reading Data and Data Types",
    "section": "Reading different types of data",
    "text": "Reading different types of data\nread_csv() is smart, but not perfect. You’ll notice that it has tried to identify the types of data in this dataframe. The Vehicle Year is read in as a num because it is made up of all digits. It correctly identified that Last Time Updated is a Date in the format hms (hours:minutes:seconds). And the DMV License Plate Number is a chr (character), because it is a categorical string variable.\nNumbers, characters, and dates, are three fundamental types of data that we will be using in R. We can use some of the other arguments of read_csv() to make sure that we get columns in the correct format. For example, it missed that Expiration Date should be a date.\nWhen you start getting long arguments, and nested functions, it can be helpful to enter between each argument.\n\nfhv &lt;- read_csv(file = \"For_Hire_Vehicles__FHV__-_Active.csv\",\n                col_types = cols(`Expiration Date` = col_datetime(format = '%m/%d/%Y'))\n                               )\n\n#col types takes one argument - cols. cols() is a named list with the variable = the column's format.\n#we'll learn more about how to parse dates and date data types in lesson 12\n\nBe careful with numeric data types that aren’t actually numbers that will drop leading zeroes (think of a zip code like “06810” which starts with a 0 would get read in as an integer 6,810). If you wanted to match to another dataset with a zipcode you wouldn’t be able to! Another helpful note: you can change the default col_type using col_type = cols(.default = col_character()). You can always change the types of columns back to numbers later."
  },
  {
    "objectID": "4.readingdata_datatypes.html#more-data-types",
    "href": "4.readingdata_datatypes.html#more-data-types",
    "title": "4. Reading Data and Data Types",
    "section": "More data types",
    "text": "More data types\nHere’s a brief look at some other object types you might find in R.\nA value is just one number, stored in an object.\n\nmy_value &lt;- 42\nmy_value\n\n[1] 42\n\n\nA list is a group of values put together, separated by commas. In R the syntax to create a list starts with c(). They are also called vectors in R.\n\nmy_character_vector &lt;- c(\"Patrick\", \"Lucy\", \"Henry\", \"Ceinna\")\nmy_character_vector\n\n[1] \"Patrick\" \"Lucy\"    \"Henry\"   \"Ceinna\" \n\nmy_numeric_vector &lt;- c(1, 3, 5, 7, 9, 11, 13, 17)\nmy_numeric_vector\n\n[1]  1  3  5  7  9 11 13 17\n\n\nVectors can be named or unnamed. Named vectors are pairs of keys (names) and values separated by =.\n\nnamed_vector &lt;- c(\"Patrick\" = 42, \"Lucy\" = 12, \"Ceinna\" = 56, \"Henry\" = 44)\n\nnamed_vector\n\nPatrick    Lucy  Ceinna   Henry \n     42      12      56      44 \n\n\nYou can get a vector of a particular variable in a dataframe by using $ with the dataframe name and the variable name.\n\nprintme &lt;- head(fhv)\n\nprintme$`Base Name`\n\n[1] \"UBER USA, LLC\"               \"UBER USA, LLC\"              \n[3] \"UBER USA, LLC\"               \"BELL LX INC\"                \n[5] \"BAYRIDGE EXPRESS LUXYRY INC\" \"FIRST CLASS C/L SVC CORP\"   \n\n#head() only keeps the first few rows of a dataframe\n\nYou’ll also notice an important type of data - missing data - noted in R as NA. In this dataset the Wheelchair Accessible column is missing for the first few observations. This means that there is no value for that observation and variable. NA values in R are sticky, meaning that unless you tell R to ignore them, R will carry them through all your operations and maybe mess up some of your calculations. For example…\n\n1 + 2 + NA\n\n[1] NA\n\nsum(1,2,NA) #you should be able to figure this out based on what we've learned about functions so far!\n\n[1] NA\n\nsum(1,2,NA, na.rm = TRUE) #the na.rm = T argument removes NAs from a calculation.\n\n[1] 3"
  },
  {
    "objectID": "5.datacleaning_pipe.html#cleaning-data",
    "href": "5.datacleaning_pipe.html#cleaning-data",
    "title": "5. Data cleaning and the pipe",
    "section": "Cleaning Data",
    "text": "Cleaning Data\nLet’s read in data like we did last time. We’re going to “clean” it, which just means making it easier to use and getting it into tidy format.\n\nlibrary(tidyverse)\nlibrary(janitor)\nfhv &lt;- read_csv(file = \"For_Hire_Vehicles__FHV__-_Active.csv\")\n\nWhen we read this in, we have some unfriendly names of variables with spaces in them. To access those variables we have to use `backticks` which are clunky. The janitor package has helpful data cleaning functions. Install it and take a look at the clean_names() function.\nFor many functions, the first argument is always the name of a dataframe. In this case we want to clean the names of our fhv dataframe.\n\nfhv_clean &lt;- clean_names(fhv)\n\nNow our names are clean - they are all lowercase, and have replaced all spaces with underscores. This will make it easier to refer to our column names as we transform data going forward.\nBut instead of assigning a new dataframe each time we want to apply a function, we should apply more than one function at once."
  },
  {
    "objectID": "5.datacleaning_pipe.html#the-pipe",
    "href": "5.datacleaning_pipe.html#the-pipe",
    "title": "5. Data cleaning and the pipe",
    "section": "The Pipe",
    "text": "The Pipe\nLet’s say we also wanted to change the name of a variable. Using the pipe %&gt;% we can apply multiple functions to the same dataframe. Use the shortcut shift+command+m on mac or shift+ctrl+m on windows\nLet’s try rename() a function to change the names of columns. I don’t know what the “veh” column means so I’m going to look it up in the data dictionary on the open data page.\nIt’s an indicator for whether the vehicle is hybrid, so i’m going to rename it “hybrid”. Use the documentation for rename() to figure out the right syntax.\nTo use the pipe, start with the name of the data frame you want to edit, and then chain the pipes after each function using some indenting to organize your code.\n\nfhv_clean &lt;- fhv %&gt;% \n  clean_names() %&gt;% \n  rename(hybrid = veh)\n\n#clean_names() is empty because the first argument is just the name of the dataframe, which has been piped in for us\n\nNow we have a dataset with clean names and a renamed column “hybrid”\nAs we learn more and more functions, we’ll have longer chains of pipes to clean and construct datasets.\n\nfhv_clean\n\n# A tibble: 98,318 x 23\n   active vehicle_license_~ name   license_type expiration_date permit_license_~\n   &lt;chr&gt;  &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;           \n 1 YES    5608977           AMERI~ FOR HIRE VE~ 04/30/2025      &lt;NA&gt;            \n 2 YES    5645622           RAMA,~ FOR HIRE VE~ 09/11/2023      &lt;NA&gt;            \n 3 YES    5192507           ORDON~ FOR HIRE VE~ 03/08/2025      &lt;NA&gt;            \n 4 YES    5378856           RIVER~ FOR HIRE VE~ 11/12/2024      &lt;NA&gt;            \n 5 YES    5852121           A/VA,~ FOR HIRE VE~ 04/11/2024      &lt;NA&gt;            \n 6 YES    5415237           REYES~ FOR HIRE VE~ 10/31/2023      AA243           \n 7 YES    5643301           BEGUM~ FOR HIRE VE~ 09/30/2025      &lt;NA&gt;            \n 8 YES    5701439           GONZA~ FOR HIRE VE~ 06/13/2024      &lt;NA&gt;            \n 9 YES    5790931           GOMEZ~ FOR HIRE VE~ 05/23/2025      &lt;NA&gt;            \n10 YES    5743759           HOSSA~ FOR HIRE VE~ 12/08/2024      &lt;NA&gt;            \n# ... with 98,308 more rows, and 17 more variables:\n#   dmv_license_plate_number &lt;chr&gt;, vehicle_vin_number &lt;chr&gt;,\n#   wheelchair_accessible &lt;chr&gt;, certification_date &lt;chr&gt;, hack_up_date &lt;chr&gt;,\n#   vehicle_year &lt;dbl&gt;, base_number &lt;chr&gt;, base_name &lt;chr&gt;, base_type &lt;chr&gt;,\n#   hybrid &lt;chr&gt;, base_telephone_number &lt;chr&gt;, website &lt;chr&gt;,\n#   base_address &lt;chr&gt;, reason &lt;chr&gt;, order_date &lt;lgl&gt;,\n#   last_date_updated &lt;chr&gt;, last_time_updated &lt;time&gt;"
  },
  {
    "objectID": "6.select_filter.html#select",
    "href": "6.select_filter.html#select",
    "title": "6. Select and Filter",
    "section": "Select",
    "text": "Select\nLet’s read in our data and do some cleaning up of the names with the pipe\n\nlibrary(tidyverse)\nlibrary(janitor)\n\nfhv_clean &lt;- read_csv(file = \"For_Hire_Vehicles__FHV__-_Active.csv\") %&gt;% \n  clean_names() %&gt;% \n  rename(hybrid = veh)\n\nWe have a lot of information in this data frame. What if we want to look at just a few rows and columns. Two core dplyr functions, select and filter, help us do so. dplyr is a core part of the tidyverse, and it has functions that modify dataframes (think of the pipe!)\nLet’s try just keeping active, vehicle_lisence_number, name, license_type, vehicle_year, base_name, and base_type. Select’s first argument is the dataframe, and the following arguments are all the names of columns. In R documentation, an ellipses argument ... means that the function takes a list of arguments. In this case, a list of variables to select\n\nfhv_clean %&gt;% \n  select(active, vehicle_license_number, name, license_type, vehicle_year, base_name, base_type)\n\n# A tibble: 98,318 x 7\n   active vehicle_license_~ name   license_type vehicle_year base_name base_type\n   &lt;chr&gt;  &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    \n 1 YES    5608977           AMERI~ FOR HIRE VE~         2015 UBER USA~ BLACK-CAR\n 2 YES    5645622           RAMA,~ FOR HIRE VE~         2022 UBER USA~ BLACK-CAR\n 3 YES    5192507           ORDON~ FOR HIRE VE~         2016 UBER USA~ BLACK-CAR\n 4 YES    5378856           RIVER~ FOR HIRE VE~         2018 BELL LX ~ BLACK-CAR\n 5 YES    5852121           A/VA,~ FOR HIRE VE~         2019 BAYRIDGE~ BLACK-CAR\n 6 YES    5415237           REYES~ FOR HIRE VE~         2012 FIRST CL~ LIVERY   \n 7 YES    5643301           BEGUM~ FOR HIRE VE~         2015 UBER USA~ BLACK-CAR\n 8 YES    5701439           GONZA~ FOR HIRE VE~         2016 UBER USA~ BLACK-CAR\n 9 YES    5790931           GOMEZ~ FOR HIRE VE~         2017 UBER USA~ BLACK-CAR\n10 YES    5743759           HOSSA~ FOR HIRE VE~         2021 TRI-CITY~ BLACK-CAR\n# ... with 98,308 more rows\n\n#this dataframe has all our observations, but only 6 variables (columns)\n\nFor more advanced selection, check out the logical operations using the tidy-select expressions. Check what - does, for instance.\n\nfhv_clean %&gt;% \n  select(-active)\n\n# A tibble: 98,318 x 22\n   vehicle_license_number name     license_type expiration_date permit_license_~\n   &lt;chr&gt;                  &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;           \n 1 5608977                AMERICA~ FOR HIRE VE~ 04/30/2025      &lt;NA&gt;            \n 2 5645622                RAMA,IL~ FOR HIRE VE~ 09/11/2023      &lt;NA&gt;            \n 3 5192507                ORDONEZ~ FOR HIRE VE~ 03/08/2025      &lt;NA&gt;            \n 4 5378856                RIVERA,~ FOR HIRE VE~ 11/12/2024      &lt;NA&gt;            \n 5 5852121                A/VA,SE~ FOR HIRE VE~ 04/11/2024      &lt;NA&gt;            \n 6 5415237                REYES,J~ FOR HIRE VE~ 10/31/2023      AA243           \n 7 5643301                BEGUM,T~ FOR HIRE VE~ 09/30/2025      &lt;NA&gt;            \n 8 5701439                GONZALE~ FOR HIRE VE~ 06/13/2024      &lt;NA&gt;            \n 9 5790931                GOMEZ,J~ FOR HIRE VE~ 05/23/2025      &lt;NA&gt;            \n10 5743759                HOSSAIN~ FOR HIRE VE~ 12/08/2024      &lt;NA&gt;            \n# ... with 98,308 more rows, and 17 more variables:\n#   dmv_license_plate_number &lt;chr&gt;, vehicle_vin_number &lt;chr&gt;,\n#   wheelchair_accessible &lt;chr&gt;, certification_date &lt;chr&gt;, hack_up_date &lt;chr&gt;,\n#   vehicle_year &lt;dbl&gt;, base_number &lt;chr&gt;, base_name &lt;chr&gt;, base_type &lt;chr&gt;,\n#   hybrid &lt;chr&gt;, base_telephone_number &lt;chr&gt;, website &lt;chr&gt;,\n#   base_address &lt;chr&gt;, reason &lt;chr&gt;, order_date &lt;lgl&gt;,\n#   last_date_updated &lt;chr&gt;, last_time_updated &lt;time&gt;"
  },
  {
    "objectID": "6.select_filter.html#filter",
    "href": "6.select_filter.html#filter",
    "title": "6. Select and Filter",
    "section": "Filter",
    "text": "Filter\nFilter does the same thing as select, but for rows that meet certain logical conditions. Let’s get all the uber vehicles. The first argument of filter is the dataframe. The second is a logical expression.\n\nfhv_clean %&gt;% \n  filter(base_name == \"UBER USA, LLC\")\n\n# A tibble: 76,710 x 23\n   active vehicle_license_~ name   license_type expiration_date permit_license_~\n   &lt;chr&gt;  &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;           \n 1 YES    5608977           AMERI~ FOR HIRE VE~ 04/30/2025      &lt;NA&gt;            \n 2 YES    5645622           RAMA,~ FOR HIRE VE~ 09/11/2023      &lt;NA&gt;            \n 3 YES    5192507           ORDON~ FOR HIRE VE~ 03/08/2025      &lt;NA&gt;            \n 4 YES    5643301           BEGUM~ FOR HIRE VE~ 09/30/2025      &lt;NA&gt;            \n 5 YES    5701439           GONZA~ FOR HIRE VE~ 06/13/2024      &lt;NA&gt;            \n 6 YES    5790931           GOMEZ~ FOR HIRE VE~ 05/23/2025      &lt;NA&gt;            \n 7 YES    5867611           HUSSA~ FOR HIRE VE~ 05/08/2024      &lt;NA&gt;            \n 8 YES    5869802           LU,GU~ FOR HIRE VE~ 05/12/2024      &lt;NA&gt;            \n 9 YES    5715034           LI,PEI FOR HIRE VE~ 08/15/2024      &lt;NA&gt;            \n10 YES    5725892           HAILE~ FOR HIRE VE~ 09/23/2024      &lt;NA&gt;            \n# ... with 76,700 more rows, and 17 more variables:\n#   dmv_license_plate_number &lt;chr&gt;, vehicle_vin_number &lt;chr&gt;,\n#   wheelchair_accessible &lt;chr&gt;, certification_date &lt;chr&gt;, hack_up_date &lt;chr&gt;,\n#   vehicle_year &lt;dbl&gt;, base_number &lt;chr&gt;, base_name &lt;chr&gt;, base_type &lt;chr&gt;,\n#   hybrid &lt;chr&gt;, base_telephone_number &lt;chr&gt;, website &lt;chr&gt;,\n#   base_address &lt;chr&gt;, reason &lt;chr&gt;, order_date &lt;lgl&gt;,\n#   last_date_updated &lt;chr&gt;, last_time_updated &lt;time&gt;\n\n#this dataframe has fewer rows because we have only kept the registered Ubers.\n\nYou use R’s logical operators to return the rows that you care about. Here I’ve returned all the rows where the base_name column exactly matches the string “UBER USA, LLC.” Always use == for logical expressions. The single equals sign = is just for defining the names of arguments and other list items, and will confuse R.\nHere’s some other helpful logical operators you may find yourself using, to return certain strings, numbers, or lists.\n\nfhv_clean %&gt;% \n  filter(base_name %in% c(\"UBER USA, LLC\", \"Take Me 2 Inc\"), #name is in the list\n         vehicle_year &gt;= 2000, #year is greater than or equal to\n         hybrid != \"HYB\" #no hybrids\n         )\n\n# A tibble: 6,433 x 23\n   active vehicle_license_~ name   license_type expiration_date permit_license_~\n   &lt;chr&gt;  &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;           \n 1 YES    6025256           ALSAH~ FOR HIRE VE~ 04/17/2025      &lt;NA&gt;            \n 2 YES    5707125           CITY,~ FOR HIRE VE~ 07/12/2024      &lt;NA&gt;            \n 3 YES    5278357           LI,LIN FOR HIRE VE~ 11/01/2023      &lt;NA&gt;            \n 4 YES    6015005           GULAT~ FOR HIRE VE~ 01/23/2025      &lt;NA&gt;            \n 5 YES    5839092           WILSO~ FOR HIRE VE~ 12/28/2023      &lt;NA&gt;            \n 6 YES    5837702           AMERI~ FOR HIRE VE~ 12/18/2023      &lt;NA&gt;            \n 7 YES    6036945           CCM N~ FOR HIRE VE~ 08/02/2025      &lt;NA&gt;            \n 8 YES    6002683           WU, J~ FOR HIRE VE~ 08/23/2024      &lt;NA&gt;            \n 9 YES    5999878           ALL G~ FOR HIRE VE~ 08/08/2024      &lt;NA&gt;            \n10 YES    5661911           SINGH~ FOR HIRE VE~ 12/16/2023      &lt;NA&gt;            \n# ... with 6,423 more rows, and 17 more variables:\n#   dmv_license_plate_number &lt;chr&gt;, vehicle_vin_number &lt;chr&gt;,\n#   wheelchair_accessible &lt;chr&gt;, certification_date &lt;chr&gt;, hack_up_date &lt;chr&gt;,\n#   vehicle_year &lt;dbl&gt;, base_number &lt;chr&gt;, base_name &lt;chr&gt;, base_type &lt;chr&gt;,\n#   hybrid &lt;chr&gt;, base_telephone_number &lt;chr&gt;, website &lt;chr&gt;,\n#   base_address &lt;chr&gt;, reason &lt;chr&gt;, order_date &lt;lgl&gt;,\n#   last_date_updated &lt;chr&gt;, last_time_updated &lt;time&gt;\n\n\nLet’s combine it to get a subsample of columns and rows based on the criteria specified and assign it for further analysis\n\nubers_thiscentury &lt;- fhv_clean %&gt;% \n  select(active, vehicle_license_number, name, license_type, vehicle_year, base_name, base_type) %&gt;% \n  filter(base_name == \"UBER USA, LLC\",\n         vehicle_year &gt;= 2000, #year is greater than or equal to\n         )"
  },
  {
    "objectID": "7.mutate.html#mutate",
    "href": "7.mutate.html#mutate",
    "title": "7. Mutate",
    "section": "Mutate",
    "text": "Mutate\nMutate is an incredibly powerful tool to create new columns and new variables.\nLet’s grab our code to read in the clean dataframe\n\nfhv_clean &lt;- read_csv(file = \"For_Hire_Vehicles__FHV__-_Active.csv\") %&gt;% \n  clean_names() %&gt;% \n  rename(hybrid = veh)\n\nWe create a new column with mutate by setting the name of our new column and a new value\n\nfhv_clean %&gt;% \n  mutate(city = \"New York City\")\n\n# A tibble: 98,318 x 24\n   active vehicle_license_~ name   license_type expiration_date permit_license_~\n   &lt;chr&gt;  &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;           \n 1 YES    5608977           AMERI~ FOR HIRE VE~ 04/30/2025      &lt;NA&gt;            \n 2 YES    5645622           RAMA,~ FOR HIRE VE~ 09/11/2023      &lt;NA&gt;            \n 3 YES    5192507           ORDON~ FOR HIRE VE~ 03/08/2025      &lt;NA&gt;            \n 4 YES    5378856           RIVER~ FOR HIRE VE~ 11/12/2024      &lt;NA&gt;            \n 5 YES    5852121           A/VA,~ FOR HIRE VE~ 04/11/2024      &lt;NA&gt;            \n 6 YES    5415237           REYES~ FOR HIRE VE~ 10/31/2023      AA243           \n 7 YES    5643301           BEGUM~ FOR HIRE VE~ 09/30/2025      &lt;NA&gt;            \n 8 YES    5701439           GONZA~ FOR HIRE VE~ 06/13/2024      &lt;NA&gt;            \n 9 YES    5790931           GOMEZ~ FOR HIRE VE~ 05/23/2025      &lt;NA&gt;            \n10 YES    5743759           HOSSA~ FOR HIRE VE~ 12/08/2024      &lt;NA&gt;            \n# ... with 98,308 more rows, and 18 more variables:\n#   dmv_license_plate_number &lt;chr&gt;, vehicle_vin_number &lt;chr&gt;,\n#   wheelchair_accessible &lt;chr&gt;, certification_date &lt;chr&gt;, hack_up_date &lt;chr&gt;,\n#   vehicle_year &lt;dbl&gt;, base_number &lt;chr&gt;, base_name &lt;chr&gt;, base_type &lt;chr&gt;,\n#   hybrid &lt;chr&gt;, base_telephone_number &lt;chr&gt;, website &lt;chr&gt;,\n#   base_address &lt;chr&gt;, reason &lt;chr&gt;, order_date &lt;lgl&gt;,\n#   last_date_updated &lt;chr&gt;, last_time_updated &lt;time&gt;, city &lt;chr&gt;\n\n\nYou can create multiple new columns (...) at once\n\nfhv_clean %&gt;% \n  mutate(city = \"New York City\",\n         active = TRUE) #I can overwrite column names too. I've made this active column boolean (true or false)\n\n# A tibble: 98,318 x 24\n   active vehicle_license_~ name   license_type expiration_date permit_license_~\n   &lt;lgl&gt;  &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;           \n 1 TRUE   5608977           AMERI~ FOR HIRE VE~ 04/30/2025      &lt;NA&gt;            \n 2 TRUE   5645622           RAMA,~ FOR HIRE VE~ 09/11/2023      &lt;NA&gt;            \n 3 TRUE   5192507           ORDON~ FOR HIRE VE~ 03/08/2025      &lt;NA&gt;            \n 4 TRUE   5378856           RIVER~ FOR HIRE VE~ 11/12/2024      &lt;NA&gt;            \n 5 TRUE   5852121           A/VA,~ FOR HIRE VE~ 04/11/2024      &lt;NA&gt;            \n 6 TRUE   5415237           REYES~ FOR HIRE VE~ 10/31/2023      AA243           \n 7 TRUE   5643301           BEGUM~ FOR HIRE VE~ 09/30/2025      &lt;NA&gt;            \n 8 TRUE   5701439           GONZA~ FOR HIRE VE~ 06/13/2024      &lt;NA&gt;            \n 9 TRUE   5790931           GOMEZ~ FOR HIRE VE~ 05/23/2025      &lt;NA&gt;            \n10 TRUE   5743759           HOSSA~ FOR HIRE VE~ 12/08/2024      &lt;NA&gt;            \n# ... with 98,308 more rows, and 18 more variables:\n#   dmv_license_plate_number &lt;chr&gt;, vehicle_vin_number &lt;chr&gt;,\n#   wheelchair_accessible &lt;chr&gt;, certification_date &lt;chr&gt;, hack_up_date &lt;chr&gt;,\n#   vehicle_year &lt;dbl&gt;, base_number &lt;chr&gt;, base_name &lt;chr&gt;, base_type &lt;chr&gt;,\n#   hybrid &lt;chr&gt;, base_telephone_number &lt;chr&gt;, website &lt;chr&gt;,\n#   base_address &lt;chr&gt;, reason &lt;chr&gt;, order_date &lt;lgl&gt;,\n#   last_date_updated &lt;chr&gt;, last_time_updated &lt;time&gt;, city &lt;chr&gt;"
  },
  {
    "objectID": "7.mutate.html#mutate-with-logical-expressions",
    "href": "7.mutate.html#mutate-with-logical-expressions",
    "title": "7. Mutate",
    "section": "Mutate with logical expressions",
    "text": "Mutate with logical expressions\nWhere mutate gets powerful is when you use it with logical expressions. Here we use if_else()\n\nfhv_rideshare &lt;- fhv_clean %&gt;% \n  mutate(rideshare = if_else(\n    condition = base_name == \"UBER USA, LLC\",\n    true = \"rideshare\",\n    false = \"limo\"\n  )) #if it's an uber call it rideshare, if its a limo call it something else\n#notice I named the arguments here! A good practice when the argument is not ...\n\nTabulate the variable we made with the count() funtion\n\nfhv_rideshare %&gt;% \n  count(rideshare)\n\n# A tibble: 2 x 2\n  rideshare     n\n  &lt;chr&gt;     &lt;int&gt;\n1 limo      21608\n2 rideshare 76710\n\n\nWhat if we have more than one logical expression we care about? Check out case_when.\n\nfhv_blackcar &lt;- fhv_clean %&gt;% \n  mutate(\n    ride_type = case_when(\n      base_name == \"UBER USA, LLC\" & base_type == \"BLACK-CAR\" ~ \"BLACK CAR RIDESHARE\",\n      base_name != \"UBER USA, LLC\" & base_type == \"BLACK-CAR\" ~ \"BLACK CAR NON-RIDESHARE\",\n      TRUE ~ base_type #if it doesn't meet either condition, return the base_type\n    ))\n\nUse & and | for and and or logical expressions with multiple conditions\n\nfhv_blackcar %&gt;% \n  count(ride_type)#now we have four categories!\n\n# A tibble: 4 x 2\n  ride_type                   n\n  &lt;chr&gt;                   &lt;int&gt;\n1 BLACK CAR NON-RIDESHARE 16225\n2 BLACK CAR RIDESHARE     76710\n3 LIVERY                   3652\n4 LUXURY                   1731"
  },
  {
    "objectID": "7.mutate.html#normalizing-with-mutate",
    "href": "7.mutate.html#normalizing-with-mutate",
    "title": "7. Mutate",
    "section": "Normalizing with Mutate",
    "text": "Normalizing with Mutate\nYou can use statistical functions like mean to normalize data with mutate. mean will return the average of all the vehicle years. You can use mutate to generate a new variable that takes the distance from each observation to the mean.\n\nfhv_clean %&gt;% \n  mutate(year_norm = vehicle_year/mean(vehicle_year, na.rm = T),\n         year_pct = percent_rank(vehicle_year)) %&gt;% \n  select(vehicle_license_number, vehicle_year, year_norm, year_pct)\n\n# A tibble: 98,318 x 4\n   vehicle_license_number vehicle_year year_norm year_pct\n   &lt;chr&gt;                         &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 5608977                        2015     0.998   0.120 \n 2 5645622                        2022     1.00    0.797 \n 3 5192507                        2016     0.999   0.212 \n 4 5378856                        2018     1.00    0.440 \n 5 5852121                        2019     1.00    0.552 \n 6 5415237                        2012     0.997   0.0225\n 7 5643301                        2015     0.998   0.120 \n 8 5701439                        2016     0.999   0.212 \n 9 5790931                        2017     0.999   0.313 \n10 5743759                        2021     1.00    0.714 \n# ... with 98,308 more rows"
  },
  {
    "objectID": "8.groupby_summarize.html#why-summarize-data",
    "href": "8.groupby_summarize.html#why-summarize-data",
    "title": "8. Group By and Summarize",
    "section": "Why summarize data?",
    "text": "Why summarize data?\nHaving clean data is great, but when working with large datasets we are often looking for summary statistics to let us compare different groups. group_by and summarize, often used together in a pipe, are a powerful combo for generating statistics at the group level.\nSummarizing allows us to compare means, medians, or top values based on different categories. It can also be a helpful data cleaning tool, depending on the level of observations in the data."
  },
  {
    "objectID": "8.groupby_summarize.html#summarize",
    "href": "8.groupby_summarize.html#summarize",
    "title": "8. Group By and Summarize",
    "section": "Summarize",
    "text": "Summarize\nSummarize takes a data frame and a ... list of new variables to generate.\nLet’s grab our code to read in the clean dataframe again.\n\nfhv_clean &lt;- read_csv(file = \"For_Hire_Vehicles__FHV__-_Active.csv\") %&gt;% \n  clean_names() %&gt;% \n  rename(hybrid = veh)\n\nNote - summarize is different than summary - a helpful function that provides the basic stats of all variables - a good first step when looking at a new data set\n\nsummary(fhv_clean)\n\n    active          vehicle_license_number     name          \n Length:98318       Length:98318           Length:98318      \n Class :character   Class :character       Class :character  \n Mode  :character   Mode  :character       Mode  :character  \n                                                             \n                                                             \n                                                             \n license_type       expiration_date    permit_license_number\n Length:98318       Length:98318       Length:98318         \n Class :character   Class :character   Class :character     \n Mode  :character   Mode  :character   Mode  :character     \n                                                            \n                                                            \n                                                            \n dmv_license_plate_number vehicle_vin_number wheelchair_accessible\n Length:98318             Length:98318       Length:98318         \n Class :character         Class :character   Class :character     \n Mode  :character         Mode  :character   Mode  :character     \n                                                                  \n                                                                  \n                                                                  \n certification_date hack_up_date        vehicle_year  base_number       \n Length:98318       Length:98318       Min.   :1949   Length:98318      \n Class :character   Class :character   1st Qu.:2016   Class :character  \n Mode  :character   Mode  :character   Median :2018   Mode  :character  \n                                       Mean   :2018                     \n                                       3rd Qu.:2021                     \n                                       Max.   :5015                     \n  base_name          base_type            hybrid          base_telephone_number\n Length:98318       Length:98318       Length:98318       Length:98318         \n Class :character   Class :character   Class :character   Class :character     \n Mode  :character   Mode  :character   Mode  :character   Mode  :character     \n                                                                               \n                                                                               \n                                                                               \n   website          base_address          reason          order_date    \n Length:98318       Length:98318       Length:98318       Mode:logical  \n Class :character   Class :character   Class :character   NA's:98318    \n Mode  :character   Mode  :character   Mode  :character                 \n                                                                        \n                                                                        \n                                                                        \n last_date_updated  last_time_updated\n Length:98318       Length:98318     \n Class :character   Class1:hms       \n Mode  :character   Class2:difftime  \n                    Mode  :numeric   \n                                     \n                                     \n\n\nWith a basic application of summarize, we take all the rows of the dataframe and turn them into one row of data. Here we use mean() to get the average\n\nfhv_clean %&gt;% \n  summarize(average_year = mean(vehicle_year))\n\n# A tibble: 1 x 1\n  average_year\n         &lt;dbl&gt;\n1        2018.\n\n#careful - NAs are sticky so mean() will return NA if there are any missing values. Use na.rm = T to exclude missing in calculating the average\n\nfhv_clean %&gt;% \n  summarize(average_year = mean(vehicle_year, na.rm = TRUE))\n\n# A tibble: 1 x 1\n  average_year\n         &lt;dbl&gt;\n1        2018.\n\n\nYou can summarize multiple variables (...) at once. Look at summarize documentation for the full list of operations you can summarize with.\n\nfhv_clean %&gt;% \n  summarize(total_cars = n(), #n() just counts the number of rows in the group\n            average_year = mean(vehicle_year, na.rm = TRUE),\n            median_year = median(vehicle_year, na.rm = T))\n\n# A tibble: 1 x 3\n  total_cars average_year median_year\n       &lt;int&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n1      98318        2018.        2018\n\n\nWhen using summarize it defaults to one big group - all the data is summarized. To summarize by group we can add group_by()"
  },
  {
    "objectID": "8.groupby_summarize.html#group_by",
    "href": "8.groupby_summarize.html#group_by",
    "title": "8. Group By and Summarize",
    "section": "Group_by",
    "text": "Group_by\nWhere summarize becomes really powerful is pairing it with group_by\n\nfhv_clean %&gt;% \n  group_by(hybrid) %&gt;% \n  summarize(number_cars = n(),\n            mean_year = mean(vehicle_year, na.rm = T))\n\n# A tibble: 9 x 3\n  hybrid number_cars mean_year\n  &lt;chr&gt;        &lt;int&gt;     &lt;dbl&gt;\n1 BEV           2267     2022.\n2 CNG              1     2020 \n3 DSE              1     2019 \n4 HYB           3267     2019.\n5 N                1     2016 \n6 NON              1     2012 \n7 STR             33     2017.\n8 WAV           6016     2019.\n9 &lt;NA&gt;         86731     2018.\n\n\nOften we are grouping on variables of interest and summarizing across that variable. Take the variable we made last time, for example\n\nfhv_type_summary &lt;- fhv_clean %&gt;% \n  mutate(\n    ride_type = case_when(\n      base_name == \"UBER USA, LLC\" & base_type == \"BLACK-CAR\" ~ \"BLACK CAR RIDESHARE\",\n      base_name != \"UBER USA, LLC\" & base_type == \"BLACK-CAR\" ~ \"BLACK CAR NON-RIDESHARE\",\n      TRUE ~ base_type #if it doesn't meet either condition, return the base_type\n    )) %&gt;% \n  group_by(ride_type) %&gt;% #group by the variable we just created!\n  summarize(no_cars = n(),\n            average_year = mean(vehicle_year, na.rm = T))\n\nfhv_type_summary\n\n# A tibble: 4 x 3\n  ride_type               no_cars average_year\n  &lt;chr&gt;                     &lt;int&gt;        &lt;dbl&gt;\n1 BLACK CAR NON-RIDESHARE   16225        2018.\n2 BLACK CAR RIDESHARE       76710        2018.\n3 LIVERY                     3652        2015.\n4 LUXURY                     1731        2020.\n\n\nHere we can see some interesting trends start to emerge, like how the livery cars tend to be the oldest and the luxury cars tend to be newer.\nWe can also group_by multiple variables, or group by logical expressions.\n\nfhv_clean %&gt;% \n  group_by(hybrid, base_type) %&gt;% \n  summarize(total_cars = n())\n\n`summarise()` has grouped output by 'hybrid'. You can override using the `.groups` argument.\n\n\n# A tibble: 18 x 3\n# Groups:   hybrid [9]\n   hybrid base_type total_cars\n   &lt;chr&gt;  &lt;chr&gt;          &lt;int&gt;\n 1 BEV    BLACK-CAR       2232\n 2 BEV    LIVERY            17\n 3 BEV    LUXURY            18\n 4 CNG    BLACK-CAR          1\n 5 DSE    BLACK-CAR          1\n 6 HYB    BLACK-CAR       3009\n 7 HYB    LIVERY           174\n 8 HYB    LUXURY            84\n 9 N      BLACK-CAR          1\n10 NON    BLACK-CAR          1\n11 STR    BLACK-CAR         18\n12 STR    LUXURY            15\n13 WAV    BLACK-CAR       5904\n14 WAV    LIVERY            96\n15 WAV    LUXURY            16\n16 &lt;NA&gt;   BLACK-CAR      81768\n17 &lt;NA&gt;   LIVERY          3365\n18 &lt;NA&gt;   LUXURY          1598\n\nfhv_clean %&gt;% \n  group_by(base_type, vehicle_year &gt;= 2000) %&gt;% \n  summarize(total_cars = n())\n\n`summarise()` has grouped output by 'base_type'. You can override using the `.groups` argument.\n\n\n# A tibble: 4 x 3\n# Groups:   base_type [3]\n  base_type `vehicle_year &gt;= 2000` total_cars\n  &lt;chr&gt;     &lt;lgl&gt;                       &lt;int&gt;\n1 BLACK-CAR TRUE                        92935\n2 LIVERY    TRUE                         3652\n3 LUXURY    FALSE                           5\n4 LUXURY    TRUE                         1726"
  },
  {
    "objectID": "8.groupby_summarize.html#group_by-with-mutate",
    "href": "8.groupby_summarize.html#group_by-with-mutate",
    "title": "8. Group By and Summarize",
    "section": "Group_by with mutate",
    "text": "Group_by with mutate\nPair group_by with mutate to create helpful summary level variables without reducing the number of rows in the dataset.\n\nfhv_clean %&gt;% \n  group_by(base_name) %&gt;% \n  mutate(total_by_name = n()) #variable with the total # of cars for each company name\n\n# A tibble: 98,318 x 24\n# Groups:   base_name [771]\n   active vehicle_license_~ name   license_type expiration_date permit_license_~\n   &lt;chr&gt;  &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;           \n 1 YES    5608977           AMERI~ FOR HIRE VE~ 04/30/2025      &lt;NA&gt;            \n 2 YES    5645622           RAMA,~ FOR HIRE VE~ 09/11/2023      &lt;NA&gt;            \n 3 YES    5192507           ORDON~ FOR HIRE VE~ 03/08/2025      &lt;NA&gt;            \n 4 YES    5378856           RIVER~ FOR HIRE VE~ 11/12/2024      &lt;NA&gt;            \n 5 YES    5852121           A/VA,~ FOR HIRE VE~ 04/11/2024      &lt;NA&gt;            \n 6 YES    5415237           REYES~ FOR HIRE VE~ 10/31/2023      AA243           \n 7 YES    5643301           BEGUM~ FOR HIRE VE~ 09/30/2025      &lt;NA&gt;            \n 8 YES    5701439           GONZA~ FOR HIRE VE~ 06/13/2024      &lt;NA&gt;            \n 9 YES    5790931           GOMEZ~ FOR HIRE VE~ 05/23/2025      &lt;NA&gt;            \n10 YES    5743759           HOSSA~ FOR HIRE VE~ 12/08/2024      &lt;NA&gt;            \n# ... with 98,308 more rows, and 18 more variables:\n#   dmv_license_plate_number &lt;chr&gt;, vehicle_vin_number &lt;chr&gt;,\n#   wheelchair_accessible &lt;chr&gt;, certification_date &lt;chr&gt;, hack_up_date &lt;chr&gt;,\n#   vehicle_year &lt;dbl&gt;, base_number &lt;chr&gt;, base_name &lt;chr&gt;, base_type &lt;chr&gt;,\n#   hybrid &lt;chr&gt;, base_telephone_number &lt;chr&gt;, website &lt;chr&gt;,\n#   base_address &lt;chr&gt;, reason &lt;chr&gt;, order_date &lt;lgl&gt;,\n#   last_date_updated &lt;chr&gt;, last_time_updated &lt;time&gt;, total_by_name &lt;int&gt;\n\n\nUse ungroup() to return to normal mutation operations\n\nfhv_clean %&gt;% \n  group_by(base_type) %&gt;% \n  mutate(mean_by_type = mean(vehicle_year, na.rm =T)) %&gt;% \n  ungroup() %&gt;% \n  mutate(above_below_mean = if_else(\n    condition = vehicle_year &gt; mean_by_type,\n    true = \"above mean\",\n    false = \"below mean\"\n  )) %&gt;% \n  count(above_below_mean)\n\n# A tibble: 2 x 2\n  above_below_mean     n\n  &lt;chr&gt;            &lt;int&gt;\n1 above mean       44530\n2 below mean       53788\n\n#this creates a variable to show if this car is above or below the average year for the group"
  },
  {
    "objectID": "8.groupby_summarize.html#normalizing-with-groups",
    "href": "8.groupby_summarize.html#normalizing-with-groups",
    "title": "8. Group By and Summarize",
    "section": "Normalizing with Groups",
    "text": "Normalizing with Groups\nGroup by, summarize, and mutate are crucial when comparing geographic areas. You can use group_by to get the proportion within a certain group.\nHere’s a full example of how to normalize within a group, using the data on new york housing authority apartments by borough. We want to find the proportion of NYCHA apartments that are Section 8 (vouchers) in each borough.\n\nnycha &lt;- read_csv('https://data.cityofnewyork.us/resource/evjd-dqpz.csv') %&gt;%\n  clean_names()\n\n# Filter for developments that contain any Section 8 transition apartments\nsection8devs &lt;- nycha %&gt;%\n  filter(number_of_section_8_transition_apartments &gt; 0)\n\n# Get some stats on number of section 8 apts across all developments by borough\nsection8devs_by_boro &lt;- section8devs %&gt;%\n  group_by(borough) %&gt;%\n  summarize(section8apts = sum(number_of_section_8_transition_apartments),\n            totalapts = sum(total_number_of_apartments),\n            median_section8apts = median(number_of_section_8_transition_apartments),\n            avg_section8apts = mean(number_of_section_8_transition_apartments)) \n\n# Is this all the info we need? What's missing? (Normalization)\n\n# Section 8 units as a share of all units in mixed finance developments, by borough\nsection8devs_grouped &lt;- section8devs %&gt;%\n  group_by(borough) %&gt;%\n  summarize(total_s8_apts = sum(number_of_section_8_transition_apartments),\n            total_apts = sum(total_number_of_apartments))%&gt;%\n  mutate(s8_share = total_s8_apts / total_apts)\n\n# Section 8 units as a share of all NYCHA units, by borough\nnycha_grouped &lt;- nycha %&gt;%\n  group_by(borough) %&gt;%\n  summarize(total_s8_apts = sum(number_of_section_8_transition_apartments, na.rm=TRUE),\n            total_apts = sum(total_number_of_apartments, na.rm=TRUE))%&gt;%\n  mutate(s8_share = total_s8_apts / total_apts)"
  },
  {
    "objectID": "9.arrange_writecsv.html#how-do-we-get-data-out-of-r",
    "href": "9.arrange_writecsv.html#how-do-we-get-data-out-of-r",
    "title": "9. Arrange and Write Data",
    "section": "How do we get data out of R?",
    "text": "How do we get data out of R?\nOften, we will want to take data that we clean, mutate, summarize, filter, or select with, and output it for use in another software. Think about how you might want to process a million-row data set to get some summary statistics, then create a nice table in excel. Or take some data that you need to make a chart or graphic, and export it so that you can read it into DataWrapper or some other visualization tool. Maybe you need to send your boss a list of items that are buried in a big R dataset.\nWriting data will let you take data out of R and use it other places. But first we might want to use some other functions to get it looking nice and orderly."
  },
  {
    "objectID": "9.arrange_writecsv.html#arrange",
    "href": "9.arrange_writecsv.html#arrange",
    "title": "9. Arrange and Write Data",
    "section": "Arrange",
    "text": "Arrange\narrange() takes data and sorts it based on certain criteria. Like many of our basic functions, it takes a list ... of inputs to sort on. Let’s take a look at an example of something we summarized.\nLet’s grab our code to read in the clean dataframe again. This time I’m just going to use a big pipe to go right to the summary.\n\nlibrary(tidyverse)\nlibrary(janitor)\n\nfhv_summary &lt;- read_csv(file = \"For_Hire_Vehicles__FHV__-_Active.csv\") %&gt;% \n  clean_names() %&gt;% \n  rename(hybrid = veh) %&gt;% \n  mutate(\n    ride_type = case_when(\n      base_name == \"UBER USA, LLC\" & base_type == \"BLACK-CAR\" ~ \"BLACK CAR RIDESHARE\",\n      base_name != \"UBER USA, LLC\" & base_type == \"BLACK-CAR\" ~ \"BLACK CAR NON-RIDESHARE\",\n      TRUE ~ base_type #if it doesn't meet either condition, return the base_type\n    )) %&gt;% \n  group_by(ride_type) %&gt;% #group by the variable we just created!\n  summarize(no_cars = n(),\n            average_year = mean(vehicle_year, na.rm = T))\n\nfhv_summary\n\n# A tibble: 4 x 3\n  ride_type               no_cars average_year\n  &lt;chr&gt;                     &lt;int&gt;        &lt;dbl&gt;\n1 BLACK CAR NON-RIDESHARE   16225        2018.\n2 BLACK CAR RIDESHARE       76710        2018.\n3 LIVERY                     3652        2015.\n4 LUXURY                     1731        2020.\n\n\nNow Let’s say we wanted to sort this list by average oldest car to newest car.\n\nfhv_summary %&gt;% \n  arrange(average_year)\n\n# A tibble: 4 x 3\n  ride_type               no_cars average_year\n  &lt;chr&gt;                     &lt;int&gt;        &lt;dbl&gt;\n1 LIVERY                     3652        2015.\n2 BLACK CAR NON-RIDESHARE   16225        2018.\n3 BLACK CAR RIDESHARE       76710        2018.\n4 LUXURY                     1731        2020.\n\n\nThat puts all the oldest car on top and the newest car on bottom\ndesc is a function that transforms a vector to descending order, and is helpful to use nested inside arrange.\n\nfhv_arranged &lt;- fhv_summary %&gt;% \n  arrange(desc(average_year))\n\nfhv_arranged\n\n# A tibble: 4 x 3\n  ride_type               no_cars average_year\n  &lt;chr&gt;                     &lt;int&gt;        &lt;dbl&gt;\n1 LUXURY                     1731        2020.\n2 BLACK CAR RIDESHARE       76710        2018.\n3 BLACK CAR NON-RIDESHARE   16225        2018.\n4 LIVERY                     3652        2015.\n\n\nArrange also works with multiple variables - the variable listed second breaks ties - and within groups with group_by."
  },
  {
    "objectID": "9.arrange_writecsv.html#write-out-data",
    "href": "9.arrange_writecsv.html#write-out-data",
    "title": "9. Arrange and Write Data",
    "section": "Write out data",
    "text": "Write out data\nNow that we have a nice table arranged the way we want, we can output it for use in another software.\nwrite_csv() is a twin function to read_csv(). It takes the name of an object and then a filepath to write to.\n\nfhv_arranged %&gt;% \n  write_csv(file = \"output/ride_type_by_average_year.csv\")\n\nSince we used the local path this shows up right in our project directory. We will be writing out to .csvs mostly, but there are companion functions to write out other types of data, like excel spreadsheets."
  }
]