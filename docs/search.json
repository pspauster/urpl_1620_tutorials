[
  {
    "objectID": "20.intro_crs.html#introduction-to-coordinate-reference-systems",
    "href": "20.intro_crs.html#introduction-to-coordinate-reference-systems",
    "title": "20. Introduction to Coordinate Reference Systems",
    "section": "Introduction to Coordinate Reference Systems",
    "text": "Introduction to Coordinate Reference Systems\nIn this tutorial: Understand the basics of Coordinate Reference Systems (CRSs) and map projections. See how they function based on the layers you add and learn to adjust your project CRS.\nLearn more about troubleshooting CRS issues: I Hate Coordinate Systems!",
    "crumbs": [
      "QGIS",
      "20. Introduction to Coordinate Reference Systems"
    ]
  },
  {
    "objectID": "20.intro_crs.html#data-downloads",
    "href": "20.intro_crs.html#data-downloads",
    "title": "20. Introduction to Coordinate Reference Systems",
    "section": "Data downloads",
    "text": "Data downloads\nBorough boundaries\nNYC subway stations (Saved copy)\nStormwater outflows",
    "crumbs": [
      "QGIS",
      "20. Introduction to Coordinate Reference Systems"
    ]
  },
  {
    "objectID": "22.spatial_csv.html#adding-a-spatial-csv-layer-to-your-project",
    "href": "22.spatial_csv.html#adding-a-spatial-csv-layer-to-your-project",
    "title": "22. Adding a spatial CSV layer",
    "section": "Adding a spatial CSV layer to your project",
    "text": "Adding a spatial CSV layer to your project\nIn this tutorial: How to add a CSV that contains latitude and longitude to your map project as a point layer",
    "crumbs": [
      "QGIS",
      "22. Adding a spatial CSV layer"
    ]
  },
  {
    "objectID": "22.spatial_csv.html#data-downloads",
    "href": "22.spatial_csv.html#data-downloads",
    "title": "22. Adding a spatial CSV layer",
    "section": "Data downloads",
    "text": "Data downloads\nCSV of geocoded free lunch locations during COVID\nBorough boundaries",
    "crumbs": [
      "QGIS",
      "22. Adding a spatial CSV layer"
    ]
  },
  {
    "objectID": "19.adding_spatial_layers.html#adding-and-exploring-spatial-layers",
    "href": "19.adding_spatial_layers.html#adding-and-exploring-spatial-layers",
    "title": "19. Adding and exploring spatial layers",
    "section": "Adding and Exploring Spatial Layers",
    "text": "Adding and Exploring Spatial Layers\nIn this tutorial: Add New York City boroughs and subway station shapefiles as layers to your QGIS project and explore the data that they contain using the attribute table and the Identify Features tool.",
    "crumbs": [
      "QGIS",
      "19. Adding and exploring spatial layers"
    ]
  },
  {
    "objectID": "19.adding_spatial_layers.html#data-downloads",
    "href": "19.adding_spatial_layers.html#data-downloads",
    "title": "19. Adding and exploring spatial layers",
    "section": "Data downloads",
    "text": "Data downloads\nBorough boundaries\nNYC subway stations (Saved copy)",
    "crumbs": [
      "QGIS",
      "19. Adding and exploring spatial layers"
    ]
  },
  {
    "objectID": "10.joins.html#joining-two-tables-together",
    "href": "10.joins.html#joining-two-tables-together",
    "title": "10. Joins",
    "section": "Joining two Tables together",
    "text": "Joining two Tables together\nJoins are powerful functions that allow you to connect two datasets together through matching values. They can be useful with spatial and non-spatial data alike.\nJoins rely on “keys” that match records across different datasets. This can be something like a name or ID number.\nAs a recap of how joins work, we’re going to show a simple example of two different kinds of joins: ‘left’ joins and ‘inner’ joins. For this example, we will be using the band_members and band_instruments dataframes, which are simple, 3-row datasets that comes included in the dplyr package.\n\nlibrary(tidyverse)\n\nband_members\n\n# A tibble: 3 × 2\n  name  band   \n  &lt;chr&gt; &lt;chr&gt;  \n1 Mick  Stones \n2 John  Beatles\n3 Paul  Beatles\n\nband_instruments\n\n# A tibble: 3 × 2\n  name  plays \n  &lt;chr&gt; &lt;chr&gt; \n1 John  guitar\n2 Paul  bass  \n3 Keith guitar\n\n\nAs you would expect, the first two arguments in a join function are the two tables you are trying to connect together. The third argument is the “join field”, which is the matching column in both datasets we will use to pair up rows.",
    "crumbs": [
      "Learning R",
      "10. Joins"
    ]
  },
  {
    "objectID": "10.joins.html#left-joins",
    "href": "10.joins.html#left-joins",
    "title": "10. Joins",
    "section": "Left Joins",
    "text": "Left Joins\n\nA left_join keeps all of the rows in the first table you specify, appending data from the second table through matching values in the specified “join field”. Let’s see how this kind of join looks with our example data:\n\nband_members_and_instruments &lt;- \n  left_join(band_members, band_instruments, by = \"name\")\n\n# When the \"join field\" column names don't match, you can use:\n# by = c(\"column1\" = \"column2\")\n\nband_members_and_instruments\n\n# A tibble: 3 × 3\n  name  band    plays \n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 Mick  Stones  &lt;NA&gt;  \n2 John  Beatles guitar\n3 Paul  Beatles bass",
    "crumbs": [
      "Learning R",
      "10. Joins"
    ]
  },
  {
    "objectID": "10.joins.html#inner-joins",
    "href": "10.joins.html#inner-joins",
    "title": "10. Joins",
    "section": "Inner Joins",
    "text": "Inner Joins\n\nAn `inner_join` keeps only the rows that have matching values between both tables in the specified “join field.” Any other rows are discarded. Let’s see how this kind of join looks with our example data:\n\nband_members_with_instruments_only &lt;- \n  inner_join(band_members, band_instruments, by = \"name\")\n\nband_members_with_instruments_only\n\n# A tibble: 2 × 3\n  name  band    plays \n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 John  Beatles guitar\n2 Paul  Beatles bass",
    "crumbs": [
      "Learning R",
      "10. Joins"
    ]
  },
  {
    "objectID": "10.joins.html#full-joins",
    "href": "10.joins.html#full-joins",
    "title": "10. Joins",
    "section": "Full Joins",
    "text": "Full Joins\n\nA full_join keeps all rows from both tables, even if a row from the join field isn’t present in one of them. It shows any missing values as NA.\n\nband_members_with_or_without_instruments &lt;- \n  full_join(band_members, band_instruments, by = \"name\")\n\nband_members_with_or_without_instruments\n\n# A tibble: 4 × 3\n  name  band    plays \n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 Mick  Stones  &lt;NA&gt;  \n2 John  Beatles guitar\n3 Paul  Beatles bass  \n4 Keith &lt;NA&gt;    guitar",
    "crumbs": [
      "Learning R",
      "10. Joins"
    ]
  },
  {
    "objectID": "10.joins.html#troubleshooting-joins",
    "href": "10.joins.html#troubleshooting-joins",
    "title": "10. Joins",
    "section": "Troubleshooting Joins",
    "text": "Troubleshooting Joins\n\nJoining when matching columns have different names\nOften times, the “join field” in your first table has a different name than that of your second table. For example, you may be trying to join two tables on a common zip code, but the first table calls the column ‘Zip’ and the second table calls it ‘Postal Code’. There’s a special syntax here to make it work:\n\n# Let's change the \"name\" column to be called \"MusicalArtist\"\n\nband_instruments_renamed &lt;- band_instruments %&gt;% rename(MusicalArtist = name)\n\n# In our join function, we need to specify that the \"name\" column in the first table matches up with the \"MusicalArtist\" column in the second table. We do that by setting our \"by\" parameter differently:\n\nband_members_and_instruments_2 &lt;- \n  inner_join(band_members, band_instruments_renamed, \n             by = c(\"name\" = \"MusicalArtist\"))\n\nband_members_and_instruments_2\n\n# A tibble: 2 × 3\n  name  band    plays \n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 John  Beatles guitar\n2 Paul  Beatles bass  \n\n\nYou can also join across multiple keys (variables), by giving by a list. It will return only rows that match both variables.\n\n\nDetecting duplicate values\nDuplicate values in your data can cause problems with joins. For example, what if our `band_instruments` dataset listed “John” twice:\n\n# Let's add a new row to band_instruments… say \"John\" also plays \"flute\"\n\nband_instruments_with_dup &lt;- band_instruments %&gt;% add_row(name = \"John\", plays = \"flute\")\n\nband_instruments_with_dup\n\n# A tibble: 4 × 2\n  name  plays \n  &lt;chr&gt; &lt;chr&gt; \n1 John  guitar\n2 Paul  bass  \n3 Keith guitar\n4 John  flute \n\n\nWhen we try and join our `band_members` table with this new table, we now get 4 rows in the resulting table, even though our first table only had 3 rows… how can that be?\n\nband_members_and_instruments_dup &lt;- \n  left_join(band_members, band_instruments_with_dup, by = \"name\")\n\nband_members_and_instruments_dup\n\n# A tibble: 4 × 3\n  name  band    plays \n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 Mick  Stones  &lt;NA&gt;  \n2 John  Beatles guitar\n3 John  Beatles flute \n4 Paul  Beatles bass  \n\n\nIn R, if there are multiple matches between the two tables, all combinations of the matches are returned. This GIF illustrates visually how this works:\n\nIn general, to avoid confusing and unexpected results like this, it’s important to always check for duplicate values in your data, _especially_ in columns that you intend to use as a join field.\nLuckily, the `janitor` package has a function for that called `get_dupes`.\n\nlibrary(janitor)# Remember to run `install.packages('janitor')` in your console if you've\n\nband_instruments_with_dup %&gt;% get_dupes(name)\n\n# A tibble: 2 × 3\n  name  dupe_count plays \n  &lt;chr&gt;      &lt;int&gt; &lt;chr&gt; \n1 John           2 guitar\n2 John           2 flute \n\n\nSometimes you may expect duplicate values in a column, and sometimes they may come as a surprise. General Rule: always know what each row represents in your data and what should be unique values.\nSometimes you’ll want to return more rows than you start with, for example if you were matching census divisions to states in order to aggregate the total land area.\n\nregions_divisions #crosswalk between regions and divisions\n\n         region           division\n1         South East South Central\n2          West            Pacific\n3          West           Mountain\n4         South West South Central\n5     Northeast        New England\n6         South     South Atlantic\n7 North Central East North Central\n8 North Central West North Central\n9     Northeast    Middle Atlantic\n\nstate_area #this doesn't have the region included! oh no!\n\n             name           division   area\n1         Alabama East South Central  51609\n2          Alaska            Pacific 589757\n3         Arizona           Mountain 113909\n4        Arkansas West South Central  53104\n5      California            Pacific 158693\n6        Colorado           Mountain 104247\n7     Connecticut        New England   5009\n8        Delaware     South Atlantic   2057\n9         Florida     South Atlantic  58560\n10        Georgia     South Atlantic  58876\n11         Hawaii            Pacific   6450\n12          Idaho           Mountain  83557\n13       Illinois East North Central  56400\n14        Indiana East North Central  36291\n15           Iowa West North Central  56290\n16         Kansas West North Central  82264\n17       Kentucky East South Central  40395\n18      Louisiana West South Central  48523\n19          Maine        New England  33215\n20       Maryland     South Atlantic  10577\n21  Massachusetts        New England   8257\n22       Michigan East North Central  58216\n23      Minnesota West North Central  84068\n24    Mississippi East South Central  47716\n25       Missouri West North Central  69686\n26        Montana           Mountain 147138\n27       Nebraska West North Central  77227\n28         Nevada           Mountain 110540\n29  New Hampshire        New England   9304\n30     New Jersey    Middle Atlantic   7836\n31     New Mexico           Mountain 121666\n32       New York    Middle Atlantic  49576\n33 North Carolina     South Atlantic  52586\n34   North Dakota West North Central  70665\n35           Ohio East North Central  41222\n36       Oklahoma West South Central  69919\n37         Oregon            Pacific  96981\n38   Pennsylvania    Middle Atlantic  45333\n39   Rhode Island        New England   1214\n40 South Carolina     South Atlantic  31055\n41   South Dakota West North Central  77047\n42      Tennessee East South Central  42244\n43          Texas West South Central 267339\n44           Utah           Mountain  84916\n45        Vermont        New England   9609\n46       Virginia     South Atlantic  40815\n47     Washington            Pacific  68192\n48  West Virginia     South Atlantic  24181\n49      Wisconsin East North Central  56154\n50        Wyoming           Mountain  97914\n\nregions_states &lt;- left_join(regions_divisions, state_area, by = \"division\")\n\nregions_states #the join matches state to region and lets us summarize\n\n          region           division           name   area\n1          South East South Central        Alabama  51609\n2          South East South Central       Kentucky  40395\n3          South East South Central    Mississippi  47716\n4          South East South Central      Tennessee  42244\n5           West            Pacific         Alaska 589757\n6           West            Pacific     California 158693\n7           West            Pacific         Hawaii   6450\n8           West            Pacific         Oregon  96981\n9           West            Pacific     Washington  68192\n10          West           Mountain        Arizona 113909\n11          West           Mountain       Colorado 104247\n12          West           Mountain          Idaho  83557\n13          West           Mountain        Montana 147138\n14          West           Mountain         Nevada 110540\n15          West           Mountain     New Mexico 121666\n16          West           Mountain           Utah  84916\n17          West           Mountain        Wyoming  97914\n18         South West South Central       Arkansas  53104\n19         South West South Central      Louisiana  48523\n20         South West South Central       Oklahoma  69919\n21         South West South Central          Texas 267339\n22     Northeast        New England    Connecticut   5009\n23     Northeast        New England          Maine  33215\n24     Northeast        New England  Massachusetts   8257\n25     Northeast        New England  New Hampshire   9304\n26     Northeast        New England   Rhode Island   1214\n27     Northeast        New England        Vermont   9609\n28         South     South Atlantic       Delaware   2057\n29         South     South Atlantic        Florida  58560\n30         South     South Atlantic        Georgia  58876\n31         South     South Atlantic       Maryland  10577\n32         South     South Atlantic North Carolina  52586\n33         South     South Atlantic South Carolina  31055\n34         South     South Atlantic       Virginia  40815\n35         South     South Atlantic  West Virginia  24181\n36 North Central East North Central       Illinois  56400\n37 North Central East North Central        Indiana  36291\n38 North Central East North Central       Michigan  58216\n39 North Central East North Central           Ohio  41222\n40 North Central East North Central      Wisconsin  56154\n41 North Central West North Central           Iowa  56290\n42 North Central West North Central         Kansas  82264\n43 North Central West North Central      Minnesota  84068\n44 North Central West North Central       Missouri  69686\n45 North Central West North Central       Nebraska  77227\n46 North Central West North Central   North Dakota  70665\n47 North Central West North Central   South Dakota  77047\n48     Northeast    Middle Atlantic     New Jersey   7836\n49     Northeast    Middle Atlantic       New York  49576\n50     Northeast    Middle Atlantic   Pennsylvania  45333\n\nregions_states %&gt;% \n  group_by(region) %&gt;% \n  summarize(region_area = sum(area))\n\n# A tibble: 4 × 2\n  region        region_area\n  &lt;fct&gt;               &lt;dbl&gt;\n1 Northeast          169353\n2 South              899556\n3 North Central      765530\n4 West              1783960",
    "crumbs": [
      "Learning R",
      "10. Joins"
    ]
  },
  {
    "objectID": "6.select_filter.html#select",
    "href": "6.select_filter.html#select",
    "title": "6. Select and Filter",
    "section": "Select",
    "text": "Select\nLet’s read in our data and do some cleaning up of the names with the pipe\n\nlibrary(tidyverse)\nlibrary(janitor)\n\nfhv_clean &lt;- read_csv(file = \"For_Hire_Vehicles__FHV__-_Active.csv\") %&gt;% \n  clean_names() %&gt;% \n  rename(hybrid = veh)\n\nWe have a lot of information in this data frame. What if we want to look at just a few rows and columns. Two core dplyr functions, select and filter, help us do so. dplyr is a core part of the tidyverse, and it has functions that modify dataframes (think of the pipe!)\nLet’s try just keeping active, vehicle_lisence_number, name, license_type, vehicle_year, base_name, and base_type. Select’s first argument is the dataframe, and the following arguments are all the names of columns. In R documentation, an ellipses argument ... means that the function takes a list of arguments. In this case, a list of variables to select\n\nfhv_clean %&gt;% \n  select(active, vehicle_license_number, name, license_type, vehicle_year, base_name, base_type)\n\n# A tibble: 98,318 × 7\n   active vehicle_license_number name        license_type vehicle_year base_name\n   &lt;chr&gt;  &lt;chr&gt;                  &lt;chr&gt;       &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;    \n 1 YES    5608977                AMERICAN,U… FOR HIRE VE…         2015 UBER USA…\n 2 YES    5645622                RAMA,ILIR   FOR HIRE VE…         2022 UBER USA…\n 3 YES    5192507                ORDONEZ,EL… FOR HIRE VE…         2016 UBER USA…\n 4 YES    5378856                RIVERA,ENMA FOR HIRE VE…         2018 BELL LX …\n 5 YES    5852121                A/VA,SERVI… FOR HIRE VE…         2019 BAYRIDGE…\n 6 YES    5415237                REYES,JUAN… FOR HIRE VE…         2012 FIRST CL…\n 7 YES    5643301                BEGUM,TAZM… FOR HIRE VE…         2015 UBER USA…\n 8 YES    5701439                GONZALEZAL… FOR HIRE VE…         2016 UBER USA…\n 9 YES    5790931                GOMEZ,JOSE… FOR HIRE VE…         2017 UBER USA…\n10 YES    5743759                HOSSAIN,SM… FOR HIRE VE…         2021 TRI-CITY…\n# ℹ 98,308 more rows\n# ℹ 1 more variable: base_type &lt;chr&gt;\n\n#this dataframe has all our observations, but only 6 variables (columns)\n\nFor more advanced selection, check out the logical operations using the tidy-select expressions. Check what - does, for instance.\n\nfhv_clean %&gt;% \n  select(-active)\n\n# A tibble: 98,318 × 22\n   vehicle_license_number name                      license_type expiration_date\n   &lt;chr&gt;                  &lt;chr&gt;                     &lt;chr&gt;        &lt;chr&gt;          \n 1 5608977                AMERICAN,UNITED,TRANSPOR… FOR HIRE VE… 04/30/2025     \n 2 5645622                RAMA,ILIR                 FOR HIRE VE… 09/11/2023     \n 3 5192507                ORDONEZ,ELIAS             FOR HIRE VE… 03/08/2025     \n 4 5378856                RIVERA,ENMA               FOR HIRE VE… 11/12/2024     \n 5 5852121                A/VA,SERVICE,CORP         FOR HIRE VE… 04/11/2024     \n 6 5415237                REYES,JUAN,E              FOR HIRE VE… 10/31/2023     \n 7 5643301                BEGUM,TAZMINUR            FOR HIRE VE… 09/30/2025     \n 8 5701439                GONZALEZALVARADO,L        FOR HIRE VE… 06/13/2024     \n 9 5790931                GOMEZ,JOSE,A              FOR HIRE VE… 05/23/2025     \n10 5743759                HOSSAIN,SM,KAMAL          FOR HIRE VE… 12/08/2024     \n# ℹ 98,308 more rows\n# ℹ 18 more variables: permit_license_number &lt;chr&gt;,\n#   dmv_license_plate_number &lt;chr&gt;, vehicle_vin_number &lt;chr&gt;,\n#   wheelchair_accessible &lt;chr&gt;, certification_date &lt;chr&gt;, hack_up_date &lt;chr&gt;,\n#   vehicle_year &lt;dbl&gt;, base_number &lt;chr&gt;, base_name &lt;chr&gt;, base_type &lt;chr&gt;,\n#   hybrid &lt;chr&gt;, base_telephone_number &lt;chr&gt;, website &lt;chr&gt;,\n#   base_address &lt;chr&gt;, reason &lt;chr&gt;, order_date &lt;lgl&gt;, …",
    "crumbs": [
      "Learning R",
      "6. Select and Filter"
    ]
  },
  {
    "objectID": "6.select_filter.html#filter",
    "href": "6.select_filter.html#filter",
    "title": "6. Select and Filter",
    "section": "Filter",
    "text": "Filter\nFilter does the same thing as select, but for rows that meet certain logical conditions. Let’s get all the uber vehicles. The first argument of filter is the dataframe. The second is a logical expression.\n\nfhv_clean %&gt;% \n  filter(base_name == \"UBER USA, LLC\")\n\n# A tibble: 76,710 × 23\n   active vehicle_license_number name               license_type expiration_date\n   &lt;chr&gt;  &lt;chr&gt;                  &lt;chr&gt;              &lt;chr&gt;        &lt;chr&gt;          \n 1 YES    5608977                AMERICAN,UNITED,T… FOR HIRE VE… 04/30/2025     \n 2 YES    5645622                RAMA,ILIR          FOR HIRE VE… 09/11/2023     \n 3 YES    5192507                ORDONEZ,ELIAS      FOR HIRE VE… 03/08/2025     \n 4 YES    5643301                BEGUM,TAZMINUR     FOR HIRE VE… 09/30/2025     \n 5 YES    5701439                GONZALEZALVARADO,L FOR HIRE VE… 06/13/2024     \n 6 YES    5790931                GOMEZ,JOSE,A       FOR HIRE VE… 05/23/2025     \n 7 YES    5867611                HUSSAIN, TARIQ     FOR HIRE VE… 05/08/2024     \n 8 YES    5869802                LU,GUI,ZHAO        FOR HIRE VE… 05/12/2024     \n 9 YES    5715034                LI,PEI             FOR HIRE VE… 08/15/2024     \n10 YES    5725892                HAILE,TEMESGEN,K   FOR HIRE VE… 09/23/2024     \n# ℹ 76,700 more rows\n# ℹ 18 more variables: permit_license_number &lt;chr&gt;,\n#   dmv_license_plate_number &lt;chr&gt;, vehicle_vin_number &lt;chr&gt;,\n#   wheelchair_accessible &lt;chr&gt;, certification_date &lt;chr&gt;, hack_up_date &lt;chr&gt;,\n#   vehicle_year &lt;dbl&gt;, base_number &lt;chr&gt;, base_name &lt;chr&gt;, base_type &lt;chr&gt;,\n#   hybrid &lt;chr&gt;, base_telephone_number &lt;chr&gt;, website &lt;chr&gt;,\n#   base_address &lt;chr&gt;, reason &lt;chr&gt;, order_date &lt;lgl&gt;, …\n\n#this dataframe has fewer rows because we have only kept the registered Ubers.\n\nYou use R’s logical operators to return the rows that you care about. Here I’ve returned all the rows where the base_name column exactly matches the string “UBER USA, LLC.” Always use == for logical expressions. The single equals sign = is just for defining the names of arguments and other list items, and will confuse R.\nHere’s some other helpful logical operators you may find yourself using, to return certain strings, numbers, or lists.\n\nfhv_clean %&gt;% \n  filter(base_name %in% c(\"UBER USA, LLC\", \"Take Me 2 Inc\"), #name is in the list\n         vehicle_year &gt;= 2000, #year is greater than or equal to\n         hybrid != \"HYB\" #no hybrids\n         )\n\n# A tibble: 6,433 × 23\n   active vehicle_license_number name               license_type expiration_date\n   &lt;chr&gt;  &lt;chr&gt;                  &lt;chr&gt;              &lt;chr&gt;        &lt;chr&gt;          \n 1 YES    6025256                ALSAHYBI, SUHAIB   FOR HIRE VE… 04/17/2025     \n 2 YES    5707125                CITY,QUEENS,INC    FOR HIRE VE… 07/12/2024     \n 3 YES    5278357                LI,LIN             FOR HIRE VE… 11/01/2023     \n 4 YES    6015005                GULATI,SONU        FOR HIRE VE… 01/23/2025     \n 5 YES    5839092                WILSON',SONS,INC   FOR HIRE VE… 12/28/2023     \n 6 YES    5837702                AMERICAN,UNITED,T… FOR HIRE VE… 12/18/2023     \n 7 YES    6036945                CCM NY LLC         FOR HIRE VE… 08/02/2025     \n 8 YES    6002683                WU, JINXIANG       FOR HIRE VE… 08/23/2024     \n 9 YES    5999878                ALL GREEN HAMSAF … FOR HIRE VE… 08/08/2024     \n10 YES    5661911                SINGH,SANDEEP      FOR HIRE VE… 12/16/2023     \n# ℹ 6,423 more rows\n# ℹ 18 more variables: permit_license_number &lt;chr&gt;,\n#   dmv_license_plate_number &lt;chr&gt;, vehicle_vin_number &lt;chr&gt;,\n#   wheelchair_accessible &lt;chr&gt;, certification_date &lt;chr&gt;, hack_up_date &lt;chr&gt;,\n#   vehicle_year &lt;dbl&gt;, base_number &lt;chr&gt;, base_name &lt;chr&gt;, base_type &lt;chr&gt;,\n#   hybrid &lt;chr&gt;, base_telephone_number &lt;chr&gt;, website &lt;chr&gt;,\n#   base_address &lt;chr&gt;, reason &lt;chr&gt;, order_date &lt;lgl&gt;, …\n\n\nLet’s combine it to get a subsample of columns and rows based on the criteria specified and assign it for further analysis\n\nubers_thiscentury &lt;- fhv_clean %&gt;% \n  select(active, vehicle_license_number, name, license_type, vehicle_year, base_name, base_type) %&gt;% \n  filter(base_name == \"UBER USA, LLC\",\n         vehicle_year &gt;= 2000, #year is greater than or equal to\n         )",
    "crumbs": [
      "Learning R",
      "6. Select and Filter"
    ]
  },
  {
    "objectID": "12.ggplot.html#preparing-data-for-ggplot",
    "href": "12.ggplot.html#preparing-data-for-ggplot",
    "title": "12. ggplot",
    "section": "Preparing Data for ggplot",
    "text": "Preparing Data for ggplot\nData for ggplot needs to be in “long” format, meaning that all the values need to be in the same column and all the variables need to be in another column.\nLet’s use that rent stabilization data to create a plot. In this case the data is wide by year, meaning there is a column for each year with different values. We want a dataset where each year has its own row - where each row is a year-building combination - that we can plot.\n\nlibrary(tidyverse)\nlibrary(janitor)\n\nrent_stab_long &lt;- read_csv(\"https://taxbillsnyc.s3.amazonaws.com/joined.csv\") %&gt;% \n  select(borough, ucbbl, ends_with(\"uc\")) %&gt;% \n  pivot_longer(\n    ends_with(\"uc\"),  # The multiple column names we want to mush into one column\n    names_to = \"year\", # The title for the new column of names we're generating\n    values_to = \"units\" # The title for the new column of values we're generating\n  )",
    "crumbs": [
      "Learning R",
      "12. ggplot"
    ]
  },
  {
    "objectID": "12.ggplot.html#ggplot-syntax",
    "href": "12.ggplot.html#ggplot-syntax",
    "title": "12. ggplot",
    "section": "ggplot syntax",
    "text": "ggplot syntax\nggplots use similar syntax to regular R operations - they are groups of functions beginning with ggplot(). Instead of the pipe, ggplot uses + between different functions to build layers on top of each other.\nTypically, ggplot will start with ggplot(dataframe) + a geometric function like geom_col() and an aesthetics or aes argument that indicates which variables to plot.\n\n\nAfter that, ggplot has a ton of options to specify the labels, scales, axes, themes, legends,and more. It’s best shown through examples",
    "crumbs": [
      "Learning R",
      "12. ggplot"
    ]
  },
  {
    "objectID": "12.ggplot.html#sample-line-chart",
    "href": "12.ggplot.html#sample-line-chart",
    "title": "12. ggplot",
    "section": "Sample Line Chart",
    "text": "Sample Line Chart\nLine charts are often a good fit for time-series data. Let’s summarize the long data by year and borough and count the number of units.\n\nrs_long_manhattan_summary &lt;- rent_stab_long %&gt;% \n  filter(borough %in% c(\"MN\",\"BK\") # Filter only Manhattan and Brooklyn values\n          & !is.na(units)) %&gt;% # Filter out null unit count values\n  mutate(year = as.numeric(gsub(\"uc\",\"\", year))) %&gt;% # Remove \"uc\" from year values\n  select(year, borough, units) %&gt;% \n  # Grouping by 2 columns means each row will have a unique pair of the two columns' values.\n  # Our rows will look like: 2007 MN, 2007 BK, 2008 MN... \n  group_by(year, borough) %&gt;% \n  summarise(total_units = sum(units))\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\n\nNow let’s plot it. We start with the data, then add aesthetics, our chart type (line), axis specifications, and labels.\n\nrs_over_time_graph &lt;- ggplot(rs_long_manhattan_summary) +\n    # Note these arguments inside 'geom_line' :\n  geom_line(aes(x=year, y=total_units, color=borough)) +\n    # Restyle the Y-axis labels: \n  scale_y_continuous(\n    limits = c(0,300000),\n    labels = scales::unit_format(scale = 1/1000, unit=\"K\")) +\n  scale_x_continuous(breaks = seq(2007, 2017, by = 1))+\n    # Restyle the Legend: \n  scale_fill_discrete(\n    name=\"Borough\",\n    breaks=c(\"BK\", \"MN\"),\n    labels=c(\"Brooklyn\", \"Manhattan\")) +\n  labs(\n    title = \"Total Rent Stabilized Units over Time\",\n    subtitle = \"Manhattan and Brooklyn, 2007 to 2017\",\n    x = \"Year\",\n    y = \"Total Rent Stabilized Units\",\n    caption = \"Source: taxbills.nyc\"\n  )+\n  theme_minimal()\n\nrs_over_time_graph",
    "crumbs": [
      "Learning R",
      "12. ggplot"
    ]
  },
  {
    "objectID": "12.ggplot.html#sample-bar-chart-faceting",
    "href": "12.ggplot.html#sample-bar-chart-faceting",
    "title": "12. ggplot",
    "section": "Sample Bar Chart + Faceting",
    "text": "Sample Bar Chart + Faceting\nLet’s make some bar charts out of the table of # of children by the languages they speak at home by borough.\nWe’ll learn how we pulled this data in an upcoming lesson, but for now just download this csv. Or run read_csv(\"https://raw.githubusercontent.com/pspauster/learning_R/master/langs_by_boro.csv\")\n\nlangs_by_boro_for_graphing &lt;- read_csv(\"langs_by_boro.csv\") %&gt;%\n  mutate(\n    labels = # Add a new column with neat category labels\n      case_when(\n        variable == 'englishkids' ~ 'English',\n        variable == 'spanishkids' ~ 'Spanish',\n        variable == 'indoeurkids' ~ 'Indo-European',\n        variable == 'apikids' ~ 'Asian & Pacific Islander',\n        variable == 'otherkids' ~ 'Other Languages'\n      ),\n    labels = fct_reorder(labels, estimate)\n  ) %&gt;% # Overwrite the variable column of langs_by_boro with a function that tells R to order the variable column by the estimate column when it gets plotted (like a sort). If I wanted it ordered in the other direction I would put estimate inside of desc().\n  filter(variable != 'totalkids')\n\nProduce a horizontal bar chart\n\n# Note - this builds progressively; you can run all the code before any + sign as a step toward the final result.\n\nbarchart &lt;- ggplot(langs_by_boro_for_graphing) +\n  aes(x = estimate, y = labels) +\n  geom_col() +\n  scale_x_continuous(labels = scales::comma) + # format count labels with commas and thousands\n  theme_minimal() +\n  theme(panel.grid.major.y = element_blank()) +\n  labs(\n    title = 'What languages do NYC kids speak at home?',\n    subtitle = 'Number of children ages 5-17 by the language spoken at home',\n    x = NULL,\n    y = NULL,\n    caption = \"Source: Census American Community Survey 2020 5-Year Estimates, Table B16007\"\n  )\n\nbarchart\n\n\n\n\n\n\n\n\nNow let’s facet it by borough\n\nbarchart +\n  facet_wrap( ~ name, ncol = 1)",
    "crumbs": [
      "Learning R",
      "12. ggplot"
    ]
  },
  {
    "objectID": "12.ggplot.html#additional-resources",
    "href": "12.ggplot.html#additional-resources",
    "title": "12. ggplot",
    "section": "Additional Resources",
    "text": "Additional Resources\nThis guide from the Urban Institute has a number of helpful tutorials for how to create a wide number of graphs with ggplot.",
    "crumbs": [
      "Learning R",
      "12. ggplot"
    ]
  },
  {
    "objectID": "8.groupby_summarize.html#why-summarize-data",
    "href": "8.groupby_summarize.html#why-summarize-data",
    "title": "8. Group By and Summarize",
    "section": "Why summarize data?",
    "text": "Why summarize data?\nHaving clean data is great, but when working with large datasets we are often looking for summary statistics to let us compare different groups. group_by and summarize, often used together in a pipe, are a powerful combo for generating statistics at the group level.\nSummarizing allows us to compare means, medians, or top values based on different categories. It can also be a helpful data cleaning tool, depending on the level of observations in the data.",
    "crumbs": [
      "Learning R",
      "8. Group By and Summarize"
    ]
  },
  {
    "objectID": "8.groupby_summarize.html#summarize",
    "href": "8.groupby_summarize.html#summarize",
    "title": "8. Group By and Summarize",
    "section": "Summarize",
    "text": "Summarize\nSummarize takes a data frame and a ... list of new variables to generate.\nLet’s grab our code to read in the clean dataframe again.\n\nfhv_clean &lt;- read_csv(file = \"For_Hire_Vehicles__FHV__-_Active.csv\") %&gt;% \n  clean_names() %&gt;% \n  rename(hybrid = veh)\n\nNote - summarize is different than summary - a helpful function that provides the basic stats of all variables - a good first step when looking at a new data set\n\nsummary(fhv_clean)\n\n    active          vehicle_license_number     name          \n Length:98318       Length:98318           Length:98318      \n Class :character   Class :character       Class :character  \n Mode  :character   Mode  :character       Mode  :character  \n                                                             \n                                                             \n                                                             \n license_type       expiration_date    permit_license_number\n Length:98318       Length:98318       Length:98318         \n Class :character   Class :character   Class :character     \n Mode  :character   Mode  :character   Mode  :character     \n                                                            \n                                                            \n                                                            \n dmv_license_plate_number vehicle_vin_number wheelchair_accessible\n Length:98318             Length:98318       Length:98318         \n Class :character         Class :character   Class :character     \n Mode  :character         Mode  :character   Mode  :character     \n                                                                  \n                                                                  \n                                                                  \n certification_date hack_up_date        vehicle_year  base_number       \n Length:98318       Length:98318       Min.   :1949   Length:98318      \n Class :character   Class :character   1st Qu.:2016   Class :character  \n Mode  :character   Mode  :character   Median :2018   Mode  :character  \n                                       Mean   :2018                     \n                                       3rd Qu.:2021                     \n                                       Max.   :5015                     \n  base_name          base_type            hybrid          base_telephone_number\n Length:98318       Length:98318       Length:98318       Length:98318         \n Class :character   Class :character   Class :character   Class :character     \n Mode  :character   Mode  :character   Mode  :character   Mode  :character     \n                                                                               \n                                                                               \n                                                                               \n   website          base_address          reason          order_date    \n Length:98318       Length:98318       Length:98318       Mode:logical  \n Class :character   Class :character   Class :character   NA's:98318    \n Mode  :character   Mode  :character   Mode  :character                 \n                                                                        \n                                                                        \n                                                                        \n last_date_updated  last_time_updated\n Length:98318       Length:98318     \n Class :character   Class1:hms       \n Mode  :character   Class2:difftime  \n                    Mode  :numeric   \n                                     \n                                     \n\n\nWith a basic application of summarize, we take all the rows of the dataframe and turn them into one row of data. Here we use mean() to get the average\n\nfhv_clean %&gt;% \n  summarize(average_year = mean(vehicle_year))\n\n# A tibble: 1 × 1\n  average_year\n         &lt;dbl&gt;\n1        2018.\n\n#careful - NAs are sticky so mean() will return NA if there are any missing values. Use na.rm = T to exclude missing in calculating the average\n\nfhv_clean %&gt;% \n  summarize(average_year = mean(vehicle_year, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  average_year\n         &lt;dbl&gt;\n1        2018.\n\n\nYou can summarize multiple variables (...) at once. Look at summarize documentation for the full list of operations you can summarize with.\n\nfhv_clean %&gt;% \n  summarize(total_cars = n(), #n() just counts the number of rows in the group\n            average_year = mean(vehicle_year, na.rm = TRUE),\n            median_year = median(vehicle_year, na.rm = T))\n\n# A tibble: 1 × 3\n  total_cars average_year median_year\n       &lt;int&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n1      98318        2018.        2018\n\n\nWhen using summarize it defaults to one big group - all the data is summarized. To summarize by group we can add group_by()",
    "crumbs": [
      "Learning R",
      "8. Group By and Summarize"
    ]
  },
  {
    "objectID": "8.groupby_summarize.html#group_by",
    "href": "8.groupby_summarize.html#group_by",
    "title": "8. Group By and Summarize",
    "section": "Group_by",
    "text": "Group_by\nWhere summarize becomes really powerful is pairing it with group_by\n\nfhv_clean %&gt;% \n  group_by(hybrid) %&gt;% \n  summarize(number_cars = n(),\n            mean_year = mean(vehicle_year, na.rm = T))\n\n# A tibble: 9 × 3\n  hybrid number_cars mean_year\n  &lt;chr&gt;        &lt;int&gt;     &lt;dbl&gt;\n1 BEV           2267     2022.\n2 CNG              1     2020 \n3 DSE              1     2019 \n4 HYB           3267     2019.\n5 N                1     2016 \n6 NON              1     2012 \n7 STR             33     2017.\n8 WAV           6016     2019.\n9 &lt;NA&gt;         86731     2018.\n\n\nOften we are grouping on variables of interest and summarizing across that variable. Take the variable we made last time, for example\n\nfhv_type_summary &lt;- fhv_clean %&gt;% \n  mutate(\n    ride_type = case_when(\n      base_name == \"UBER USA, LLC\" & base_type == \"BLACK-CAR\" ~ \"BLACK CAR RIDESHARE\",\n      base_name != \"UBER USA, LLC\" & base_type == \"BLACK-CAR\" ~ \"BLACK CAR NON-RIDESHARE\",\n      TRUE ~ base_type #if it doesn't meet either condition, return the base_type\n    )) %&gt;% \n  group_by(ride_type) %&gt;% #group by the variable we just created!\n  summarize(no_cars = n(),\n            average_year = mean(vehicle_year, na.rm = T))\n\nfhv_type_summary\n\n# A tibble: 4 × 3\n  ride_type               no_cars average_year\n  &lt;chr&gt;                     &lt;int&gt;        &lt;dbl&gt;\n1 BLACK CAR NON-RIDESHARE   16225        2018.\n2 BLACK CAR RIDESHARE       76710        2018.\n3 LIVERY                     3652        2015.\n4 LUXURY                     1731        2020.\n\n\nHere we can see some interesting trends start to emerge, like how the livery cars tend to be the oldest and the luxury cars tend to be newer.\nWe can also group_by multiple variables, or group by logical expressions.\n\nfhv_clean %&gt;% \n  group_by(hybrid, base_type) %&gt;% \n  summarize(total_cars = n())\n\n`summarise()` has grouped output by 'hybrid'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 18 × 3\n# Groups:   hybrid [9]\n   hybrid base_type total_cars\n   &lt;chr&gt;  &lt;chr&gt;          &lt;int&gt;\n 1 BEV    BLACK-CAR       2232\n 2 BEV    LIVERY            17\n 3 BEV    LUXURY            18\n 4 CNG    BLACK-CAR          1\n 5 DSE    BLACK-CAR          1\n 6 HYB    BLACK-CAR       3009\n 7 HYB    LIVERY           174\n 8 HYB    LUXURY            84\n 9 N      BLACK-CAR          1\n10 NON    BLACK-CAR          1\n11 STR    BLACK-CAR         18\n12 STR    LUXURY            15\n13 WAV    BLACK-CAR       5904\n14 WAV    LIVERY            96\n15 WAV    LUXURY            16\n16 &lt;NA&gt;   BLACK-CAR      81768\n17 &lt;NA&gt;   LIVERY          3365\n18 &lt;NA&gt;   LUXURY          1598\n\nfhv_clean %&gt;% \n  group_by(base_type, vehicle_year &gt;= 2000) %&gt;% \n  summarize(total_cars = n())\n\n`summarise()` has grouped output by 'base_type'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 4 × 3\n# Groups:   base_type [3]\n  base_type `vehicle_year &gt;= 2000` total_cars\n  &lt;chr&gt;     &lt;lgl&gt;                       &lt;int&gt;\n1 BLACK-CAR TRUE                        92935\n2 LIVERY    TRUE                         3652\n3 LUXURY    FALSE                           5\n4 LUXURY    TRUE                         1726",
    "crumbs": [
      "Learning R",
      "8. Group By and Summarize"
    ]
  },
  {
    "objectID": "8.groupby_summarize.html#group_by-with-mutate",
    "href": "8.groupby_summarize.html#group_by-with-mutate",
    "title": "8. Group By and Summarize",
    "section": "Group_by with mutate",
    "text": "Group_by with mutate\nPair group_by with mutate to create helpful summary level variables without reducing the number of rows in the dataset.\n\nfhv_clean %&gt;% \n  group_by(base_name) %&gt;% \n  mutate(total_by_name = n()) #variable with the total # of cars for each company name\n\n# A tibble: 98,318 × 24\n# Groups:   base_name [771]\n   active vehicle_license_number name               license_type expiration_date\n   &lt;chr&gt;  &lt;chr&gt;                  &lt;chr&gt;              &lt;chr&gt;        &lt;chr&gt;          \n 1 YES    5608977                AMERICAN,UNITED,T… FOR HIRE VE… 04/30/2025     \n 2 YES    5645622                RAMA,ILIR          FOR HIRE VE… 09/11/2023     \n 3 YES    5192507                ORDONEZ,ELIAS      FOR HIRE VE… 03/08/2025     \n 4 YES    5378856                RIVERA,ENMA        FOR HIRE VE… 11/12/2024     \n 5 YES    5852121                A/VA,SERVICE,CORP  FOR HIRE VE… 04/11/2024     \n 6 YES    5415237                REYES,JUAN,E       FOR HIRE VE… 10/31/2023     \n 7 YES    5643301                BEGUM,TAZMINUR     FOR HIRE VE… 09/30/2025     \n 8 YES    5701439                GONZALEZALVARADO,L FOR HIRE VE… 06/13/2024     \n 9 YES    5790931                GOMEZ,JOSE,A       FOR HIRE VE… 05/23/2025     \n10 YES    5743759                HOSSAIN,SM,KAMAL   FOR HIRE VE… 12/08/2024     \n# ℹ 98,308 more rows\n# ℹ 19 more variables: permit_license_number &lt;chr&gt;,\n#   dmv_license_plate_number &lt;chr&gt;, vehicle_vin_number &lt;chr&gt;,\n#   wheelchair_accessible &lt;chr&gt;, certification_date &lt;chr&gt;, hack_up_date &lt;chr&gt;,\n#   vehicle_year &lt;dbl&gt;, base_number &lt;chr&gt;, base_name &lt;chr&gt;, base_type &lt;chr&gt;,\n#   hybrid &lt;chr&gt;, base_telephone_number &lt;chr&gt;, website &lt;chr&gt;,\n#   base_address &lt;chr&gt;, reason &lt;chr&gt;, order_date &lt;lgl&gt;, …\n\n\nUse ungroup() to return to normal mutation operations\n\nfhv_clean %&gt;% \n  group_by(base_type) %&gt;% \n  mutate(mean_by_type = mean(vehicle_year, na.rm =T)) %&gt;% \n  ungroup() %&gt;% \n  mutate(above_below_mean = if_else(\n    condition = vehicle_year &gt; mean_by_type,\n    true = \"above mean\",\n    false = \"below mean\"\n  )) %&gt;% \n  count(above_below_mean)\n\n# A tibble: 2 × 2\n  above_below_mean     n\n  &lt;chr&gt;            &lt;int&gt;\n1 above mean       44530\n2 below mean       53788\n\n#this creates a variable to show if this car is above or below the average year for the group",
    "crumbs": [
      "Learning R",
      "8. Group By and Summarize"
    ]
  },
  {
    "objectID": "8.groupby_summarize.html#normalizing-with-groups",
    "href": "8.groupby_summarize.html#normalizing-with-groups",
    "title": "8. Group By and Summarize",
    "section": "Normalizing with Groups",
    "text": "Normalizing with Groups\nGroup by, summarize, and mutate are crucial when comparing geographic areas. You can use group_by to get the proportion within a certain group.\nHere’s a full example of how to normalize within a group, using the data on new york housing authority apartments by borough. We want to find the proportion of NYCHA apartments that are Section 8 (vouchers) in each borough.\n\nnycha &lt;- read_csv('https://data.cityofnewyork.us/resource/evjd-dqpz.csv') %&gt;%\n  clean_names()\n\n# Filter for developments that contain any Section 8 transition apartments\nsection8devs &lt;- nycha %&gt;%\n  filter(number_of_section_8_transition_apartments &gt; 0)\n\n# Get some stats on number of section 8 apts across all developments by borough\nsection8devs_by_boro &lt;- section8devs %&gt;%\n  group_by(borough) %&gt;%\n  summarize(section8apts = sum(number_of_section_8_transition_apartments),\n            totalapts = sum(total_number_of_apartments),\n            median_section8apts = median(number_of_section_8_transition_apartments),\n            avg_section8apts = mean(number_of_section_8_transition_apartments)) \n\n# Is this all the info we need? What's missing? (Normalization)\n\n# Section 8 units as a share of all units in mixed finance developments, by borough\nsection8devs_grouped &lt;- section8devs %&gt;%\n  group_by(borough) %&gt;%\n  summarize(total_s8_apts = sum(number_of_section_8_transition_apartments),\n            total_apts = sum(total_number_of_apartments))%&gt;%\n  mutate(s8_share = total_s8_apts / total_apts)\n\n# Section 8 units as a share of all NYCHA units, by borough\nnycha_grouped &lt;- nycha %&gt;%\n  group_by(borough) %&gt;%\n  summarize(total_s8_apts = sum(number_of_section_8_transition_apartments, na.rm=TRUE),\n            total_apts = sum(total_number_of_apartments, na.rm=TRUE))%&gt;%\n  mutate(s8_share = total_s8_apts / total_apts)",
    "crumbs": [
      "Learning R",
      "8. Group By and Summarize"
    ]
  },
  {
    "objectID": "13.stringr.html#what-is-a-string",
    "href": "13.stringr.html#what-is-a-string",
    "title": "13. Working with Strings",
    "section": "What is a string?",
    "text": "What is a string?\nStrings are groups of characters. They can form words, sentences, addresses, categories, or represent other data. Working with strings is going to be essential to cleaning data. Often times we get string and character data that is manually inputted and messy. We can use string modifiers to clean it up. Think of address data for example. What if addresses are misspelled or inconsistent in how they refer to street names?\nIn this lesson we’ll learn a number of useful functions for manipulating and rewriting strings, using some base R, tidyverse, and a package called stringr.",
    "crumbs": [
      "Learning R",
      "13. Working with Strings"
    ]
  },
  {
    "objectID": "13.stringr.html#separate-paste",
    "href": "13.stringr.html#separate-paste",
    "title": "13. Working with Strings",
    "section": "Separate & Paste",
    "text": "Separate & Paste\nLet’s read in a clean dataframe for film permits from the open data portal.\n\nlibrary(tidyverse)\nlibrary(janitor)\n\nfilmpermits &lt;- read_csv(\"Film_Permits.csv\", \n                        col_types = cols(EventID = col_character())) %&gt;%\n  clean_names()\n\nWe can use separate() to split up long string columns and paste() to concatenate strings into new columns\n\nstreet_closures &lt;- filmpermits %&gt;% \n  separate_rows(parking_held, sep = \",\") %&gt;% #this makes a new row for each street closure listed\n  separate(parking_held, into = c(\"street\", \"cross_street1\", \"cross_street2\"), sep = \"between|and\") %&gt;% #this separates the string into three different columns\n  mutate_at(.vars = c(\"street\", \"cross_street1\", \"cross_street2\", \"borough\", \"country\"), .funs = ~tolower(.)) %&gt;% # a .fns argument takes a function like tolower, which makes all the characters lowercase. start the function with ~ and subsitite . for the argument of the nested function\n  mutate(intersection1_address = paste(street, \"and\", cross_street1, borough, country), #paste concatenates strings to create, in this case an address of an intersection\n         intersection2_address = paste(street, \"and\", cross_street1, borough, country))",
    "crumbs": [
      "Learning R",
      "13. Working with Strings"
    ]
  },
  {
    "objectID": "13.stringr.html#stringr",
    "href": "13.stringr.html#stringr",
    "title": "13. Working with Strings",
    "section": "StringR",
    "text": "StringR\nStringR is a package with a number of handy functions. All of them take a string as the first argument, and return the result of your inquiry. There’s tons of possibilities and uses, here’s few examples.\n\n\nThe spacing for the strings in the street columns is weird, I can use str_trim to get rid of white space\n\nlibrary(stringr)\n\nstreet_closures %&gt;% head() %&gt;% .$street #here I am just printing the first 10 rows of the variable street\n\n[1] \"commerce street \"   \"  seabring street \" \"amsterdam avenue \" \n[4] \"eagle street \"      \"  west street \"     \"  freeman street \" \n\nstreet_closures %&gt;% \n  mutate(street = str_trim(street, side = \"both\")) %&gt;% \n  head() %&gt;% #here I am just printing the first 10 rows of the variable street that I overwrote\n  .$street\n\n[1] \"commerce street\"  \"seabring street\"  \"amsterdam avenue\" \"eagle street\"    \n[5] \"west street\"      \"freeman street\"  \n\n\nOr perhaps I want to know the total closures on 14th street, but I don’t care if it’s West 14th street or East 14th street, or I’m worried that sometimes it’s in the data as “street” and other times as “st” - making it hard to do an exact match. str_detect finds matches of certain patterns. We can pair it with conditional logic to create a variable that flags if the closure was on the street we care about.\n\nstreet_closures %&gt;% \n  filter(borough == \"manhattan\") %&gt;% \n  mutate(fourteenth_street = if_else(str_detect(street, \"14 |14th\"), T, F)) %&gt;% #use these with conditional logic!\n  count(fourteenth_street) #count how many times!\n\n# A tibble: 2 × 2\n  fourteenth_street     n\n  &lt;lgl&gt;             &lt;int&gt;\n1 FALSE              5110\n2 TRUE                 17\n\n\nOr use stringr to change data entry inconsistencies!\n\nstreet_replace &lt;- street_closures %&gt;% \n  mutate(street = str_replace(street, \"14 \", \"14th\")) \n\nWriting regular expressions, the complex notation you can use to return parts of strings is a great example of something you can use AI for!\n\n\n# Define the regular expression pattern\npattern &lt;- \"^(.*?)(?=\\\\b(?:street|boulevard|avenue|st|blvd|ave|rd|road|circle|cr)\\\\b)\"\n\n# Use str_match to extract the matched part\nstr_extract(head(street_closures)$street, pattern)\n\n[1] \"commerce \"   \"  seabring \" \"amsterdam \"  \"eagle \"      \"  west \"    \n[6] \"  freeman \"",
    "crumbs": [
      "Learning R",
      "13. Working with Strings"
    ]
  },
  {
    "objectID": "4.readingdata_datatypes.html#reading-data",
    "href": "4.readingdata_datatypes.html#reading-data",
    "title": "4. Reading Data and Data Types",
    "section": "Reading Data",
    "text": "Reading Data\nWe can use R to read in a number of different types of data, manipulate it, and output it in different ways.\nThe core type of data we will be using in this class is the .csv or a comma separated values file. A .csv is a text file where each observation is in its own row and each variable or value is, you guessed it, separated by a comma. R can read these types of files in super easily. Let’s download our first comma separated file from the NYC Open Data Portal.\n\nLet’s download the data on for hire vehicles in NYC and read it into R.\n\nIf we open a csv in a text editor it looks like this, but R will read it into something called a dataframe which is the tidy format for tabular data (data that has rows and columns).\nTo read data into R, we are going to need the function read_csv() and need to learn about file paths.\nIn order for R to read in the file, we need to tell R where the file is. We can do that with an absolute or a local path. An absolute path is the exact location of the file on your computer. For me, when I downloaded this file it went to my downloads folder - a path that looks something like this: /Users/patrickspauster/Downloads/For_Hire_Vehicles__FHV__-_Active.csv. You can look up the path to a file by navigating to the file in finder or windows explorer and right clicking to “Get Info”. I could read it in by using read_csv(\"/Users/patrickspauster/Downloads/For_Hire_Vehicles__FHV__-_Active.csv\").\nBut, not everyone who views my work or wants to run my code will have the same file structure on their computer. If i sent this code to someone and they tried to run it, they would get an error. That’s where the R project and a local path comes in handy.\nNow, save a copy of For_Hire_Vehicles__FHV__-_Active.csv to your project folder. When you do, you should see it appear in the file explorer in the bottom right of your R Studio window. Now we can access the .csv using a local path. Because we have the R project open, R will start looking in the project folder. Now we can run read_csv on our file without having to look up the path.\n(remember to load the tidyverse first! If you get an error like “the function function_name can’t be found”, you probably forgot to load the proper package with library()!)\n\nlibrary(tidyverse)\n\n\nread_csv(\"For_Hire_Vehicles__FHV__-_Active.csv\")\n\nRows: 98318 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (20): Active, Vehicle License Number, Name, License Type, Expiration Da...\ndbl   (1): Vehicle Year\nlgl   (1): Order Date\ntime  (1): Last Time Updated\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 98,318 × 23\n   Active `Vehicle License Number` Name         `License Type` `Expiration Date`\n   &lt;chr&gt;  &lt;chr&gt;                    &lt;chr&gt;        &lt;chr&gt;          &lt;chr&gt;            \n 1 YES    5608977                  AMERICAN,UN… FOR HIRE VEHI… 04/30/2025       \n 2 YES    5645622                  RAMA,ILIR    FOR HIRE VEHI… 09/11/2023       \n 3 YES    5192507                  ORDONEZ,ELI… FOR HIRE VEHI… 03/08/2025       \n 4 YES    5378856                  RIVERA,ENMA  FOR HIRE VEHI… 11/12/2024       \n 5 YES    5852121                  A/VA,SERVIC… FOR HIRE VEHI… 04/11/2024       \n 6 YES    5415237                  REYES,JUAN,E FOR HIRE VEHI… 10/31/2023       \n 7 YES    5643301                  BEGUM,TAZMI… FOR HIRE VEHI… 09/30/2025       \n 8 YES    5701439                  GONZALEZALV… FOR HIRE VEHI… 06/13/2024       \n 9 YES    5790931                  GOMEZ,JOSE,A FOR HIRE VEHI… 05/23/2025       \n10 YES    5743759                  HOSSAIN,SM,… FOR HIRE VEHI… 12/08/2024       \n# ℹ 98,308 more rows\n# ℹ 18 more variables: `Permit License Number` &lt;chr&gt;,\n#   `DMV License Plate Number` &lt;chr&gt;, `Vehicle VIN Number` &lt;chr&gt;,\n#   `Wheelchair Accessible` &lt;chr&gt;, `Certification Date` &lt;chr&gt;,\n#   `Hack Up Date` &lt;chr&gt;, `Vehicle Year` &lt;dbl&gt;, `Base Number` &lt;chr&gt;,\n#   `Base Name` &lt;chr&gt;, `Base Type` &lt;chr&gt;, VEH &lt;chr&gt;,\n#   `Base Telephone Number` &lt;chr&gt;, Website &lt;chr&gt;, `Base Address` &lt;chr&gt;, …\n\n\nLet’s take a closer look at what read_csv() is doing.\n\n?read_csv()\n\nThe function has one required argument, “file” and several optional arguments that we can change. The “file” argument asks for a path to a file as a “string” - remember if you see the words “character” or “string” think quotes. So let’s feed read_csv() the name of the file we want to read in in quotes, and assign it to something using our assignment operator &lt;- so we can further modify it.\n\nfhv &lt;- read_csv(file = \"For_Hire_Vehicles__FHV__-_Active.csv\")\n\n(Aside - naming things is hard, and you will have to name a lot of different objects. Some general rules - don’t use spaces, and try to keep the names simple but informative, and be careful about overwriting the same name)\nNow, fhv is an object in our environment. R gives us some helpful details about the object in the environment menu and the dropdown arrow on the object itself.\n\nR tells us how many observations (rows) and variables (columns) this object has - note how this is a “tidy” dataset. If you hover over the object itself, it will tell you the type of object and its size. In this case we have a dataframe, the tidy format for data in R, often abbreviated df. You can confirm this by running the function is.data.frame() which identifies if an object is of a certain type.\n\nis.data.frame(fhv)\n\n[1] TRUE",
    "crumbs": [
      "Learning R",
      "4. Reading Data and Data Types"
    ]
  },
  {
    "objectID": "4.readingdata_datatypes.html#reading-different-types-of-data",
    "href": "4.readingdata_datatypes.html#reading-different-types-of-data",
    "title": "4. Reading Data and Data Types",
    "section": "Reading different types of data",
    "text": "Reading different types of data\nread_csv() is smart, but not perfect. You’ll notice that it has tried to identify the types of data in this dataframe. The Vehicle Year is read in as a num because it is made up of all digits. It correctly identified that Last Time Updated is a Date in the format hms (hours:minutes:seconds). And the DMV License Plate Number is a chr (character), because it is a categorical string variable.\nNumbers, characters, and dates, are three fundamental types of data that we will be using in R. We can use some of the other arguments of read_csv() to make sure that we get columns in the correct format. For example, it missed that Expiration Date should be a date.\nWhen you start getting long arguments, and nested functions, it can be helpful to enter between each argument.\n\nfhv &lt;- read_csv(file = \"For_Hire_Vehicles__FHV__-_Active.csv\",\n                col_types = cols(`Expiration Date` = col_datetime(format = '%m/%d/%Y'))\n                               )\n\n#col types takes one argument - cols. cols() is a named list with the variable = the column's format.\n#we'll learn more about how to parse dates and date data types in lesson 12\n\nBe careful with numeric data types that aren’t actually numbers that will drop leading zeroes (think of a zip code like “06810” which starts with a 0 would get read in as an integer 6,810). If you wanted to match to another dataset with a zipcode you wouldn’t be able to! Another helpful note: you can change the default col_type using col_type = cols(.default = col_character()). You can always change the types of columns back to numbers later.",
    "crumbs": [
      "Learning R",
      "4. Reading Data and Data Types"
    ]
  },
  {
    "objectID": "4.readingdata_datatypes.html#more-data-types",
    "href": "4.readingdata_datatypes.html#more-data-types",
    "title": "4. Reading Data and Data Types",
    "section": "More data types",
    "text": "More data types\nHere’s a brief look at some other object types you might find in R.\nA value is just one number, stored in an object.\n\nmy_value &lt;- 42\nmy_value\n\n[1] 42\n\n\nA list is a group of values put together, separated by commas. In R the syntax to create a list starts with c(). They are also called vectors in R.\n\nmy_character_vector &lt;- c(\"Patrick\", \"Lucy\", \"Henry\", \"Ceinna\")\nmy_character_vector\n\n[1] \"Patrick\" \"Lucy\"    \"Henry\"   \"Ceinna\" \n\nmy_numeric_vector &lt;- c(1, 3, 5, 7, 9, 11, 13, 17)\nmy_numeric_vector\n\n[1]  1  3  5  7  9 11 13 17\n\n\nVectors can be named or unnamed. Named vectors are pairs of keys (names) and values separated by =.\n\nnamed_vector &lt;- c(\"Patrick\" = 42, \"Lucy\" = 12, \"Ceinna\" = 56, \"Henry\" = 44)\n\nnamed_vector\n\nPatrick    Lucy  Ceinna   Henry \n     42      12      56      44 \n\n\nYou can get a vector of a particular variable in a dataframe by using $ with the dataframe name and the variable name.\n\nprintme &lt;- head(fhv)\n\nprintme$`Base Name`\n\n[1] \"UBER USA, LLC\"               \"UBER USA, LLC\"              \n[3] \"UBER USA, LLC\"               \"BELL LX INC\"                \n[5] \"BAYRIDGE EXPRESS LUXYRY INC\" \"FIRST CLASS C/L SVC CORP\"   \n\n#head() only keeps the first few rows of a dataframe\n\nYou’ll also notice an important type of data - missing data - noted in R as NA. In this dataset the Wheelchair Accessible column is missing for the first few observations. This means that there is no value for that observation and variable. NA values in R are sticky, meaning that unless you tell R to ignore them, R will carry them through all your operations and maybe mess up some of your calculations. For example…\n\n1 + 2 + NA\n\n[1] NA\n\nsum(1,2,NA) #you should be able to figure this out based on what we've learned about functions so far!\n\n[1] NA\n\nsum(1,2,NA, na.rm = TRUE) #the na.rm = T argument removes NAs from a calculation.\n\n[1] 3",
    "crumbs": [
      "Learning R",
      "4. Reading Data and Data Types"
    ]
  },
  {
    "objectID": "14.lubridate.html#dates-are-tricky",
    "href": "14.lubridate.html#dates-are-tricky",
    "title": "14. Working with Dates",
    "section": "Dates are tricky",
    "text": "Dates are tricky\nDates can be annoying to work with because they come in many formats…\n\n08/31/2023\n08-31-2023\n08/31/23 01:30:36\n08-31-2023 12:36 PM\n\nBut R has some helpful tools that standardize dates and allow us to use them in calculations\nTo begin, we’re going to grab a dataset from the NYC Open Data Portal, download it as a .csv, and save it to our project.\n\nlibrary(tidyverse)\nlibrary(janitor)\nfilmpermits &lt;- read_csv(\"Film_Permits.csv\", \n                        col_types = cols(EventID = col_character())) %&gt;%\n  clean_names()\n\nLet’s clean it and do some summarizing\n\nfilmpermits_clean &lt;- filmpermits %&gt;% \n  select(event_type, borough, category, sub_category_name, start_date_time, end_date_time) %&gt;%\n  filter(category != \"WEB\") %&gt;%\n  mutate(type = \n           case_when(category == 'Documentary' ~ 'Film',\n                     category == 'Film' ~ 'Film', \n                     category == 'Television' ~ 'Television',\n                     category == 'Commerical' ~ 'Commercial',\n                     TRUE ~ 'Other'))",
    "crumbs": [
      "Learning R",
      "14. Working with Dates"
    ]
  },
  {
    "objectID": "14.lubridate.html#working-with-dates",
    "href": "14.lubridate.html#working-with-dates",
    "title": "14. Working with Dates",
    "section": "Working with dates",
    "text": "Working with dates\nWe’re going to install the lubridate package and load it. Some core R packages have helpful cheatsheets like this one. With our core knowledge of how functions work we should be able to apply these to our work!.\nWe can use lubridate to work with dates that come in various formats. With the film permits dataset we can run the below to make R recognize these fields as dates. Here’s a lubridate cheat sheet: https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_lubridate.pdf\n\n\n\nlibrary(lubridate)\n\nfilmpermits_clean_dates &lt;- filmpermits_clean %&gt;% \n  mutate(start_date_time = mdy_hms(start_date_time),\n         end_date_time = mdy_hms(end_date_time))\n\n# Let's see what the earliest start date in the dataset is. This will run in the console. \nfilmpermits_clean_dates %&gt;% arrange(start_date_time)\n\n# A tibble: 2,597 × 7\n   event_type             borough category sub_category_name start_date_time    \n   &lt;chr&gt;                  &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;             &lt;dttm&gt;             \n 1 Theater Load in and L… Manhat… Theater  Theater           2023-01-01 00:01:00\n 2 Theater Load in and L… Manhat… Theater  Theater           2023-01-01 00:01:00\n 3 Shooting Permit        Manhat… Televis… News              2023-01-01 04:00:00\n 4 Shooting Permit        Manhat… Televis… News              2023-01-02 04:00:00\n 5 Theater Load in and L… Brookl… Theater  Theater           2023-01-03 07:00:00\n 6 Shooting Permit        Queens  Televis… Episodic series   2023-01-03 07:00:00\n 7 Shooting Permit        Brookl… Televis… Episodic series   2023-01-03 10:00:00\n 8 Rigging Permit         Manhat… Documen… Not Applicable    2023-01-03 17:00:00\n 9 Shooting Permit        Manhat… Televis… Morning Show      2023-01-04 05:00:00\n10 Shooting Permit        Manhat… Documen… Not Applicable    2023-01-04 06:00:00\n# ℹ 2,587 more rows\n# ℹ 2 more variables: end_date_time &lt;dttm&gt;, type &lt;chr&gt;\n\n# Let's see what the latest start date in the dataset is. \nfilmpermits_clean_dates %&gt;% arrange(desc(start_date_time))\n\n# A tibble: 2,597 × 7\n   event_type             borough category sub_category_name start_date_time    \n   &lt;chr&gt;                  &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;             &lt;dttm&gt;             \n 1 Shooting Permit        Manhat… Film     Feature           2023-06-01 09:00:00\n 2 Shooting Permit        Manhat… Televis… News              2023-06-01 09:00:00\n 3 Shooting Permit        Queens  Film     Feature           2023-06-01 08:00:00\n 4 Shooting Permit        Bronx   Televis… Episodic series   2023-06-01 07:00:00\n 5 Shooting Permit        Manhat… Televis… Episodic series   2023-06-01 07:00:00\n 6 Shooting Permit        Queens  Televis… Episodic series   2023-06-01 07:00:00\n 7 Shooting Permit        Manhat… Commerc… Commercial        2023-06-01 06:00:00\n 8 Shooting Permit        Manhat… Still P… Not Applicable    2023-06-01 06:00:00\n 9 Shooting Permit        Brookl… Televis… Episodic series   2023-06-01 05:00:00\n10 Theater Load in and L… Manhat… Theater  Theater           2023-06-01 01:00:00\n# ℹ 2,587 more rows\n# ℹ 2 more variables: end_date_time &lt;dttm&gt;, type &lt;chr&gt;\n\n\nLet’s use lubridate to make a list of all the film permits active just this summer. When sending R a date in a logical condition, wrap it in as.Date() so R knows its a date not a string. R & Lubridate defaults to the 'YYYY-MM-DD' format.\n\nfilmpermits_summer23 &lt;- filmpermits_clean_dates %&gt;%\n  filter(end_date_time &gt;= as.Date('2023-06-01') & start_date_time &lt;= as.Date('2023-08-31'))\n\n# Now I can run the same analysis as above and see if the % breakdowns are any different. \n\nfilmpermits_summer23_grouped &lt;- filmpermits_summer23 %&gt;% \n  group_by(type) %&gt;%\n  summarize(num_permits = n()) %&gt;%\n  mutate(share = num_permits / sum(num_permits)) %&gt;%\n  arrange(desc(share))\n\nfilmpermits_summer23_grouped\n\n# A tibble: 3 × 3\n  type       num_permits  share\n  &lt;chr&gt;            &lt;int&gt;  &lt;dbl&gt;\n1 Other               16 0.667 \n2 Television           6 0.25  \n3 Film                 2 0.0833",
    "crumbs": [
      "Learning R",
      "14. Working with Dates"
    ]
  },
  {
    "objectID": "3.packages_functions.html#packages",
    "href": "3.packages_functions.html#packages",
    "title": "3. Packages and Functions",
    "section": "Packages",
    "text": "Packages\nR is a base programming language. We access R through a library of different packages. Packages are downloadable content that we use in R to modify data. Packages are made up of functions, which we use to modify and analyze data.\nBase R has a number of functions, packages, and data already installed, which we can preview by putting code in our console.\nTake the iris dataset for example, which we can access by simply typing iris\n\nhead(iris) #head just limits the output to the first few rows of a dataset. put \"iris\" into your console to see the whole dataset\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\nTo get started with R, we need to install packages beyond the preinstalled.\nWe install packages with a console command, using a function called install.packages(). We can get our first, and most crucial package, the tidyverse, using this function. Copy this into your console. Make sure to put the package name in quotes.\n\n#install.packages(\"tidyverse\") #remove the # at the front to actually get this to run\n\nWe can install multiple packages at once by putting them into a list (also called a vector), like so. More on lists later.\n\nFinally we need to load packages at the beginning of our .R script in order to use them. The library() function loads functions that we have installed. Note that we only need to install packages once, so we use the command line. But we need to load packages with library each time we use them, so we put that in our .R script.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "Learning R",
      "3. Packages and Functions"
    ]
  },
  {
    "objectID": "3.packages_functions.html#functions",
    "href": "3.packages_functions.html#functions",
    "title": "3. Packages and Functions",
    "section": "Functions",
    "text": "Functions\nSo how do these functions we’ve been using work?\nEach function has a name and arguments. The name of a function tells R the operation we want to do. The arguments are the inputs for the function, or what we want to transform, separated by commas.\nYou can look up any R function by typing the function name into the console, preceded by a ?.\n\n?install.packages()\n\nWhen we look at the first function we used, install.packages() the help menu pops up in the bottom right, describing the function, the arguments, and giving us examples. The first argument is called pkgs and it’s defined as “character vector of the names of the packages whose current versions should be downloaded from the repositories.” That first argument is required. Without it install.packages() won’t know which package to install.\nNote that the argument here, the name of the package, is in quotes. In programming, quotes define character objects. In this case the function requires a character input, so we use quotes. More on this later when we talk about data types.\nArguments in R can be named or ordered. Naming an argument means adding the name of the argument, followed by = and then the value of the argument. Unnamed arguments rely on the programmer to put each argument in the proper order, separated by commas. In this case, pkgs is the first argument. So install.packages(pkgs = \"tidyverse\") and install.packages(\"tidyverse\") do the same thing. When you are getting started programming, it’s good practice to name your arguments.",
    "crumbs": [
      "Learning R",
      "3. Packages and Functions"
    ]
  },
  {
    "objectID": "3.packages_functions.html#tidy-data",
    "href": "3.packages_functions.html#tidy-data",
    "title": "3. Packages and Functions",
    "section": "Tidy Data",
    "text": "Tidy Data\nOur first package, the tidyverse features a number of functions that help keep our data organized in a way that a computer can read, understand, and transform it. The tidyverse uses a principle of tidy data, a standard way of mapping the meaning of a dataset to its structure. In tidy data…\n\nEvery column is a variable.\nEvery row is an observation.\nEvery cell is a single value.\n\nNext time we’ll learn how to read in data, keep it tidy, and get our observations in the right data types.\nTake a second look at iris to see an example of a tidy dataset. There’s one row (observation) for each flower in the sample, a column for each variable (measurements and species) and one value in each cell, the value of that variable for that observation.",
    "crumbs": [
      "Learning R",
      "3. Packages and Functions"
    ]
  },
  {
    "objectID": "18.qgis_setup.html#setting-up-your-first-qgis-project",
    "href": "18.qgis_setup.html#setting-up-your-first-qgis-project",
    "title": "18. Setting up your first QGIS project",
    "section": "Setting up your first QGIS project",
    "text": "Setting up your first QGIS project\nIn this tutorial: download shapefiles from the NYC Open Data Portal, open QGIS, save a QGIS project, and orient to the QGIS interface\nDownload the latest Long Term Version of QGIS here.\nThe most common issue with installing QGIS is for Mac users the first time you open up the program. You’ll often see an error message that says “QGIS” can’t be opened because Apple cannot check it for malicious software.\nYou don’t need to worry about this message; QGIS is trustworthy. If this happens, locate QGIS in Finder and right-click, then Open from that menu. That should resolve the problem.",
    "crumbs": [
      "QGIS",
      "18. Setting up your first QGIS project"
    ]
  },
  {
    "objectID": "18.qgis_setup.html#data-downloads",
    "href": "18.qgis_setup.html#data-downloads",
    "title": "18. Setting up your first QGIS project",
    "section": "Data downloads",
    "text": "Data downloads\nBorough boundaries\nNYC subway stations (Note - the subways dataset appears to have been removed from the NYC Open Data Portal since I made this video, but you can download an old saved version using that link.)",
    "crumbs": [
      "QGIS",
      "18. Setting up your first QGIS project"
    ]
  },
  {
    "objectID": "7.mutate.html#mutate",
    "href": "7.mutate.html#mutate",
    "title": "7. Mutate",
    "section": "Mutate",
    "text": "Mutate\nMutate is an incredibly powerful tool to create new columns and new variables.\nLet’s grab our code to read in the clean dataframe\n\nfhv_clean &lt;- read_csv(file = \"For_Hire_Vehicles__FHV__-_Active.csv\") %&gt;% \n  clean_names() %&gt;% \n  rename(hybrid = veh)\n\nWe create a new column with mutate by setting the name of our new column and a new value\n\nfhv_clean %&gt;% \n  mutate(city = \"New York City\")\n\n# A tibble: 98,318 × 24\n   active vehicle_license_number name               license_type expiration_date\n   &lt;chr&gt;  &lt;chr&gt;                  &lt;chr&gt;              &lt;chr&gt;        &lt;chr&gt;          \n 1 YES    5608977                AMERICAN,UNITED,T… FOR HIRE VE… 04/30/2025     \n 2 YES    5645622                RAMA,ILIR          FOR HIRE VE… 09/11/2023     \n 3 YES    5192507                ORDONEZ,ELIAS      FOR HIRE VE… 03/08/2025     \n 4 YES    5378856                RIVERA,ENMA        FOR HIRE VE… 11/12/2024     \n 5 YES    5852121                A/VA,SERVICE,CORP  FOR HIRE VE… 04/11/2024     \n 6 YES    5415237                REYES,JUAN,E       FOR HIRE VE… 10/31/2023     \n 7 YES    5643301                BEGUM,TAZMINUR     FOR HIRE VE… 09/30/2025     \n 8 YES    5701439                GONZALEZALVARADO,L FOR HIRE VE… 06/13/2024     \n 9 YES    5790931                GOMEZ,JOSE,A       FOR HIRE VE… 05/23/2025     \n10 YES    5743759                HOSSAIN,SM,KAMAL   FOR HIRE VE… 12/08/2024     \n# ℹ 98,308 more rows\n# ℹ 19 more variables: permit_license_number &lt;chr&gt;,\n#   dmv_license_plate_number &lt;chr&gt;, vehicle_vin_number &lt;chr&gt;,\n#   wheelchair_accessible &lt;chr&gt;, certification_date &lt;chr&gt;, hack_up_date &lt;chr&gt;,\n#   vehicle_year &lt;dbl&gt;, base_number &lt;chr&gt;, base_name &lt;chr&gt;, base_type &lt;chr&gt;,\n#   hybrid &lt;chr&gt;, base_telephone_number &lt;chr&gt;, website &lt;chr&gt;,\n#   base_address &lt;chr&gt;, reason &lt;chr&gt;, order_date &lt;lgl&gt;, …\n\n\nYou can create multiple new columns (...) at once\n\nfhv_clean %&gt;% \n  mutate(city = \"New York City\",\n         active = TRUE) #I can overwrite column names too. I've made this active column boolean (true or false)\n\n# A tibble: 98,318 × 24\n   active vehicle_license_number name               license_type expiration_date\n   &lt;lgl&gt;  &lt;chr&gt;                  &lt;chr&gt;              &lt;chr&gt;        &lt;chr&gt;          \n 1 TRUE   5608977                AMERICAN,UNITED,T… FOR HIRE VE… 04/30/2025     \n 2 TRUE   5645622                RAMA,ILIR          FOR HIRE VE… 09/11/2023     \n 3 TRUE   5192507                ORDONEZ,ELIAS      FOR HIRE VE… 03/08/2025     \n 4 TRUE   5378856                RIVERA,ENMA        FOR HIRE VE… 11/12/2024     \n 5 TRUE   5852121                A/VA,SERVICE,CORP  FOR HIRE VE… 04/11/2024     \n 6 TRUE   5415237                REYES,JUAN,E       FOR HIRE VE… 10/31/2023     \n 7 TRUE   5643301                BEGUM,TAZMINUR     FOR HIRE VE… 09/30/2025     \n 8 TRUE   5701439                GONZALEZALVARADO,L FOR HIRE VE… 06/13/2024     \n 9 TRUE   5790931                GOMEZ,JOSE,A       FOR HIRE VE… 05/23/2025     \n10 TRUE   5743759                HOSSAIN,SM,KAMAL   FOR HIRE VE… 12/08/2024     \n# ℹ 98,308 more rows\n# ℹ 19 more variables: permit_license_number &lt;chr&gt;,\n#   dmv_license_plate_number &lt;chr&gt;, vehicle_vin_number &lt;chr&gt;,\n#   wheelchair_accessible &lt;chr&gt;, certification_date &lt;chr&gt;, hack_up_date &lt;chr&gt;,\n#   vehicle_year &lt;dbl&gt;, base_number &lt;chr&gt;, base_name &lt;chr&gt;, base_type &lt;chr&gt;,\n#   hybrid &lt;chr&gt;, base_telephone_number &lt;chr&gt;, website &lt;chr&gt;,\n#   base_address &lt;chr&gt;, reason &lt;chr&gt;, order_date &lt;lgl&gt;, …",
    "crumbs": [
      "Learning R",
      "7. Mutate"
    ]
  },
  {
    "objectID": "7.mutate.html#mutate-with-logical-expressions",
    "href": "7.mutate.html#mutate-with-logical-expressions",
    "title": "7. Mutate",
    "section": "Mutate with logical expressions",
    "text": "Mutate with logical expressions\nWhere mutate gets powerful is when you use it with logical expressions. Here we use if_else()\n\nfhv_rideshare &lt;- fhv_clean %&gt;% \n  mutate(rideshare = if_else(\n    condition = base_name == \"UBER USA, LLC\",\n    true = \"rideshare\",\n    false = \"limo\"\n  )) #if it's an uber call it rideshare, if its a limo call it something else\n#notice I named the arguments here! A good practice when the argument is not ...\n\nTabulate the variable we made with the count() funtion\n\nfhv_rideshare %&gt;% \n  count(rideshare)\n\n# A tibble: 2 × 2\n  rideshare     n\n  &lt;chr&gt;     &lt;int&gt;\n1 limo      21608\n2 rideshare 76710\n\n\nWhat if we have more than one logical expression we care about? Check out case_when.\n\nfhv_blackcar &lt;- fhv_clean %&gt;% \n  mutate(\n    ride_type = case_when(\n      base_name == \"UBER USA, LLC\" & base_type == \"BLACK-CAR\" ~ \"BLACK CAR RIDESHARE\",\n      base_name != \"UBER USA, LLC\" & base_type == \"BLACK-CAR\" ~ \"BLACK CAR NON-RIDESHARE\",\n      TRUE ~ base_type #if it doesn't meet either condition, return the base_type\n    ))\n\nUse & and | for and and or logical expressions with multiple conditions\n\nfhv_blackcar %&gt;% \n  count(ride_type)#now we have four categories!\n\n# A tibble: 4 × 2\n  ride_type                   n\n  &lt;chr&gt;                   &lt;int&gt;\n1 BLACK CAR NON-RIDESHARE 16225\n2 BLACK CAR RIDESHARE     76710\n3 LIVERY                   3652\n4 LUXURY                   1731",
    "crumbs": [
      "Learning R",
      "7. Mutate"
    ]
  },
  {
    "objectID": "7.mutate.html#normalizing-with-mutate",
    "href": "7.mutate.html#normalizing-with-mutate",
    "title": "7. Mutate",
    "section": "Normalizing with Mutate",
    "text": "Normalizing with Mutate\nYou can use statistical functions like mean to normalize data with mutate. mean will return the average of all the vehicle years. You can use mutate to generate a new variable that takes the distance from each observation to the mean.\n\nfhv_clean %&gt;% \n  mutate(year_norm = vehicle_year/mean(vehicle_year, na.rm = T),\n         year_pct = percent_rank(vehicle_year)) %&gt;% \n  select(vehicle_license_number, vehicle_year, year_norm, year_pct)\n\n# A tibble: 98,318 × 4\n   vehicle_license_number vehicle_year year_norm year_pct\n   &lt;chr&gt;                         &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 5608977                        2015     0.998   0.120 \n 2 5645622                        2022     1.00    0.797 \n 3 5192507                        2016     0.999   0.212 \n 4 5378856                        2018     1.00    0.440 \n 5 5852121                        2019     1.00    0.552 \n 6 5415237                        2012     0.997   0.0225\n 7 5643301                        2015     0.998   0.120 \n 8 5701439                        2016     0.999   0.212 \n 9 5790931                        2017     0.999   0.313 \n10 5743759                        2021     1.00    0.714 \n# ℹ 98,308 more rows",
    "crumbs": [
      "Learning R",
      "7. Mutate"
    ]
  },
  {
    "objectID": "23.tabular_joins.html#tabular-joins",
    "href": "23.tabular_joins.html#tabular-joins",
    "title": "23. Tabular joins",
    "section": "Tabular joins",
    "text": "Tabular joins\nIn this tutorial: how to join tabular data from a CSV to a shapefile using a common identifier",
    "crumbs": [
      "QGIS",
      "23. Tabular joins"
    ]
  },
  {
    "objectID": "23.tabular_joins.html#data-downloads",
    "href": "23.tabular_joins.html#data-downloads",
    "title": "23. Tabular joins",
    "section": "Data downloads",
    "text": "Data downloads\nCommunity Districts shapefile\nCSV containing healthcare facilities and population by community district\n\nSources to create CSV\nNYC Facilities database filter: FACDOMAIN = HEALTH AND HUMAN SERVICES, then count by community district\nPopulation by community district: 2021 ACS 5-Year, Demographic variable = Pop_1E",
    "crumbs": [
      "QGIS",
      "23. Tabular joins"
    ]
  },
  {
    "objectID": "5.datacleaning_pipe.html#cleaning-data",
    "href": "5.datacleaning_pipe.html#cleaning-data",
    "title": "5. Data cleaning and the pipe",
    "section": "Cleaning Data",
    "text": "Cleaning Data\nLet’s read in data like we did last time. We’re going to “clean” it, which just means making it easier to use and getting it into tidy format.\n\nlibrary(tidyverse)\nlibrary(janitor)\nfhv &lt;- read_csv(file = \"For_Hire_Vehicles__FHV__-_Active.csv\")\n\nWhen we read this in, we have some unfriendly names of variables with spaces in them. To access those variables we have to use `backticks` which are clunky. The janitor package has helpful data cleaning functions. Install it and take a look at the clean_names() function.\nFor many functions, the first argument is always the name of a dataframe. In this case we want to clean the names of our fhv dataframe.\n\nfhv_clean &lt;- clean_names(fhv)\n\nNow our names are clean - they are all lowercase, and have replaced all spaces with underscores. This will make it easier to refer to our column names as we transform data going forward.\nBut instead of assigning a new dataframe each time we want to apply a function, we should apply more than one function at once.",
    "crumbs": [
      "Learning R",
      "5. Data cleaning and the pipe"
    ]
  },
  {
    "objectID": "5.datacleaning_pipe.html#the-pipe",
    "href": "5.datacleaning_pipe.html#the-pipe",
    "title": "5. Data cleaning and the pipe",
    "section": "The Pipe",
    "text": "The Pipe\nLet’s say we also wanted to change the name of a variable. Using the pipe %&gt;% we can apply multiple functions to the same dataframe. Use the shortcut shift+command+m on mac or shift+ctrl+m on windows\nLet’s try rename() a function to change the names of columns. I don’t know what the “veh” column means so I’m going to look it up in the data dictionary on the open data page.\nIt’s an indicator for whether the vehicle is hybrid, so i’m going to rename it “hybrid”. Use the documentation for rename() to figure out the right syntax.\nTo use the pipe, start with the name of the data frame you want to edit, and then chain the pipes after each function using some indenting to organize your code.\n\nfhv_clean &lt;- fhv %&gt;% \n  clean_names() %&gt;% \n  rename(hybrid = veh)\n\n#clean_names() is empty because the first argument is just the name of the dataframe, which has been piped in for us\n\nNow we have a dataset with clean names and a renamed column “hybrid”\nAs we learn more and more functions, we’ll have longer chains of pipes to clean and construct datasets.\n\nfhv_clean\n\n# A tibble: 98,318 × 23\n   active vehicle_license_number name               license_type expiration_date\n   &lt;chr&gt;  &lt;chr&gt;                  &lt;chr&gt;              &lt;chr&gt;        &lt;chr&gt;          \n 1 YES    5608977                AMERICAN,UNITED,T… FOR HIRE VE… 04/30/2025     \n 2 YES    5645622                RAMA,ILIR          FOR HIRE VE… 09/11/2023     \n 3 YES    5192507                ORDONEZ,ELIAS      FOR HIRE VE… 03/08/2025     \n 4 YES    5378856                RIVERA,ENMA        FOR HIRE VE… 11/12/2024     \n 5 YES    5852121                A/VA,SERVICE,CORP  FOR HIRE VE… 04/11/2024     \n 6 YES    5415237                REYES,JUAN,E       FOR HIRE VE… 10/31/2023     \n 7 YES    5643301                BEGUM,TAZMINUR     FOR HIRE VE… 09/30/2025     \n 8 YES    5701439                GONZALEZALVARADO,L FOR HIRE VE… 06/13/2024     \n 9 YES    5790931                GOMEZ,JOSE,A       FOR HIRE VE… 05/23/2025     \n10 YES    5743759                HOSSAIN,SM,KAMAL   FOR HIRE VE… 12/08/2024     \n# ℹ 98,308 more rows\n# ℹ 18 more variables: permit_license_number &lt;chr&gt;,\n#   dmv_license_plate_number &lt;chr&gt;, vehicle_vin_number &lt;chr&gt;,\n#   wheelchair_accessible &lt;chr&gt;, certification_date &lt;chr&gt;, hack_up_date &lt;chr&gt;,\n#   vehicle_year &lt;dbl&gt;, base_number &lt;chr&gt;, base_name &lt;chr&gt;, base_type &lt;chr&gt;,\n#   hybrid &lt;chr&gt;, base_telephone_number &lt;chr&gt;, website &lt;chr&gt;,\n#   base_address &lt;chr&gt;, reason &lt;chr&gt;, order_date &lt;lgl&gt;, …",
    "crumbs": [
      "Learning R",
      "5. Data cleaning and the pipe"
    ]
  },
  {
    "objectID": "9.arrange_writecsv.html#how-do-we-get-data-out-of-r",
    "href": "9.arrange_writecsv.html#how-do-we-get-data-out-of-r",
    "title": "9. Arrange and Write Data",
    "section": "How do we get data out of R?",
    "text": "How do we get data out of R?\nOften, we will want to take data that we clean, mutate, summarize, filter, or select with, and output it for use in another software. Think about how you might want to process a million-row data set to get some summary statistics, then create a nice table in excel. Or take some data that you need to make a chart or graphic, and export it so that you can read it into DataWrapper or some other visualization tool. Maybe you need to send your boss a list of items that are buried in a big R dataset.\nWriting data will let you take data out of R and use it other places. But first we might want to use some other functions to get it looking nice and orderly.",
    "crumbs": [
      "Learning R",
      "9. Arrange and Write Data"
    ]
  },
  {
    "objectID": "9.arrange_writecsv.html#arrange",
    "href": "9.arrange_writecsv.html#arrange",
    "title": "9. Arrange and Write Data",
    "section": "Arrange",
    "text": "Arrange\narrange() takes data and sorts it based on certain criteria. Like many of our basic functions, it takes a list ... of inputs to sort on. Let’s take a look at an example of something we summarized.\nLet’s grab our code to read in the clean dataframe again. This time I’m just going to use a big pipe to go right to the summary.\n\nlibrary(tidyverse)\nlibrary(janitor)\n\nfhv_summary &lt;- read_csv(file = \"For_Hire_Vehicles__FHV__-_Active.csv\") %&gt;% \n  clean_names() %&gt;% \n  rename(hybrid = veh) %&gt;% \n  mutate(\n    ride_type = case_when(\n      base_name == \"UBER USA, LLC\" & base_type == \"BLACK-CAR\" ~ \"BLACK CAR RIDESHARE\",\n      base_name != \"UBER USA, LLC\" & base_type == \"BLACK-CAR\" ~ \"BLACK CAR NON-RIDESHARE\",\n      TRUE ~ base_type #if it doesn't meet either condition, return the base_type\n    )) %&gt;% \n  group_by(ride_type) %&gt;% #group by the variable we just created!\n  summarize(no_cars = n(),\n            average_year = mean(vehicle_year, na.rm = T))\n\nfhv_summary\n\n# A tibble: 4 × 3\n  ride_type               no_cars average_year\n  &lt;chr&gt;                     &lt;int&gt;        &lt;dbl&gt;\n1 BLACK CAR NON-RIDESHARE   16225        2018.\n2 BLACK CAR RIDESHARE       76710        2018.\n3 LIVERY                     3652        2015.\n4 LUXURY                     1731        2020.\n\n\nNow Let’s say we wanted to sort this list by average oldest car to newest car.\n\nfhv_summary %&gt;% \n  arrange(average_year)\n\n# A tibble: 4 × 3\n  ride_type               no_cars average_year\n  &lt;chr&gt;                     &lt;int&gt;        &lt;dbl&gt;\n1 LIVERY                     3652        2015.\n2 BLACK CAR NON-RIDESHARE   16225        2018.\n3 BLACK CAR RIDESHARE       76710        2018.\n4 LUXURY                     1731        2020.\n\n\nThat puts all the oldest car on top and the newest car on bottom\ndesc is a function that transforms a vector to descending order, and is helpful to use nested inside arrange.\n\nfhv_arranged &lt;- fhv_summary %&gt;% \n  arrange(desc(average_year))\n\nfhv_arranged\n\n# A tibble: 4 × 3\n  ride_type               no_cars average_year\n  &lt;chr&gt;                     &lt;int&gt;        &lt;dbl&gt;\n1 LUXURY                     1731        2020.\n2 BLACK CAR RIDESHARE       76710        2018.\n3 BLACK CAR NON-RIDESHARE   16225        2018.\n4 LIVERY                     3652        2015.\n\n\nArrange also works with multiple variables - the variable listed second breaks ties - and within groups with group_by.",
    "crumbs": [
      "Learning R",
      "9. Arrange and Write Data"
    ]
  },
  {
    "objectID": "9.arrange_writecsv.html#write-out-data",
    "href": "9.arrange_writecsv.html#write-out-data",
    "title": "9. Arrange and Write Data",
    "section": "Write out data",
    "text": "Write out data\nNow that we have a nice table arranged the way we want, we can output it for use in another software.\nwrite_csv() is a twin function to read_csv(). It takes the name of an object and then a filepath to write to.\n\nfhv_arranged %&gt;% \n  write_csv(file = \"output/ride_type_by_average_year.csv\")\n\nSince we used the local path this shows up right in our project directory. We will be writing out to .csvs mostly, but there are companion functions to write out other types of data, like excel spreadsheets.",
    "crumbs": [
      "Learning R",
      "9. Arrange and Write Data"
    ]
  },
  {
    "objectID": "16.tidycensus.html#intro-to-tidycensus",
    "href": "16.tidycensus.html#intro-to-tidycensus",
    "title": "16. Census Data with tidycensus",
    "section": "Intro to TidyCensus",
    "text": "Intro to TidyCensus\nTidycensus is incredible powerful and gives you access to a ton of census data. Once you get it down you’ll be able to use it to quickly grab a bunch of data.\nhttps://walker-data.com/census-r/an-introduction-to-tidycensus.html\n\nlibrary(tidycensus)\nlibrary(tidyverse)\nlibrary(janitor)\n\nRequest your own API key here: https://api.census.gov/data/key_signup.html\n\nInstall the API key:\n\ncensus_api_key(\"8524147f6edf7fe4b7c85681397fe5acd6993d62\")\n\nTo install your API key for use in future sessions, run this function with `install = TRUE`.\n\n\nYou can use this key for practicing this demo, but please request your own for your projects and future use.\nWhen you get your own key install it, so you won’t have to call this function again with census_api_key(\"key\", install = TRUE)\n\n\nBrowse available variables:\nUse load variables to browse and find the variables of interest\n\nv20 &lt;- load_variables(2020, \"acs5\", cache = TRUE)\n\nAGE BY LANGUAGE SPOKEN AT HOME FOR THE POPULATION 5 YEARS AND OVER\n\nB16007_001 Estimate!!Total:\nB16007_002 Estimate!!Total:!!5 to 17 years:\nB16007_003 Estimate!!Total:!!5 to 17 years:!!Speak only English\nB16007_004 Estimate!!Total:!!5 to 17 years:!!Speak Spanish\nB16007_005 Estimate!!Total:!!5 to 17 years:!!Speak other Indo-European languages\nB16007_006 Estimate!!Total:!!5 to 17 years:!!Speak Asian and Pacific Island languages\nB16007_007 Estimate!!Total:!!5 to 17 years:!!Speak other languages",
    "crumbs": [
      "Learning R",
      "16. Census Data with tidycensus"
    ]
  },
  {
    "objectID": "16.tidycensus.html#pull-data",
    "href": "16.tidycensus.html#pull-data",
    "title": "16. Census Data with tidycensus",
    "section": "Pull data",
    "text": "Pull data\nI use the basic usage of tidycensus webpage to find the right argument names to use.\n\nlangs_by_puma &lt;- get_acs(\n    geography = \"public use microdata area\", \n    variables = c( totalkids = \"B16007_002\",\n                   englishkids = \"B16007_003\",\n                   spanishkids = \"B16007_004\",\n                   indoeurkids = \"B16007_005\",\n                   apikids = \"B16007_006\",\n                   otherkids = \"B16007_007\" ), \n    state = \"New York\", \n    year = 2020, survey = \"acs5\" ) %&gt;% \n  filter(str_detect(NAME, \"NYC\")) %&gt;% \n  mutate(moeshare = moe / estimate)\n\nGetting data from the 2016-2020 5-year ACS\n\n\n\nlangs_by_boro &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    totalkids = \"B16007_002\",\n    englishkids = \"B16007_003\",\n    spanishkids = \"B16007_004\",\n    indoeurkids = \"B16007_005\",\n    apikids = \"B16007_006\",\n    otherkids = \"B16007_007\"\n  ),\n  state =  \"New York\",\n  year = 2020,\n  survey = \"acs5\"\n) %&gt;%\n  filter(\n    NAME == \"Kings County, New York\" |\n      NAME == \"Queens County, New York\" |\n      NAME == \"New York County, New York\" |\n      NAME == \"Bronx County, New York\" |\n      NAME == \"Richmond County, New York\"\n  ) %&gt;%\n  clean_names()\n\nGetting data from the 2016-2020 5-year ACS\n\n\nWrite langs_by_boro as a CSV file into the same folder\n\nwrite_csv(langs_by_boro, 'langs_by_boro.csv')\n#this output might look familiar from our ggplot lesson!\n\nTidycensus also has a “wide” option to make calculating percentages, for example, easier.\n\nget_acs(\n  geography = \"county\",\n  variables = c(\n    totalkids = \"B16007_002\",\n    englishkids = \"B16007_003\",\n    spanishkids = \"B16007_004\",\n    indoeurkids = \"B16007_005\",\n    apikids = \"B16007_006\",\n    otherkids = \"B16007_007\"\n  ),\n  state =  \"New York\",\n  year = 2020,\n  survey = \"acs5\",\n  output = \"wide\" #look here!\n) %&gt;%\n  filter(\n    NAME == \"Kings County, New York\" |\n      NAME == \"Queens County, New York\" |\n      NAME == \"New York County, New York\" |\n      NAME == \"Bronx County, New York\" |\n      NAME == \"Richmond County, New York\"\n  ) %&gt;%\n  clean_names() %&gt;% \n  mutate(\n    pct_englishkids = englishkids_e / totalkids_e, #_u is for the estimate and _m is the margin or error\n    pct_spanishkids = spanishkids_e / totalkids_e,\n    pct_indoeurkids = indoeurkids_e / totalkids_e,\n    pct_aapikids = apikids_e / totalkids_e,\n    pct_otherkids = otherkids_e / totalkids_e\n  ) %&gt;% \n  select(name, starts_with(\"pct\"))\n\nGetting data from the 2016-2020 5-year ACS\n\n\n# A tibble: 5 × 6\n  name              pct_englishkids pct_spanishkids pct_indoeurkids pct_aapikids\n  &lt;chr&gt;                       &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;        &lt;dbl&gt;\n1 New York County,…           0.577           0.265          0.0734      0.0545 \n2 Richmond County,…           0.722           0.108          0.0837      0.0487 \n3 Bronx County, Ne…           0.466           0.437          0.0391      0.00797\n4 Kings County, Ne…           0.555           0.147          0.191       0.0686 \n5 Queens County, N…           0.495           0.251          0.129       0.105  \n# ℹ 1 more variable: pct_otherkids &lt;dbl&gt;",
    "crumbs": [
      "Learning R",
      "16. Census Data with tidycensus"
    ]
  },
  {
    "objectID": "16.tidycensus.html#crosswalks-and-matching-census-geographies",
    "href": "16.tidycensus.html#crosswalks-and-matching-census-geographies",
    "title": "16. Census Data with tidycensus",
    "section": "Crosswalks and matching census geographies",
    "text": "Crosswalks and matching census geographies\nLet’s say I wanted to compare a number of statistics by Brooklyn neighborhood. But oh no! The census doesn’t provide data at the neighborhood level. Fear not, you can use something called a crosswalk to match data from different geographies. Census data makes it easy - they have standard GEOID columns that allow you to match data at different geographies.\nCensus data is powerful because you can join it with data on whatever you are interested in at almost any geographic level.\nFirst I’ll grab some statistics at the tract level in Brooklyn.\n\npop_data &lt;- get_acs(\n  geography = \"tract\",\n  variables = c(total_population = \"B01003_001\",\n                median_household_income = \"B19019_001\",\n                race_eth_denom = \"B03002_001\",\n                white_nonhsp = \"B03002_003\"\n  ),\n  year = 2021,\n  state = \"New York\",\n  county = \"Kings\"\n)\n\nGetting data from the 2017-2021 5-year ACS\n\n\nThen I’ll read in this crosswalk between neighborhoods and tracts from the NYC Open data portal. By joining the two on GEOID I can summarize at the neighborhood level\n\nnta_tract &lt;- read_csv(\"https://data.cityofnewyork.us/resource/hm78-6dwm.csv\",\n                      col_types = cols(geoid = col_character())) %&gt;% \n  filter(boroname == \"Brooklyn\")\n\npop_data_joined &lt;- nta_tract %&gt;% \n  full_join(pop_data, by = c(\"geoid\" = \"GEOID\"))\n  \npop_data_joined %&gt;%\n  filter(variable == \"total_population\") %&gt;%\n  group_by(ntaname) %&gt;% \n  summarize(total_population = sum(estimate))\n\n# A tibble: 53 × 2\n   ntaname                   total_population\n   &lt;chr&gt;                                &lt;dbl&gt;\n 1 Bath Beach                           33765\n 2 Bay Ridge                            85796\n 3 Bedford-Stuyvesant (East)            92298\n 4 Bedford-Stuyvesant (West)            89224\n 5 Bensonhurst                         102241\n 6 Borough Park                         84493\n 7 Brighton Beach                       31295\n 8 Brooklyn Heights                     24775\n 9 Brooklyn Navy Yard                       0\n10 Bushwick (East)                      62987\n# ℹ 43 more rows\n\n\nWhat if I just wanted to compare one neighborhood to the rest of Brooklyn? Using the pull() function which rips a list from a dataframe variable I can mutate my way to that summary.\n\ngowanus_tracts &lt;- nta_tract %&gt;% \n  mutate(geoid = as.character(geoid)) %&gt;% \n  filter(ntaname == \"Carroll Gardens-Cobble Hill-Gowanus-Red Hook\") %&gt;% \n  pull(geoid)\n\npop_data_clean &lt;- pop_data %&gt;% \n  mutate(gowanus = if_else(GEOID %in% gowanus_tracts, \"Gowanus\", \"Rest of BK\"))\n  \npop_data_clean %&gt;%\n  filter(variable == \"total_population\") %&gt;%\n  group_by(gowanus) %&gt;% \n  summarize(total = sum(estimate))\n\n# A tibble: 2 × 2\n  gowanus      total\n  &lt;chr&gt;        &lt;dbl&gt;\n1 Gowanus      63167\n2 Rest of BK 2649193",
    "crumbs": [
      "Learning R",
      "16. Census Data with tidycensus"
    ]
  },
  {
    "objectID": "25.choropleth.html#symbolizing-data-with-a-choropleth",
    "href": "25.choropleth.html#symbolizing-data-with-a-choropleth",
    "title": "25. Symbolizing data with a choropleth",
    "section": "Symbolizing data with a choropleth",
    "text": "Symbolizing data with a choropleth\nIn this tutorial: Calculate a new field (a.k.a. variable or column) of population per healthcare facility for each NYC community district using the Field Calculator tool",
    "crumbs": [
      "QGIS",
      "25. Symbolizing data with a choropleth"
    ]
  },
  {
    "objectID": "25.choropleth.html#data-downloads",
    "href": "25.choropleth.html#data-downloads",
    "title": "25. Symbolizing data with a choropleth",
    "section": "Data downloads",
    "text": "Data downloads\nShapefile of community districts with healthcare facilities and population",
    "crumbs": [
      "QGIS",
      "25. Symbolizing data with a choropleth"
    ]
  },
  {
    "objectID": "17.sf.html",
    "href": "17.sf.html",
    "title": "17. Spatial Features",
    "section": "",
    "text": "The Spatial features package allows us to read in spatial data into R and transform it. Let’s get a spatial dataset on affordable housing from the NYC open data portal.\n\naff_hsg &lt;- read_csv(\"https://data.cityofnewyork.us/resource/hg8x-zxpr.csv?$limit=10000\")\n\nRows: 7380 Columns: 41\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (9): project_name, house_number, street_name, borough, community_board...\ndbl  (29): project_id, building_id, postcode, bbl, bin, council_district, ce...\ndttm  (3): project_start_date, project_completion_date, building_completion_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWith SF, I can take tabular data and make it into a spatial dataset. In this case I have coordinates that I turn into points us st_as_sf\n\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\naff_hsg_sf &lt;- aff_hsg %&gt;% \n  clean_names() %&gt;% \n  filter(!is.na(longitude)) %&gt;%  #remove properties with missing coordinates\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 2263) #be careful! x = longitude, y = latitude\n\nNow that this is spatial, I can map it! geom_sf is the ggplot function that maps spatial objects. It works much like any other ggplot.\n\nggplot()+\n  geom_sf(aff_hsg_sf, mapping = aes())\n\n\n\n\n\n\n\n\nI can use programming for styling, too.\n\nggplot()+\n  geom_sf(aff_hsg_sf,\n          mapping = aes(size = all_counted_units,\n                        color = all_counted_units),\n          alpha = 0.25)\n\n\n\n\n\n\n\n\nBut that doesn’t look very good, let’s add some other layers. I can read in CDs directly as a shapefile using the geojson version from the Open data portal. This map is a long way from done, but now it has a semblance of a basemap.\n\ncd_sf &lt;- read_sf(\"https://data.cityofnewyork.us/resource/jp9i-3b7y.geojson\") %&gt;% \n  st_set_crs(st_crs(aff_hsg_sf)) # here I am setting the crs of the new data to the crs of the point data I already have\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\nggplot()+\n  geom_sf(cd_sf,\n          mapping = aes())+ #this layer will be on bottom!\n  geom_sf(aff_hsg_sf,\n          mapping = aes(size = all_counted_units,\n                        color = all_counted_units),\n          alpha = 0.25) #this layer will be on top!\n\n\n\n\n\n\n\n          #alpha changes the opacity of the dots\n\nI can also summarize data like I would in a tabular dataset\n\naff_hsg_sum &lt;- aff_hsg %&gt;% \n  group_by(community_board) %&gt;% \n  summarize(total_affordable_units = sum(all_counted_units, na.rm = T))\n\nAnd then I could create a choropleth with the summarized data, now that I have the nta shapes (just a simple join!)\n\ncd_aff_sum &lt;- cd_sf %&gt;% \n  mutate(community_board = case_when(\n    str_sub(boro_cd, 1, 1) == \"1\" ~ paste0(\"MN-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"2\" ~ paste0(\"BX-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"3\" ~ paste0(\"BK-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"4\" ~ paste0(\"QN-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"5\" ~ paste0(\"SI-\",str_sub(boro_cd, 2,3)),\n  )) %&gt;%  #take the first character of boro_cd, replace it with the boro abbreviation, add the community board number\n  left_join(aff_hsg_sum, by = \"community_board\")\n\nI can map that, now as a choropleth\n\nggplot()+\n  geom_sf(cd_aff_sum,\n          mapping = aes(fill = total_affordable_units))\n\n\n\n\n\n\n\n\nI could also match it to other data, and write it out to a shapefile to use in GIS\n\nlibrary(tidycensus)\n\ncensus_stats &lt;- get_acs(\n  geography = \"tract\",\n  variables = c(population = \"B01003_001\",\n                med_income = \"B07011_001\"),\n  year = 2021,\n  state = \"NY\",\n  county = c(\"Bronx\", \"New York\", \"Kings\", \"Queens\", \"Richmond\"),\n  output = \"wide\"\n) %&gt;% \n  clean_names()\n\nGetting data from the 2017-2021 5-year ACS\n\n\nI need a crosswalk to go from census tracts to community districts. Open data has one!\n\ncdtas_tracts &lt;- read_csv(\"https://data.cityofnewyork.us/resource/hm78-6dwm.csv?$limit=10000\",\n                         col_types = cols(geoid = col_character()))\n\ncdta_stats &lt;- census_stats %&gt;%\n  left_join(cdtas_tracts, by = \"geoid\") %&gt;% \n  group_by(cdtacode, cdtaname) %&gt;% \n  summarize(total_pop = sum(population_e, na.rm = T),\n            avg_med_inc = mean(med_income_e, na.rm = T)) %&gt;% \n  mutate()\n\n`summarise()` has grouped output by 'cdtacode'. You can override using the\n`.groups` argument.\n\n\nNow I can join! With everything in the same data frame I can write it out to read into spatial software, or I can visualize it\n\ncd_aff_stats &lt;- cd_aff_sum %&gt;% \n  mutate(cdtacode = str_replace(community_board, \"-\", \"\")) %&gt;% \n  left_join(cdta_stats) %&gt;% \n  mutate(aff_units_person = total_affordable_units/total_pop)\n\nJoining with `by = join_by(cdtacode)`\n\n\n\nst_write(cd_aff_stats,\n         \"output/cd_aff_hsg.shp\",\n         append = F)\n\nWarning in abbreviate_shapefile_names(obj): Field names abbreviated for ESRI\nShapefile driver\n\n\nDeleting layer `cd_aff_hsg' using driver `ESRI Shapefile'\nWriting layer `cd_aff_hsg' to data source \n  `output/cd_aff_hsg.shp' using driver `ESRI Shapefile'\nWriting 71 features with 10 fields and geometry type Multi Polygon.\n\n\nI can map affordable units per person (normalized!)\n\nggplot()+\n  geom_sf(cd_aff_stats,\n          mapping = aes(fill = aff_units_person))\n\n\n\n\n\n\n\n\nWhat if I wanted to map both both the # of units per cd and the median income?\nI can use one of sf’s spatial operators and to take a centroid and map points\n\npoints_aff_cd &lt;- cd_aff_stats %&gt;% \n  select(total_affordable_units, cdtacode) %&gt;% \n  st_centroid()\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n\nAnd overlay on a choropleth. You notice that a lot of the buildings are built in low income areas!\n\nggplot()+\n  geom_sf(cd_aff_stats,\n          mapping = aes(fill = avg_med_inc))+\n  geom_sf(points_aff_cd,\n          mapping = aes(size = total_affordable_units),\n          color = \"pink\",\n          alpha = 0.5)\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_sf()`).\n\n\n\n\n\n\n\n\n\nI could write out this ggplot to edit in vector graphics\n\nggsave(\"output/aff_hsg_inc_nyc.svg\")\n\nSaving 7 x 5 in image\n\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_sf()`).\n\n\nWhat if I didn’t have a crosswalk and needed to match points to the community district? I can do a spatial join to find what cd all the points fall into.\n\npoints_polygons_join &lt;- st_intersection(aff_hsg_sf, cd_sf)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\nI can then use summarize() to count points in polygons - or do more advanced summaries\n\npoints_polygons_join %&gt;% \n  as.data.frame() %&gt;% #summarize works faster without the spatial features attached\n  group_by(boro_cd) %&gt;% \n  summarize(points_in_polygon = n(),\n            units_per_cd = sum(all_counted_units, na.rm = T))\n\n# A tibble: 59 × 3\n   boro_cd points_in_polygon units_per_cd\n   &lt;chr&gt;               &lt;int&gt;        &lt;dbl&gt;\n 1 101                     5          300\n 2 102                     8          463\n 3 103                   142         8519\n 4 104                    68         6656\n 5 105                    18         1595\n 6 106                    79         6636\n 7 107                    79         3708\n 8 108                    19         1587\n 9 109                   107         3235\n10 110                   334         9904\n# ℹ 49 more rows\n\n\nWhat if I wanted to find the proportion of affordable housing in the flood zone? I can do this with an intersects and mutate - I don’t even need to join the two datasets!\n\n# floodplain_2020s_100y &lt;- read_sf(\"https://data.cityofnewyork.us/resource/inra-wqx3.geojson?$limit=10000\") %&gt;% \n#   st_make_valid() %&gt;%  #this magic function repairs any invalid geometries\n#   st_union() %&gt;% #here I make the entire floodplain into one big shape\n#   st_set_crs(st_crs(points_polygons_join)) #and set it to the same crs as my points\n# \n# points_polygons_join %&gt;% \n#   mutate(fplain_2020s_100y = lengths(st_intersects(.,floodplain_2020s_100y))) %&gt;%  #st_intersects returns a list of the shapes it intersects with - if its 0 it didn't intersect, if its 1 it did!\n#   as.data.frame() %&gt;% \n#   group_by(fplain_2020s_100y) %&gt;% \n#   summarize(count = n(),\n#             units = sum(all_counted_units, na.rm = T))\n\nMany more spatial operations available on the cheat sheets",
    "crumbs": [
      "Learning R",
      "17. Spatial Features"
    ]
  },
  {
    "objectID": "17.sf.html#video-tutorial",
    "href": "17.sf.html#video-tutorial",
    "title": "17. Spatial Features",
    "section": "",
    "text": "The Spatial features package allows us to read in spatial data into R and transform it. Let’s get a spatial dataset on affordable housing from the NYC open data portal.\n\naff_hsg &lt;- read_csv(\"https://data.cityofnewyork.us/resource/hg8x-zxpr.csv?$limit=10000\")\n\nRows: 7380 Columns: 41\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (9): project_name, house_number, street_name, borough, community_board...\ndbl  (29): project_id, building_id, postcode, bbl, bin, council_district, ce...\ndttm  (3): project_start_date, project_completion_date, building_completion_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWith SF, I can take tabular data and make it into a spatial dataset. In this case I have coordinates that I turn into points us st_as_sf\n\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\naff_hsg_sf &lt;- aff_hsg %&gt;% \n  clean_names() %&gt;% \n  filter(!is.na(longitude)) %&gt;%  #remove properties with missing coordinates\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 2263) #be careful! x = longitude, y = latitude\n\nNow that this is spatial, I can map it! geom_sf is the ggplot function that maps spatial objects. It works much like any other ggplot.\n\nggplot()+\n  geom_sf(aff_hsg_sf, mapping = aes())\n\n\n\n\n\n\n\n\nI can use programming for styling, too.\n\nggplot()+\n  geom_sf(aff_hsg_sf,\n          mapping = aes(size = all_counted_units,\n                        color = all_counted_units),\n          alpha = 0.25)\n\n\n\n\n\n\n\n\nBut that doesn’t look very good, let’s add some other layers. I can read in CDs directly as a shapefile using the geojson version from the Open data portal. This map is a long way from done, but now it has a semblance of a basemap.\n\ncd_sf &lt;- read_sf(\"https://data.cityofnewyork.us/resource/jp9i-3b7y.geojson\") %&gt;% \n  st_set_crs(st_crs(aff_hsg_sf)) # here I am setting the crs of the new data to the crs of the point data I already have\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\nggplot()+\n  geom_sf(cd_sf,\n          mapping = aes())+ #this layer will be on bottom!\n  geom_sf(aff_hsg_sf,\n          mapping = aes(size = all_counted_units,\n                        color = all_counted_units),\n          alpha = 0.25) #this layer will be on top!\n\n\n\n\n\n\n\n          #alpha changes the opacity of the dots\n\nI can also summarize data like I would in a tabular dataset\n\naff_hsg_sum &lt;- aff_hsg %&gt;% \n  group_by(community_board) %&gt;% \n  summarize(total_affordable_units = sum(all_counted_units, na.rm = T))\n\nAnd then I could create a choropleth with the summarized data, now that I have the nta shapes (just a simple join!)\n\ncd_aff_sum &lt;- cd_sf %&gt;% \n  mutate(community_board = case_when(\n    str_sub(boro_cd, 1, 1) == \"1\" ~ paste0(\"MN-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"2\" ~ paste0(\"BX-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"3\" ~ paste0(\"BK-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"4\" ~ paste0(\"QN-\",str_sub(boro_cd, 2,3)),\n    str_sub(boro_cd, 1, 1) == \"5\" ~ paste0(\"SI-\",str_sub(boro_cd, 2,3)),\n  )) %&gt;%  #take the first character of boro_cd, replace it with the boro abbreviation, add the community board number\n  left_join(aff_hsg_sum, by = \"community_board\")\n\nI can map that, now as a choropleth\n\nggplot()+\n  geom_sf(cd_aff_sum,\n          mapping = aes(fill = total_affordable_units))\n\n\n\n\n\n\n\n\nI could also match it to other data, and write it out to a shapefile to use in GIS\n\nlibrary(tidycensus)\n\ncensus_stats &lt;- get_acs(\n  geography = \"tract\",\n  variables = c(population = \"B01003_001\",\n                med_income = \"B07011_001\"),\n  year = 2021,\n  state = \"NY\",\n  county = c(\"Bronx\", \"New York\", \"Kings\", \"Queens\", \"Richmond\"),\n  output = \"wide\"\n) %&gt;% \n  clean_names()\n\nGetting data from the 2017-2021 5-year ACS\n\n\nI need a crosswalk to go from census tracts to community districts. Open data has one!\n\ncdtas_tracts &lt;- read_csv(\"https://data.cityofnewyork.us/resource/hm78-6dwm.csv?$limit=10000\",\n                         col_types = cols(geoid = col_character()))\n\ncdta_stats &lt;- census_stats %&gt;%\n  left_join(cdtas_tracts, by = \"geoid\") %&gt;% \n  group_by(cdtacode, cdtaname) %&gt;% \n  summarize(total_pop = sum(population_e, na.rm = T),\n            avg_med_inc = mean(med_income_e, na.rm = T)) %&gt;% \n  mutate()\n\n`summarise()` has grouped output by 'cdtacode'. You can override using the\n`.groups` argument.\n\n\nNow I can join! With everything in the same data frame I can write it out to read into spatial software, or I can visualize it\n\ncd_aff_stats &lt;- cd_aff_sum %&gt;% \n  mutate(cdtacode = str_replace(community_board, \"-\", \"\")) %&gt;% \n  left_join(cdta_stats) %&gt;% \n  mutate(aff_units_person = total_affordable_units/total_pop)\n\nJoining with `by = join_by(cdtacode)`\n\n\n\nst_write(cd_aff_stats,\n         \"output/cd_aff_hsg.shp\",\n         append = F)\n\nWarning in abbreviate_shapefile_names(obj): Field names abbreviated for ESRI\nShapefile driver\n\n\nDeleting layer `cd_aff_hsg' using driver `ESRI Shapefile'\nWriting layer `cd_aff_hsg' to data source \n  `output/cd_aff_hsg.shp' using driver `ESRI Shapefile'\nWriting 71 features with 10 fields and geometry type Multi Polygon.\n\n\nI can map affordable units per person (normalized!)\n\nggplot()+\n  geom_sf(cd_aff_stats,\n          mapping = aes(fill = aff_units_person))\n\n\n\n\n\n\n\n\nWhat if I wanted to map both both the # of units per cd and the median income?\nI can use one of sf’s spatial operators and to take a centroid and map points\n\npoints_aff_cd &lt;- cd_aff_stats %&gt;% \n  select(total_affordable_units, cdtacode) %&gt;% \n  st_centroid()\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n\nAnd overlay on a choropleth. You notice that a lot of the buildings are built in low income areas!\n\nggplot()+\n  geom_sf(cd_aff_stats,\n          mapping = aes(fill = avg_med_inc))+\n  geom_sf(points_aff_cd,\n          mapping = aes(size = total_affordable_units),\n          color = \"pink\",\n          alpha = 0.5)\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_sf()`).\n\n\n\n\n\n\n\n\n\nI could write out this ggplot to edit in vector graphics\n\nggsave(\"output/aff_hsg_inc_nyc.svg\")\n\nSaving 7 x 5 in image\n\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_sf()`).\n\n\nWhat if I didn’t have a crosswalk and needed to match points to the community district? I can do a spatial join to find what cd all the points fall into.\n\npoints_polygons_join &lt;- st_intersection(aff_hsg_sf, cd_sf)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\nI can then use summarize() to count points in polygons - or do more advanced summaries\n\npoints_polygons_join %&gt;% \n  as.data.frame() %&gt;% #summarize works faster without the spatial features attached\n  group_by(boro_cd) %&gt;% \n  summarize(points_in_polygon = n(),\n            units_per_cd = sum(all_counted_units, na.rm = T))\n\n# A tibble: 59 × 3\n   boro_cd points_in_polygon units_per_cd\n   &lt;chr&gt;               &lt;int&gt;        &lt;dbl&gt;\n 1 101                     5          300\n 2 102                     8          463\n 3 103                   142         8519\n 4 104                    68         6656\n 5 105                    18         1595\n 6 106                    79         6636\n 7 107                    79         3708\n 8 108                    19         1587\n 9 109                   107         3235\n10 110                   334         9904\n# ℹ 49 more rows\n\n\nWhat if I wanted to find the proportion of affordable housing in the flood zone? I can do this with an intersects and mutate - I don’t even need to join the two datasets!\n\n# floodplain_2020s_100y &lt;- read_sf(\"https://data.cityofnewyork.us/resource/inra-wqx3.geojson?$limit=10000\") %&gt;% \n#   st_make_valid() %&gt;%  #this magic function repairs any invalid geometries\n#   st_union() %&gt;% #here I make the entire floodplain into one big shape\n#   st_set_crs(st_crs(points_polygons_join)) #and set it to the same crs as my points\n# \n# points_polygons_join %&gt;% \n#   mutate(fplain_2020s_100y = lengths(st_intersects(.,floodplain_2020s_100y))) %&gt;%  #st_intersects returns a list of the shapes it intersects with - if its 0 it didn't intersect, if its 1 it did!\n#   as.data.frame() %&gt;% \n#   group_by(fplain_2020s_100y) %&gt;% \n#   summarize(count = n(),\n#             units = sum(all_counted_units, na.rm = T))\n\nMany more spatial operations available on the cheat sheets",
    "crumbs": [
      "Learning R",
      "17. Spatial Features"
    ]
  },
  {
    "objectID": "11.pivoting.html#wide-and-long-data",
    "href": "11.pivoting.html#wide-and-long-data",
    "title": "11. Pivoting",
    "section": "“Wide” and “Long” Data",
    "text": "“Wide” and “Long” Data\nA dataset can be written as wide and long. A wide format contains values that do not repeat in the first column, whereas long format contains values that do repeat in the first column. Imagine keeping statistics for a basket ball game. You could do it two ways:\n\nLong data is tidy - Every column is a variable Every row is an observation. Every cell is a single value.\nWe can use pivoting to convert data between wide and long formats. Here’s a visual for what pivoting does.",
    "crumbs": [
      "Learning R",
      "11. Pivoting"
    ]
  },
  {
    "objectID": "11.pivoting.html#pivoting-longer",
    "href": "11.pivoting.html#pivoting-longer",
    "title": "11. Pivoting",
    "section": "Pivoting Longer",
    "text": "Pivoting Longer\nFor this demo, we want to make a timeline of rent stabilized units in NYC.\nSo, let’s start by loading in some data from https://github.com/talos/nyc-stabilization-unit-counts.\nThe dataset we want is here.\nYou can save this file in your project folder and read it in how we’re used to. Or we can read it directly into our environment, a cool feature of read_csv() that lets you pull directly from a weblink.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nrent_stab_raw &lt;- read_csv(\"https://taxbillsnyc.s3.amazonaws.com/joined.csv\")\n\nRows: 46461 Columns: 61\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (27): borough, 2007est, 2008est, 2009est, 2009dhcr, 2009abat, 2010est, 2...\ndbl (25): ucbbl, 2007uc, 2008uc, 2009uc, 2010uc, 2011uc, 2012uc, 2013uc, 201...\nlgl  (9): 2007dhcr, 2007abat, 2008dhcr, 2008abat, 2010dhcr, 2014dhcr, 2015dh...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThis project scraped data from PDFs of property tax documents to get estimates for rent stabilized units counts in buildings across NYC. You can read up on the various field names at the Github project page:\nhttps://github.com/talos/nyc-stabilization-unit-counts#user-content-data-usage.\nFor this demo, we only want to look at rent stabilized unit counts, which according to the Github doccumentation corresponds to column names that end in “uc”. Let’s also grab BBL (which is a unique identifier for NYC buildings) and Borough while we’re at it:\n\nrent_stab &lt;- rent_stab_raw %&gt;% select(borough, ucbbl, ends_with(\"uc\"))\n\n# starts_with(…) and ends_with(…) are neat selector functions to help you \n# grab names that fit a certain pattern \n\nAnnoyingly, the data separates unit counts for different years into different columns… to make a timeline, we need all of the yearly data to be stored in one column.\nWe can use the pivot_longer function included in tidyverse to transform our data accordingly. Here is how we apply the `pivot_longer` function to our data:\n\nrs_long &lt;- rent_stab %&gt;% \n  pivot_longer(\n    ends_with(\"uc\"),  # The multiple column names we want to mush into one column\n    names_to = \"year\", # The title for the new column of names we're generating\n    values_to = \"units\" # The title for the new column of values we're generating\n  )\n\nNow we have data that is “tidy” there is one row for each year for each building. So each observation is a bbl-year pair.",
    "crumbs": [
      "Learning R",
      "11. Pivoting"
    ]
  },
  {
    "objectID": "11.pivoting.html#pivoting-wider",
    "href": "11.pivoting.html#pivoting-wider",
    "title": "11. Pivoting",
    "section": "Pivoting Wider",
    "text": "Pivoting Wider\nAdditionally, you may have data that is in this “long” format and wish to transform it into the “wide” format we are used to. Luckily, there is an analogous function called `pivot_wider` that does just that:\n\nrs_wide &lt;- rs_long %&gt;%\n  pivot_wider(\n  names_from = year, # The current column containing our future column names\n  values_from = units # The current column containing the values for our future columns\n  )",
    "crumbs": [
      "Learning R",
      "11. Pivoting"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "URPL 1620",
    "section": "",
    "text": "This page was created as a guide to help students at NYU Wagner’s Data Analysis, Mapping, and Storytelling course.\nHere are links to the Brightspace, Slack, and Google Drive",
    "crumbs": [
      "URPL 1620"
    ]
  },
  {
    "objectID": "index.html#urpl-1620",
    "href": "index.html#urpl-1620",
    "title": "URPL 1620",
    "section": "",
    "text": "This page was created as a guide to help students at NYU Wagner’s Data Analysis, Mapping, and Storytelling course.\nHere are links to the Brightspace, Slack, and Google Drive",
    "crumbs": [
      "URPL 1620"
    ]
  },
  {
    "objectID": "index.html#welcome-to-r",
    "href": "index.html#welcome-to-r",
    "title": "URPL 1620",
    "section": "Welcome to R",
    "text": "Welcome to R\nIn this directory, we’re going to learn the basics of R and how to use it to read in, analyze, and visualize data so you can use it in data stories.",
    "crumbs": [
      "URPL 1620"
    ]
  },
  {
    "objectID": "index.html#welcome-to-qgis",
    "href": "index.html#welcome-to-qgis",
    "title": "URPL 1620",
    "section": "Welcome to QGIS",
    "text": "Welcome to QGIS\nIn this directory, we’re going to learn the basics of QGIS and how to use it to read in, analyze, and visualize data so you can use it in data stories.",
    "crumbs": [
      "URPL 1620"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "URPL 1620",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese tutorials are adapted from previous course materials assembled and edited by Sam Rabiyah, Maxwell Austensen, and Lucy Block.",
    "crumbs": [
      "URPL 1620"
    ]
  },
  {
    "objectID": "1.installing_r.html",
    "href": "1.installing_r.html",
    "title": "1. Installing R",
    "section": "",
    "text": "To get started with this tutorial visit the RStudio download page",
    "crumbs": [
      "Learning R",
      "1. Installing R"
    ]
  },
  {
    "objectID": "1.installing_r.html#video-tutorial",
    "href": "1.installing_r.html#video-tutorial",
    "title": "1. Installing R",
    "section": "",
    "text": "To get started with this tutorial visit the RStudio download page",
    "crumbs": [
      "Learning R",
      "1. Installing R"
    ]
  },
  {
    "objectID": "1.installing_r.html#installing-r-and-rstudio",
    "href": "1.installing_r.html#installing-r-and-rstudio",
    "title": "1. Installing R",
    "section": "Installing R and RStudio",
    "text": "Installing R and RStudio\nTo use R, we need R, the underlying language that runs our code, as well as R studio, an integrated development environment (IDE) that allows us to save files and edit and run code.\nTo get started, we’ll visit RStudio’s homepage to install R.\nFirst, Install R for your operating system from CRAN.\nThen download the latest version of RStudio and open it.",
    "crumbs": [
      "Learning R",
      "1. Installing R"
    ]
  },
  {
    "objectID": "2.r_projects.html#opening-r-studio",
    "href": "2.r_projects.html#opening-r-studio",
    "title": "2. Creating R Projects",
    "section": "Opening R Studio",
    "text": "Opening R Studio\nWhen you load RStudio, the screen will be split in three. This is some important vocabulary to direct yourself around RStudio and get help when you need it.\n\nThe CONSOLE is where all your code is run. Here you will see the output from the code you run. The COMMAND LINE is where you can type in code and execute it to the console. Code you run in the console is not saved. Try typing 1+1 into the console, and you’ll see that R spits back 2.\nThe ENVIRONMENT is where all your data will be stored. R is an object oriented programming language. Think of it like having a bunch of spreadsheets open at once. The environment shows you all the data you have loaded, and what each dataset, list, or other object is called.\nThe DIRECTORY is in the bottom right. This links to all the files in your current folder, called your working directory. If you are ever in the wrong working directory, you can set it by running the setwd() function or going to “Session” -\\&gt; “Set Working Directory.” We will keep files organized by using an R Project.",
    "crumbs": [
      "Learning R",
      "2. Creating R Projects"
    ]
  },
  {
    "objectID": "2.r_projects.html#creating-a-project",
    "href": "2.r_projects.html#creating-a-project",
    "title": "2. Creating R Projects",
    "section": "Creating a Project",
    "text": "Creating a Project\nAn R Project is basically a folder that will hold all your files together in one place - including your code, raw data, and any output you may produce.\nCreate your first R Project by clicking on the projects icon in the top right. You can create a project from a new or existing directory.\nWhen you return to RStudio to work on a saved project, open the project again by using the Project menu in RStudio, or double clicking the .Rproj file in the project directory.",
    "crumbs": [
      "Learning R",
      "2. Creating R Projects"
    ]
  },
  {
    "objectID": "2.r_projects.html#creating-your-first-script",
    "href": "2.r_projects.html#creating-your-first-script",
    "title": "2. Creating R Projects",
    "section": "Creating Your First Script",
    "text": "Creating Your First Script\nGo to File -&gt; New Script and save it to your project folder\nUse the assignment operator &lt;- to save values, dataframes, and other objects to the environment for future use.\nUse command+enter (Mac) or ctrl + enter (Windows) to run your code. Or select all and then run the shortcut to run the whole script at once.",
    "crumbs": [
      "Learning R",
      "2. Creating R Projects"
    ]
  },
  {
    "objectID": "21.geocoding.html#geocoding-addresses",
    "href": "21.geocoding.html#geocoding-addresses",
    "title": "21. Geocoding addresses",
    "section": "Geocoding addresses",
    "text": "Geocoding addresses\nIn this tutorial: How to geocode, i.e. add latitude and longitude to a CSV/tabular dataset that only contains addresses, which will allow you to plot the CSV on a map.\nThis tutorial uses Geocodio",
    "crumbs": [
      "QGIS",
      "21. Geocoding addresses"
    ]
  },
  {
    "objectID": "21.geocoding.html#data-downloads",
    "href": "21.geocoding.html#data-downloads",
    "title": "21. Geocoding addresses",
    "section": "Data downloads",
    "text": "Data downloads\nCOVID meals dataset without latitude and longitude to practice\nOriginal COVID meals dataset",
    "crumbs": [
      "QGIS",
      "21. Geocoding addresses"
    ]
  },
  {
    "objectID": "24.calculate_field.html#calculating-a-new-field",
    "href": "24.calculate_field.html#calculating-a-new-field",
    "title": "24. Calculating a new field",
    "section": "Calculating a new field",
    "text": "Calculating a new field\nIn this tutorial: Calculate a new field (a.k.a. variable or column) of population per healthcare facility for each NYC community district using the Field Calculator tool",
    "crumbs": [
      "QGIS",
      "24. Calculating a new field"
    ]
  },
  {
    "objectID": "24.calculate_field.html#data-downloads",
    "href": "24.calculate_field.html#data-downloads",
    "title": "24. Calculating a new field",
    "section": "Data downloads",
    "text": "Data downloads\nShapefile of community districts with healthcare facilities and population",
    "crumbs": [
      "QGIS",
      "24. Calculating a new field"
    ]
  },
  {
    "objectID": "15.apis.html#downloading-data-from-the-web",
    "href": "15.apis.html#downloading-data-from-the-web",
    "title": "15. APIs",
    "section": "Downloading Data from the web",
    "text": "Downloading Data from the web\nYou can download datasets directly from the web with read_csv().\n\nread_csv('https://raw.githubusercontent.com/Statology/Miscellaneous/main/basketball_data.csv')\n\n# A tibble: 5 × 3\n  player assists points\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 A            6     12\n2 B            7     19\n3 C           14      7\n4 D            4      6\n5 E            5     10\n\n\nBut sometimes getting data stored on the web is more complicated, or you are accessing massive databases that would take forever to read the whole thing into R.\nWhen downloading data from NYC Open Data and other sources, you can use a special set of commands to filter and manipulate the data before downloading it to your local computer. These commands, unlike ones you’d write in an R script, are actually written in the URL itself. This kind of command is called an “API Call”— API stands for “Application programming interface” and is just a special system and language for users to communicate with the back end data servers. API Calls to APIs use a special syntax, which will be included in an API’s documentation. For NYC’s Open data, that syntax is very similar to a popular language called SQL or Structured Query Language.\nSome APIs will require registration of a “token” which will be an input in your URL. We’ll go over those with an example using the census API.",
    "crumbs": [
      "Learning R",
      "15. APIs"
    ]
  },
  {
    "objectID": "15.apis.html#writing-api-calls-to-nyc-open-data",
    "href": "15.apis.html#writing-api-calls-to-nyc-open-data",
    "title": "15. APIs",
    "section": "Writing API Calls to NYC Open Data",
    "text": "Writing API Calls to NYC Open Data\nUsing API Calls is particularly useful when you’re dealing with a **huge dataset** that would otherwise be a hassle to download in full. For this example, we’re going to use the HPD’s Housing Maintinance Code Violations dataset on NYC Open Data, which has ~7 million rows.\n\nGrabbing the “API Endpoint”\nLet’s first grab the beginning part of the URL that we’re going to use to write our API Call. This is called the “API Endpoint” and can be found by clicking the “API” tab on the NYC Open Data page for the dataset you’re working with.\nBefore copying the URL, make sure you set the data format toggle from “JSON” to “CSV”, as that is the format we’re going to want our data in.\nFor our example, our endpoint looks like this:\nhttps://data.cityofnewyork.us/resource/wvxf-dwi5.csv\n\n\nWriting up your API Call\nCopy the API Endpoint into a text editor - or an R script! - (I prefer Sublime Text or Visual Studio Code— others like Word or Pages have a tendency to “auto-correct” certain letters and syntax which may mess you up).\nNow, to initiate our query, we are going to add ?$query= to the end of our URL:\nhttps://data.cityofnewyork.us/resource/wvxf-dwi5.csv?$query=\n\n\nAdding your Query\nAt the end our URL, we can now add some special code to filter the violations data for our download.\nTo do this, we’re going to want to first take a look at the API Documentation for our dataset of choice, which can be found by clicking on the “API” tab again on the dataset’s Open Data page and clicking the “API Docs” button. Specifically, this documentation gives us a run down of all of the columns in the data and how we can reference them by name in our API call.\nFor this example, we want to look at the most serious (class C) HPD Violations within the past month. So, we’re going to write out our query as such:\nSELECT * – this selects all columns of the data\nWHERE inspectiondate&gt;='2021-06-01T00:00:01.000' AND inspectiondate&lt;'2021-09-01T00:00:01.000' AND class='C' – this filters only rows where the inspectiondate value is between June 1st and Aug 31st, and the class of the violation is 'C'. The AND operator here allows us to include multiple filtering conditions at once, and could even include conditions on other columns. Note the special format that the dates come in… we were able to spot this by looking at the Documentation.\nLIMIT 100000 — this sets the maximum number of downloadable rows to 100,000. It’s good practice to set a limit here so we don’t accidentially try downloading millions of rows at once. Note: if you don’t specify, the default limit is just 1,000 rows!\nYou can find more information on the types of queries you can write on the Socrata Developers Portal (Socrata is the special “flavor” of API that NYC Open Data uses).\n\n\nRunning our API Call\nWe add the above pieces in that order to our URL:\nhttps://data.cityofnewyork.us/resource/wvxf-dwi5.csv?$query=SELECT * WHERE inspectiondate&gt;='2021-06-01T00:00:01.000' AND inspectiondate&lt;'2021-09-01T00:00:01.000' AND class='C' LIMIT 100000\nNow, you can copy this full url into your browser and press ENTER— your special download should begin!\nWe can also use string operators to create and quickly modify the different components of our API call.\n\nbase_url &lt;- \"https://data.cityofnewyork.us/resource/wvxf-dwi5.csv\"\n\ninspectiondate_range &lt;- c(\"2021-06-01T00:00:01.000\",\"2021-09-01T00:00:01.000\")\n\nclass &lt;- \"C\"\n\nlimit &lt;- c(\"100000\")\n\n\nfull_api_call &lt;- paste0(base_url, \"?$query=SELECT * WHERE inspectiondate&gt;='\",inspectiondate_range[1],\"' AND inspectiondate&lt;'\",inspectiondate_range[2],\"' AND class='\",class,\"' LIMIT \",limit)\n\n\n\nImporting your data directly into R Studio\nOnce you have your data downloaded via API Call, you can feel free to import it into your R project like any other CSV. If you want to use the URL you created to import it directly, you can do that as well:\n\nlibrary(tidyverse)\nlibrary(fs)\n\n# R doesn't like weird characters like spaces and carats, so we need the `URLencode` function here to encode those symbols properly\n\nurl_hpd_viol &lt;- URLencode(\"https://data.cityofnewyork.us/resource/wvxf-dwi5.csv?$query=SELECT * WHERE inspectiondate&gt;='2021-06-01T00:00:01.000' AND inspectiondate&lt;'2021-09-01T00:00:01.000' AND class='C' LIMIT 100000\")\n\n\n# Now, we can use our formatted url inside our `read_csv` function\n\nsummer_hpd_viols &lt;- read_csv(url_hpd_viol)\n\n\n\nNote: Always check the size of your output\nSometimes, the limit on your API Call may make your data export smaller than your desired outcome, and you won’t necessarily be notified. Therefore, it is always very important to check the number of rows of your data from your API Call before proceeding with analysis— if the number of rows matches the exact number of your limit (or is 1000, the default limit), it’s very likely that your data got cut off and you don’t have the complete set of data that you wanted.\nThe below example illustrates this problem and shows how to diagnose. For the example, imagine that we didn’t include a LIMIT clause in our API Call query:\nhttps://data.cityofnewyork.us/resource/wvxf-dwi5.csv?$query=SELECT * WHERE inspectiondate&gt;='2021-06-01T00:00:01.000' AND inspectiondate&lt;'2021-09-01T00:00:01.000'\n\nurl_viol_no_limit = URLencode(\"https://data.cityofnewyork.us/resource/wvxf-dwi5.csv?$query=SELECT * WHERE inspectiondate&gt;='2021-06-01T00:00:01.000' AND inspectiondate&lt;'2021-09-01T00:00:01.000'\")\n\nsummer_violations_cut_off &lt;- read_csv(url_viol_no_limit)\n\n# Using the head() function won't actually reveal the cut-off problem:\nhead(summer_violations_cut_off)\n\n# A tibble: 6 × 41\n  violationid buildingid registrationid boroid boro   housenumber lowhousenumber\n        &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;       &lt;chr&gt;         \n1    14369016     326090         374306      3 BROOK… 735         735           \n2    14368090     374043         316185      3 BROOK… 565         565           \n3    14372713     123595         219960      2 BRONX  4639        4639          \n4    14372260     167073         320072      3 BROOK… 416         416           \n5    14372287     167073         320072      3 BROOK… 416         416           \n6    14338217      38732         122934      1 MANHA… 414         414           \n# ℹ 34 more variables: highhousenumber &lt;chr&gt;, streetname &lt;chr&gt;,\n#   streetcode &lt;dbl&gt;, zip &lt;dbl&gt;, apartment &lt;chr&gt;, …\n\n\nBy looking at the head of your dataset, things appear to be fine. However, let’s use the nrow() function to get a sense of how many rows we have:\n\nnrow(summer_violations_cut_off)\n\n[1] 1000\n\n\nGiven that our data output is 1,000 rows, which is exactly the default limit for API Calls to NYC Open Data, it’s very likely that our data got cut off and there are more rows within our filtering conditions that we want.\nOur next step would be to increase our LIMIT in our API CAll until get a number of outputs rows below the limit value. In our first example, you can see we’ve done just that— our LIMIT was set to 100,000 rows and we only received around 20K or so rows. Safe to say we got all of the rows that fit our filtering criteria…",
    "crumbs": [
      "Learning R",
      "15. APIs"
    ]
  },
  {
    "objectID": "15.apis.html#other-apis",
    "href": "15.apis.html#other-apis",
    "title": "15. APIs",
    "section": "Other APIs",
    "text": "Other APIs\nThousands of sites have APIs that work similarly. Each API will have specific documentation and formatting. Once you read up on the documentation for one, the others will be easier to decipher. Here are some examples\n\nSpotify\nPro Publica’s Nonprofit Explorer\nBureau of Labor Statistics (BLS)",
    "crumbs": [
      "Learning R",
      "15. APIs"
    ]
  },
  {
    "objectID": "15.apis.html#api-wrappers",
    "href": "15.apis.html#api-wrappers",
    "title": "15. APIs",
    "section": "API Wrappers",
    "text": "API Wrappers\nA number of developers have also created R packages that make certain APIs easier to use. The example we will look at next, tidycensus, is an example of a wrapper for the US Census API. It will construct API calls based on parameters we set in a function. Here are some other API wrappers.\n\nRSocrata (Many Open Data Portals, including NYC’s use Socrata’s data system)\nBLS\nGoogle Sheets\nDatawrapper",
    "crumbs": [
      "Learning R",
      "15. APIs"
    ]
  }
]